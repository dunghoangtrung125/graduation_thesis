{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:37:10.661995: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-11 17:37:10.662090: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-11-11 17:37:10.852273: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-11-11 17:37:10.890348: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-11 17:37:12.524492: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.646\n",
      "Iteration 2000 reward: 0.704\n",
      "Iteration 3000 reward: 0.7333333333333333\n",
      "Iteration 4000 reward: 0.7585\n",
      "Iteration 5000 reward: 0.8002\n",
      "Iteration 6000 reward: 0.8385\n",
      "Iteration 7000 reward: 0.8697142857142857\n",
      "Iteration 8000 reward: 0.896875\n",
      "Iteration 9000 reward: 0.9276666666666666\n",
      "Iteration 10000 reward: 0.952\n",
      "Iteration 11000 reward: 0.9788181818181818\n",
      "Iteration 12000 reward: 1.0015833333333333\n",
      "Iteration 13000 reward: 1.021\n",
      "Iteration 14000 reward: 1.0395\n",
      "Iteration 15000 reward: 1.0561333333333334\n",
      "Iteration 16000 reward: 1.069625\n",
      "Iteration 17000 reward: 1.0853529411764706\n",
      "Iteration 18000 reward: 1.1011111111111112\n",
      "Iteration 19000 reward: 1.1125263157894736\n",
      "Iteration 20000 reward: 1.1259\n",
      "Iteration 21000 reward: 1.1377619047619048\n",
      "Iteration 22000 reward: 1.1470909090909092\n",
      "Iteration 23000 reward: 1.1568260869565217\n",
      "Iteration 24000 reward: 1.1679583333333334\n",
      "Iteration 25000 reward: 1.17628\n",
      "Iteration 26000 reward: 1.1867307692307691\n",
      "Iteration 27000 reward: 1.193888888888889\n",
      "Iteration 28000 reward: 1.2004642857142858\n",
      "Iteration 29000 reward: 1.205\n",
      "Iteration 30000 reward: 1.2096\n",
      "Iteration 31000 reward: 1.215\n",
      "Iteration 32000 reward: 1.22103125\n",
      "Iteration 33000 reward: 1.227060606060606\n",
      "Iteration 34000 reward: 1.2326176470588235\n",
      "Iteration 35000 reward: 1.2379142857142857\n",
      "Iteration 36000 reward: 1.2434444444444444\n",
      "Iteration 37000 reward: 1.248\n",
      "Iteration 38000 reward: 1.2537894736842106\n",
      "Iteration 39000 reward: 1.2572564102564103\n",
      "Iteration 40000 reward: 1.260475\n",
      "Iteration 41000 reward: 1.2646829268292683\n",
      "Iteration 42000 reward: 1.2682142857142857\n",
      "Iteration 43000 reward: 1.2725348837209303\n",
      "Iteration 44000 reward: 1.27625\n",
      "Iteration 45000 reward: 1.2802222222222222\n",
      "Iteration 46000 reward: 1.2829347826086956\n",
      "Iteration 47000 reward: 1.2858936170212767\n",
      "Iteration 48000 reward: 1.2876875\n",
      "Iteration 49000 reward: 1.2906122448979591\n",
      "Iteration 50000 reward: 1.29484\n",
      "Iteration 51000 reward: 1.297686274509804\n",
      "Iteration 52000 reward: 1.299923076923077\n",
      "Iteration 53000 reward: 1.3014339622641509\n",
      "Iteration 54000 reward: 1.303537037037037\n",
      "Iteration 55000 reward: 1.305509090909091\n",
      "Iteration 56000 reward: 1.3078571428571428\n",
      "Iteration 57000 reward: 1.309438596491228\n",
      "Iteration 58000 reward: 1.3114310344827587\n",
      "Iteration 59000 reward: 1.3132203389830508\n",
      "Iteration 60000 reward: 1.3155666666666668\n",
      "Iteration 61000 reward: 1.3170655737704917\n",
      "Iteration 62000 reward: 1.318758064516129\n",
      "Iteration 63000 reward: 1.319984126984127\n",
      "Iteration 64000 reward: 1.32075\n",
      "Iteration 65000 reward: 1.3225692307692307\n",
      "Iteration 66000 reward: 1.3238484848484848\n",
      "Iteration 67000 reward: 1.3252686567164178\n",
      "Iteration 68000 reward: 1.3271764705882354\n",
      "Iteration 69000 reward: 1.3285072463768115\n",
      "Iteration 70000 reward: 1.3296428571428571\n",
      "Iteration 71000 reward: 1.331450704225352\n",
      "Iteration 72000 reward: 1.3329027777777778\n",
      "Iteration 73000 reward: 1.3343561643835617\n",
      "Iteration 74000 reward: 1.3353378378378378\n",
      "Iteration 75000 reward: 1.3366933333333333\n",
      "Iteration 76000 reward: 1.3379736842105263\n",
      "Iteration 77000 reward: 1.3394805194805195\n",
      "Iteration 78000 reward: 1.340423076923077\n",
      "Iteration 79000 reward: 1.3418860759493672\n",
      "Iteration 80000 reward: 1.3427\n",
      "Iteration 81000 reward: 1.3443827160493826\n",
      "Iteration 82000 reward: 1.3447804878048781\n",
      "Iteration 83000 reward: 1.3453373493975904\n",
      "Iteration 84000 reward: 1.3466190476190476\n",
      "Iteration 85000 reward: 1.3475529411764706\n",
      "Iteration 86000 reward: 1.3482441860465115\n",
      "Iteration 87000 reward: 1.3494712643678162\n",
      "Iteration 88000 reward: 1.350681818181818\n",
      "Iteration 89000 reward: 1.3517865168539325\n",
      "Iteration 90000 reward: 1.3525888888888888\n",
      "Iteration 91000 reward: 1.3534725274725274\n",
      "Iteration 92000 reward: 1.3542065217391304\n",
      "Iteration 93000 reward: 1.3551612903225807\n",
      "Iteration 94000 reward: 1.3557553191489362\n",
      "Iteration 95000 reward: 1.3561263157894736\n",
      "Iteration 96000 reward: 1.3564479166666668\n",
      "Iteration 97000 reward: 1.3571546391752578\n",
      "Iteration 98000 reward: 1.357357142857143\n",
      "Iteration 99000 reward: 1.3585353535353535\n",
      "Iteration 100000 reward: 1.35957\n",
      "Iteration 101000 reward: 1.3600396039603961\n",
      "Iteration 102000 reward: 1.360372549019608\n",
      "Iteration 103000 reward: 1.3614174757281554\n",
      "Iteration 104000 reward: 1.361826923076923\n",
      "Iteration 105000 reward: 1.3623333333333334\n",
      "Iteration 106000 reward: 1.3623584905660377\n",
      "Iteration 107000 reward: 1.362644859813084\n",
      "Iteration 108000 reward: 1.363361111111111\n",
      "Iteration 109000 reward: 1.3637247706422018\n",
      "Iteration 110000 reward: 1.3642181818181818\n",
      "Iteration 111000 reward: 1.36490990990991\n",
      "Iteration 112000 reward: 1.3653214285714286\n",
      "Iteration 113000 reward: 1.3659646017699114\n",
      "Iteration 114000 reward: 1.3663947368421052\n",
      "Iteration 115000 reward: 1.3670347826086957\n",
      "Iteration 116000 reward: 1.3673189655172413\n",
      "Iteration 117000 reward: 1.3678632478632478\n",
      "Iteration 118000 reward: 1.3684322033898304\n",
      "Iteration 119000 reward: 1.3693109243697479\n",
      "Iteration 120000 reward: 1.36985\n",
      "Iteration 121000 reward: 1.3701818181818182\n",
      "Iteration 122000 reward: 1.3707868852459015\n",
      "Iteration 123000 reward: 1.3709918699186991\n",
      "Iteration 124000 reward: 1.3713225806451612\n",
      "Iteration 125000 reward: 1.37144\n",
      "Iteration 126000 reward: 1.3719285714285714\n",
      "Iteration 127000 reward: 1.3723228346456693\n",
      "Iteration 128000 reward: 1.3727109375\n",
      "Iteration 129000 reward: 1.373263565891473\n",
      "Iteration 130000 reward: 1.373676923076923\n",
      "Iteration 131000 reward: 1.3743740458015268\n",
      "Iteration 132000 reward: 1.3745833333333333\n",
      "Iteration 133000 reward: 1.3752556390977444\n",
      "Iteration 134000 reward: 1.3755522388059702\n",
      "Iteration 135000 reward: 1.3757333333333333\n",
      "Iteration 136000 reward: 1.3760588235294118\n",
      "Iteration 137000 reward: 1.3764233576642335\n",
      "Iteration 138000 reward: 1.3767898550724638\n",
      "Iteration 139000 reward: 1.3769568345323742\n",
      "Iteration 140000 reward: 1.3774\n",
      "Iteration 141000 reward: 1.3774609929078014\n",
      "Iteration 142000 reward: 1.3779225352112676\n",
      "Iteration 143000 reward: 1.378027972027972\n",
      "Iteration 144000 reward: 1.3783194444444444\n",
      "Iteration 145000 reward: 1.3784896551724137\n",
      "Iteration 146000 reward: 1.3786301369863014\n",
      "Iteration 147000 reward: 1.3790544217687075\n",
      "Iteration 148000 reward: 1.379135135135135\n",
      "Iteration 149000 reward: 1.379724832214765\n",
      "Iteration 150000 reward: 1.37988\n",
      "Iteration 151000 reward: 1.3800993377483444\n",
      "Iteration 152000 reward: 1.3802960526315788\n",
      "Iteration 153000 reward: 1.3804052287581698\n",
      "Iteration 154000 reward: 1.3808376623376624\n",
      "Iteration 155000 reward: 1.3809935483870968\n",
      "Iteration 156000 reward: 1.3811346153846153\n",
      "Iteration 157000 reward: 1.3814777070063695\n",
      "Iteration 158000 reward: 1.3817278481012658\n",
      "Iteration 159000 reward: 1.3821132075471698\n",
      "Iteration 160000 reward: 1.38226875\n",
      "Iteration 161000 reward: 1.3823416149068324\n",
      "Iteration 162000 reward: 1.3822716049382715\n",
      "Iteration 163000 reward: 1.3828466257668712\n",
      "Iteration 164000 reward: 1.383170731707317\n",
      "Iteration 165000 reward: 1.3830848484848486\n",
      "Iteration 166000 reward: 1.383487951807229\n",
      "Iteration 167000 reward: 1.3836946107784431\n",
      "Iteration 168000 reward: 1.3839940476190475\n",
      "Iteration 169000 reward: 1.384396449704142\n",
      "Iteration 170000 reward: 1.3849117647058824\n",
      "Iteration 171000 reward: 1.3850058479532164\n",
      "Iteration 172000 reward: 1.385360465116279\n",
      "Iteration 173000 reward: 1.3856763005780346\n",
      "Iteration 174000 reward: 1.3858333333333333\n",
      "Iteration 175000 reward: 1.3860914285714285\n",
      "Iteration 176000 reward: 1.3863352272727272\n",
      "Iteration 177000 reward: 1.386502824858757\n",
      "Iteration 178000 reward: 1.3865898876404494\n",
      "Iteration 179000 reward: 1.3867877094972068\n",
      "Iteration 180000 reward: 1.3867555555555555\n",
      "Iteration 181000 reward: 1.3870331491712706\n",
      "Iteration 182000 reward: 1.3871483516483516\n",
      "Iteration 183000 reward: 1.3870601092896175\n",
      "Iteration 184000 reward: 1.3872934782608695\n",
      "Iteration 185000 reward: 1.3875783783783784\n",
      "Iteration 186000 reward: 1.3878225806451614\n",
      "Iteration 187000 reward: 1.387946524064171\n",
      "Iteration 188000 reward: 1.388063829787234\n",
      "Iteration 189000 reward: 1.388121693121693\n",
      "Iteration 190000 reward: 1.3880526315789474\n",
      "Iteration 191000 reward: 1.388068062827225\n",
      "Iteration 192000 reward: 1.3883333333333334\n",
      "Iteration 193000 reward: 1.3882694300518135\n",
      "Iteration 194000 reward: 1.3882938144329897\n",
      "Iteration 195000 reward: 1.3884358974358975\n",
      "Iteration 196000 reward: 1.3884438775510204\n",
      "Iteration 197000 reward: 1.3886903553299492\n",
      "Iteration 198000 reward: 1.3887777777777779\n",
      "Iteration 199000 reward: 1.3886884422110553\n",
      "Iteration 200000 reward: 1.389095\n",
      "Iteration 201000 reward: 1.3891194029850746\n",
      "Iteration 202000 reward: 1.3893019801980198\n",
      "Iteration 203000 reward: 1.3895911330049262\n",
      "Iteration 204000 reward: 1.3899558823529412\n",
      "Iteration 205000 reward: 1.390180487804878\n",
      "Iteration 206000 reward: 1.3905728155339805\n",
      "Iteration 207000 reward: 1.3909082125603864\n",
      "Iteration 208000 reward: 1.3909903846153846\n",
      "Iteration 209000 reward: 1.3910526315789473\n",
      "Iteration 210000 reward: 1.3912809523809524\n",
      "Iteration 211000 reward: 1.3913744075829384\n",
      "Iteration 212000 reward: 1.3913820754716981\n",
      "Iteration 213000 reward: 1.3916525821596244\n",
      "Iteration 214000 reward: 1.3918644859813085\n",
      "Iteration 215000 reward: 1.391939534883721\n",
      "Iteration 216000 reward: 1.3921203703703704\n",
      "Iteration 217000 reward: 1.3920967741935484\n",
      "Iteration 218000 reward: 1.3924908256880735\n",
      "Iteration 219000 reward: 1.3926392694063927\n",
      "Iteration 220000 reward: 1.3927772727272727\n",
      "Iteration 221000 reward: 1.392918552036199\n",
      "Iteration 222000 reward: 1.3930135135135135\n",
      "Iteration 223000 reward: 1.3929417040358745\n",
      "Iteration 224000 reward: 1.3928392857142857\n",
      "Iteration 225000 reward: 1.3930222222222222\n",
      "Iteration 226000 reward: 1.3932566371681416\n",
      "Iteration 227000 reward: 1.3933171806167401\n",
      "Iteration 228000 reward: 1.3935570175438596\n",
      "Iteration 229000 reward: 1.3938165938864628\n",
      "Iteration 230000 reward: 1.393986956521739\n",
      "Iteration 231000 reward: 1.394103896103896\n",
      "Iteration 232000 reward: 1.3942112068965518\n",
      "Iteration 233000 reward: 1.3944463519313304\n",
      "Iteration 234000 reward: 1.3945769230769232\n",
      "Iteration 235000 reward: 1.394595744680851\n",
      "Iteration 236000 reward: 1.3946737288135593\n",
      "Iteration 237000 reward: 1.3948902953586497\n",
      "Iteration 238000 reward: 1.3950084033613446\n",
      "Iteration 239000 reward: 1.3950753138075314\n",
      "Iteration 240000 reward: 1.395325\n",
      "Iteration 241000 reward: 1.39549377593361\n",
      "Iteration 242000 reward: 1.3955619834710744\n",
      "Iteration 243000 reward: 1.3956378600823045\n",
      "Iteration 244000 reward: 1.3957950819672131\n",
      "Iteration 245000 reward: 1.3959020408163265\n",
      "Iteration 246000 reward: 1.3959837398373984\n",
      "Iteration 247000 reward: 1.3961821862348178\n",
      "Iteration 248000 reward: 1.3964717741935484\n",
      "Iteration 249000 reward: 1.396694779116466\n",
      "Iteration 250000 reward: 1.396792\n",
      "Iteration 251000 reward: 1.396800796812749\n",
      "Iteration 252000 reward: 1.3966825396825397\n",
      "Iteration 253000 reward: 1.3968300395256916\n",
      "Iteration 254000 reward: 1.3970196850393701\n",
      "Iteration 255000 reward: 1.3971254901960783\n",
      "Iteration 256000 reward: 1.39695703125\n",
      "Iteration 257000 reward: 1.3970622568093385\n",
      "Iteration 258000 reward: 1.3970116279069766\n",
      "Iteration 259000 reward: 1.3972277992277993\n",
      "Iteration 260000 reward: 1.397376923076923\n",
      "Iteration 261000 reward: 1.3976015325670499\n",
      "Iteration 262000 reward: 1.3976106870229008\n",
      "Iteration 263000 reward: 1.3977946768060836\n",
      "Iteration 264000 reward: 1.397939393939394\n",
      "Iteration 265000 reward: 1.3980415094339622\n",
      "Iteration 266000 reward: 1.3979962406015038\n",
      "Iteration 267000 reward: 1.3982134831460675\n",
      "Iteration 268000 reward: 1.3982910447761194\n",
      "Iteration 269000 reward: 1.39835687732342\n",
      "Iteration 270000 reward: 1.3984\n",
      "Iteration 271000 reward: 1.398309963099631\n",
      "Iteration 272000 reward: 1.3984375\n",
      "Iteration 273000 reward: 1.3986483516483517\n",
      "Iteration 274000 reward: 1.3987189781021898\n",
      "Iteration 275000 reward: 1.3986727272727273\n",
      "Iteration 276000 reward: 1.3987608695652174\n",
      "Iteration 277000 reward: 1.398913357400722\n",
      "Iteration 278000 reward: 1.3989964028776978\n",
      "Iteration 279000 reward: 1.399078853046595\n",
      "Iteration 280000 reward: 1.3992392857142857\n",
      "Iteration 281000 reward: 1.3991957295373665\n",
      "Iteration 282000 reward: 1.3993014184397163\n",
      "Iteration 283000 reward: 1.3996219081272085\n",
      "Iteration 284000 reward: 1.3996514084507041\n",
      "Iteration 285000 reward: 1.3997298245614036\n",
      "Iteration 286000 reward: 1.3998461538461537\n",
      "Iteration 287000 reward: 1.3998919860627177\n",
      "Iteration 288000 reward: 1.399982638888889\n",
      "Iteration 289000 reward: 1.3999377162629758\n",
      "Iteration 290000 reward: 1.3999310344827587\n",
      "Iteration 291000 reward: 1.400044673539519\n",
      "Iteration 292000 reward: 1.4000068493150686\n",
      "Iteration 293000 reward: 1.4000546075085325\n",
      "Iteration 294000 reward: 1.4000578231292518\n",
      "Iteration 295000 reward: 1.4000813559322034\n",
      "Iteration 296000 reward: 1.4002297297297297\n",
      "Iteration 297000 reward: 1.4005488215488215\n",
      "Iteration 298000 reward: 1.40046644295302\n",
      "Iteration 299000 reward: 1.4005685618729098\n",
      "Iteration 300000 reward: 1.40083\n",
      "Iteration 301000 reward: 1.4008239202657806\n",
      "Iteration 302000 reward: 1.4009503311258278\n",
      "Iteration 303000 reward: 1.401089108910891\n",
      "Iteration 304000 reward: 1.401404605263158\n",
      "Iteration 305000 reward: 1.401422950819672\n",
      "Iteration 306000 reward: 1.4013692810457516\n",
      "Iteration 307000 reward: 1.4014918566775245\n",
      "Iteration 308000 reward: 1.4016915584415583\n",
      "Iteration 309000 reward: 1.4017605177993528\n",
      "Iteration 310000 reward: 1.4019935483870967\n",
      "Iteration 311000 reward: 1.4020128617363343\n",
      "Iteration 312000 reward: 1.4021634615384615\n",
      "Iteration 313000 reward: 1.4022460063897764\n",
      "Iteration 314000 reward: 1.40243949044586\n",
      "Iteration 315000 reward: 1.4024539682539683\n",
      "Iteration 316000 reward: 1.4024746835443038\n",
      "Iteration 317000 reward: 1.4025299684542587\n",
      "Iteration 318000 reward: 1.4023867924528302\n",
      "Iteration 319000 reward: 1.402435736677116\n",
      "Iteration 320000 reward: 1.402390625\n",
      "Iteration 321000 reward: 1.4024517133956387\n",
      "Iteration 322000 reward: 1.402552795031056\n",
      "Iteration 323000 reward: 1.402625386996904\n",
      "Iteration 324000 reward: 1.4028148148148147\n",
      "Iteration 325000 reward: 1.4028892307692307\n",
      "Iteration 326000 reward: 1.4029723926380369\n",
      "Iteration 327000 reward: 1.4031223241590214\n",
      "Iteration 328000 reward: 1.4031524390243904\n",
      "Iteration 329000 reward: 1.4033282674772036\n",
      "Iteration 330000 reward: 1.4034333333333333\n",
      "Iteration 331000 reward: 1.4034561933534744\n",
      "Iteration 332000 reward: 1.403563253012048\n",
      "Iteration 333000 reward: 1.4035615615615615\n",
      "Iteration 334000 reward: 1.4037185628742515\n",
      "Iteration 335000 reward: 1.403779104477612\n",
      "Iteration 336000 reward: 1.4038363095238096\n",
      "Iteration 337000 reward: 1.4039554896142432\n",
      "Iteration 338000 reward: 1.4040236686390533\n",
      "Iteration 339000 reward: 1.403952802359882\n",
      "Iteration 340000 reward: 1.4040294117647059\n",
      "Iteration 341000 reward: 1.404108504398827\n",
      "Iteration 342000 reward: 1.4041783625730995\n",
      "Iteration 343000 reward: 1.4043061224489797\n",
      "Iteration 344000 reward: 1.404485465116279\n",
      "Iteration 345000 reward: 1.4044956521739131\n",
      "Iteration 346000 reward: 1.4045115606936416\n",
      "Iteration 347000 reward: 1.4044870317002882\n",
      "Iteration 348000 reward: 1.4046666666666667\n",
      "Iteration 349000 reward: 1.404893982808023\n",
      "Iteration 350000 reward: 1.404942857142857\n",
      "Iteration 351000 reward: 1.405048433048433\n",
      "Iteration 352000 reward: 1.4050738636363636\n",
      "Iteration 353000 reward: 1.4050594900849858\n",
      "Iteration 354000 reward: 1.4051242937853108\n",
      "Iteration 355000 reward: 1.405312676056338\n",
      "Iteration 356000 reward: 1.4053679775280898\n",
      "Iteration 357000 reward: 1.4054005602240895\n",
      "Iteration 358000 reward: 1.4054385474860336\n",
      "Iteration 359000 reward: 1.4055153203342619\n",
      "Iteration 360000 reward: 1.4055527777777779\n",
      "Iteration 361000 reward: 1.405639889196676\n",
      "Iteration 362000 reward: 1.4057016574585635\n",
      "Iteration 363000 reward: 1.4058071625344353\n",
      "Iteration 364000 reward: 1.4057994505494507\n",
      "Iteration 365000 reward: 1.4059479452054795\n",
      "Iteration 366000 reward: 1.4060273224043716\n",
      "Iteration 367000 reward: 1.4059373297002724\n",
      "Iteration 368000 reward: 1.4061059782608696\n",
      "Iteration 369000 reward: 1.4063279132791329\n",
      "Iteration 370000 reward: 1.4064\n",
      "Iteration 371000 reward: 1.4066307277628032\n",
      "Iteration 372000 reward: 1.4068037634408601\n",
      "Iteration 373000 reward: 1.4068498659517426\n",
      "Iteration 374000 reward: 1.4067727272727273\n",
      "Iteration 375000 reward: 1.4068346666666667\n",
      "Iteration 376000 reward: 1.4068510638297873\n",
      "Iteration 377000 reward: 1.406925729442971\n",
      "Iteration 378000 reward: 1.4070026455026454\n",
      "Iteration 379000 reward: 1.407065963060686\n",
      "Iteration 380000 reward: 1.407021052631579\n",
      "Iteration 381000 reward: 1.4070419947506563\n",
      "Iteration 382000 reward: 1.4070287958115184\n",
      "Iteration 383000 reward: 1.4072219321148824\n",
      "Iteration 384000 reward: 1.4071588541666666\n",
      "Iteration 385000 reward: 1.4071636363636364\n",
      "Iteration 386000 reward: 1.407259067357513\n",
      "Iteration 387000 reward: 1.4071731266149872\n",
      "Iteration 388000 reward: 1.407332474226804\n",
      "Iteration 389000 reward: 1.4073341902313625\n",
      "Iteration 390000 reward: 1.4073179487179488\n",
      "Iteration 391000 reward: 1.4073478260869565\n",
      "Iteration 392000 reward: 1.407469387755102\n",
      "Iteration 393000 reward: 1.4074936386768448\n",
      "Iteration 394000 reward: 1.407505076142132\n",
      "Iteration 395000 reward: 1.407526582278481\n",
      "Iteration 396000 reward: 1.407550505050505\n",
      "Iteration 397000 reward: 1.4077103274559193\n",
      "Iteration 398000 reward: 1.4077085427135678\n",
      "Iteration 399000 reward: 1.407766917293233\n",
      "Iteration 400000 reward: 1.4077125\n",
      "Iteration 401000 reward: 1.4076583541147132\n",
      "Iteration 402000 reward: 1.4076940298507463\n",
      "Iteration 403000 reward: 1.4076923076923078\n",
      "Iteration 404000 reward: 1.4076559405940594\n",
      "Iteration 405000 reward: 1.4076543209876544\n",
      "Iteration 406000 reward: 1.4075935960591133\n",
      "Iteration 407000 reward: 1.4075135135135135\n",
      "Iteration 408000 reward: 1.4074166666666668\n",
      "Iteration 409000 reward: 1.4074180929095355\n",
      "Iteration 410000 reward: 1.4074780487804879\n",
      "Iteration 411000 reward: 1.4074866180048662\n",
      "Iteration 412000 reward: 1.4074563106796116\n",
      "Iteration 413000 reward: 1.4073389830508474\n",
      "Iteration 414000 reward: 1.407352657004831\n",
      "Iteration 415000 reward: 1.407409638554217\n",
      "Iteration 416000 reward: 1.4074182692307693\n",
      "Iteration 417000 reward: 1.4074604316546762\n",
      "Iteration 418000 reward: 1.407488038277512\n",
      "Iteration 419000 reward: 1.4075035799522673\n",
      "Iteration 420000 reward: 1.4073428571428572\n",
      "Iteration 421000 reward: 1.4073372921615201\n",
      "Iteration 422000 reward: 1.4074218009478674\n",
      "Iteration 423000 reward: 1.4073309692671394\n",
      "Iteration 424000 reward: 1.4074268867924529\n",
      "Iteration 425000 reward: 1.4075341176470588\n",
      "Iteration 426000 reward: 1.407488262910798\n",
      "Iteration 427000 reward: 1.407543325526932\n",
      "Iteration 428000 reward: 1.4075841121495327\n",
      "Iteration 429000 reward: 1.4075990675990675\n",
      "Iteration 430000 reward: 1.4075813953488372\n",
      "Iteration 431000 reward: 1.407568445475638\n",
      "Iteration 432000 reward: 1.4075833333333334\n",
      "Iteration 433000 reward: 1.4075542725173211\n",
      "Iteration 434000 reward: 1.4075230414746545\n",
      "Iteration 435000 reward: 1.4075701149425288\n",
      "Iteration 436000 reward: 1.4075802752293578\n",
      "Iteration 437000 reward: 1.407649885583524\n",
      "Iteration 438000 reward: 1.407607305936073\n",
      "Iteration 439000 reward: 1.4075671981776765\n",
      "Iteration 440000 reward: 1.4076045454545454\n",
      "Iteration 441000 reward: 1.407612244897959\n",
      "Iteration 442000 reward: 1.4074886877828054\n",
      "Iteration 443000 reward: 1.4074401805869075\n",
      "Iteration 444000 reward: 1.4074234234234235\n",
      "Iteration 445000 reward: 1.4073955056179774\n",
      "Iteration 446000 reward: 1.4074484304932735\n",
      "Iteration 447000 reward: 1.407503355704698\n",
      "Iteration 448000 reward: 1.4074620535714286\n",
      "Iteration 449000 reward: 1.4075590200445434\n",
      "Iteration 450000 reward: 1.4076422222222222\n",
      "Iteration 451000 reward: 1.40770066518847\n",
      "Iteration 452000 reward: 1.4077101769911504\n",
      "Iteration 453000 reward: 1.407858719646799\n",
      "Iteration 454000 reward: 1.4079162995594714\n",
      "Iteration 455000 reward: 1.4079934065934065\n",
      "Iteration 456000 reward: 1.4079627192982456\n",
      "Iteration 457000 reward: 1.4078840262582057\n",
      "Iteration 458000 reward: 1.4079781659388646\n",
      "Iteration 459000 reward: 1.407967320261438\n",
      "Iteration 460000 reward: 1.4080065217391304\n",
      "Iteration 461000 reward: 1.4080216919739696\n",
      "Iteration 462000 reward: 1.408077922077922\n",
      "Iteration 463000 reward: 1.4081123110151188\n",
      "Iteration 464000 reward: 1.4080689655172414\n",
      "Iteration 465000 reward: 1.4081741935483871\n",
      "Iteration 466000 reward: 1.4081888412017167\n",
      "Iteration 467000 reward: 1.408201284796574\n",
      "Iteration 468000 reward: 1.4081709401709401\n",
      "Iteration 469000 reward: 1.4082068230277185\n",
      "Iteration 470000 reward: 1.4082744680851065\n",
      "Iteration 471000 reward: 1.4083248407643312\n",
      "Iteration 472000 reward: 1.4082902542372882\n",
      "Iteration 473000 reward: 1.408262156448203\n",
      "Iteration 474000 reward: 1.4083396624472573\n",
      "Iteration 475000 reward: 1.4083915789473684\n",
      "Iteration 476000 reward: 1.408344537815126\n",
      "Iteration 477000 reward: 1.408425576519916\n",
      "Iteration 478000 reward: 1.4084435146443515\n",
      "Iteration 479000 reward: 1.408446764091858\n",
      "Iteration 480000 reward: 1.4083916666666667\n",
      "Iteration 481000 reward: 1.4083534303534304\n",
      "Iteration 482000 reward: 1.4084647302904565\n",
      "Iteration 483000 reward: 1.4084347826086956\n",
      "Iteration 484000 reward: 1.4084814049586778\n",
      "Iteration 485000 reward: 1.408521649484536\n",
      "Iteration 486000 reward: 1.408574074074074\n",
      "Iteration 487000 reward: 1.408611909650924\n",
      "Iteration 488000 reward: 1.4086127049180328\n",
      "Iteration 489000 reward: 1.4086748466257668\n",
      "Iteration 490000 reward: 1.4086632653061224\n",
      "Iteration 491000 reward: 1.408714867617108\n",
      "Iteration 492000 reward: 1.4086869918699187\n",
      "Iteration 493000 reward: 1.4086795131845842\n",
      "Iteration 494000 reward: 1.4086336032388664\n",
      "Iteration 495000 reward: 1.4085030303030304\n",
      "Iteration 496000 reward: 1.408602822580645\n",
      "Iteration 497000 reward: 1.4086780684104627\n",
      "Iteration 498000 reward: 1.4087530120481928\n",
      "Iteration 499000 reward: 1.4086032064128255\n",
      "Iteration 500000 reward: 1.408584\n",
      "Iteration 501000 reward: 1.4086367265469062\n",
      "Iteration 502000 reward: 1.4086653386454184\n",
      "Iteration 503000 reward: 1.4086958250497017\n",
      "Iteration 504000 reward: 1.408625\n",
      "Iteration 505000 reward: 1.4086\n",
      "Iteration 506000 reward: 1.408604743083004\n",
      "Iteration 507000 reward: 1.4087041420118342\n",
      "Iteration 508000 reward: 1.4086791338582678\n",
      "Iteration 509000 reward: 1.4086915520628684\n",
      "Iteration 510000 reward: 1.4087058823529413\n",
      "Iteration 511000 reward: 1.4087788649706459\n",
      "Iteration 512000 reward: 1.4088984375\n",
      "Iteration 513000 reward: 1.408879142300195\n",
      "Iteration 514000 reward: 1.4089474708171206\n",
      "Iteration 515000 reward: 1.4088660194174758\n",
      "Iteration 516000 reward: 1.4089360465116278\n",
      "Iteration 517000 reward: 1.4089961315280464\n",
      "Iteration 518000 reward: 1.408972972972973\n",
      "Iteration 519000 reward: 1.408971098265896\n",
      "Iteration 520000 reward: 1.4090557692307693\n",
      "Iteration 521000 reward: 1.4090729366602688\n",
      "Iteration 522000 reward: 1.4090919540229885\n",
      "Iteration 523000 reward: 1.409208413001912\n",
      "Iteration 524000 reward: 1.40918893129771\n",
      "Iteration 525000 reward: 1.40928\n",
      "Iteration 526000 reward: 1.4092433460076046\n",
      "Iteration 527000 reward: 1.4092277039848198\n",
      "Iteration 528000 reward: 1.4092329545454545\n",
      "Iteration 529000 reward: 1.4092400756143668\n",
      "Iteration 530000 reward: 1.409245283018868\n",
      "Iteration 531000 reward: 1.409156308851224\n",
      "Iteration 532000 reward: 1.409092105263158\n",
      "Iteration 533000 reward: 1.409045028142589\n",
      "Iteration 534000 reward: 1.4090674157303371\n",
      "Iteration 535000 reward: 1.409044859813084\n",
      "Iteration 536000 reward: 1.4090466417910448\n",
      "Iteration 537000 reward: 1.4089571694599627\n",
      "Iteration 538000 reward: 1.4088736059479554\n",
      "Iteration 539000 reward: 1.4088923933209647\n",
      "Iteration 540000 reward: 1.4089092592592594\n",
      "Iteration 541000 reward: 1.4089186691312385\n",
      "Iteration 542000 reward: 1.408959409594096\n",
      "Iteration 543000 reward: 1.408926335174954\n",
      "Iteration 544000 reward: 1.408891544117647\n",
      "Iteration 545000 reward: 1.4089174311926604\n",
      "Iteration 546000 reward: 1.409007326007326\n",
      "Iteration 547000 reward: 1.4090840950639854\n",
      "Iteration 548000 reward: 1.4091204379562043\n",
      "Iteration 549000 reward: 1.4090910746812386\n",
      "Iteration 550000 reward: 1.4091436363636363\n",
      "Iteration 551000 reward: 1.409266787658802\n",
      "Iteration 552000 reward: 1.4093115942028986\n",
      "Iteration 553000 reward: 1.4092857142857143\n",
      "Iteration 554000 reward: 1.409259927797834\n",
      "Iteration 555000 reward: 1.4092072072072073\n",
      "Iteration 556000 reward: 1.4092428057553956\n",
      "Iteration 557000 reward: 1.4092567324955116\n",
      "Iteration 558000 reward: 1.4093279569892474\n",
      "Iteration 559000 reward: 1.4092933810375672\n",
      "Iteration 560000 reward: 1.4092875\n",
      "Iteration 561000 reward: 1.4092245989304812\n",
      "Iteration 562000 reward: 1.4092562277580072\n",
      "Iteration 563000 reward: 1.4092362344582594\n",
      "Iteration 564000 reward: 1.409209219858156\n",
      "Iteration 565000 reward: 1.4092548672566372\n",
      "Iteration 566000 reward: 1.4093109540636042\n",
      "Iteration 567000 reward: 1.4093245149911817\n",
      "Iteration 568000 reward: 1.4094031690140845\n",
      "Iteration 569000 reward: 1.4094042179261863\n",
      "Iteration 570000 reward: 1.4094543859649122\n",
      "Iteration 571000 reward: 1.409444833625219\n",
      "Iteration 572000 reward: 1.409423076923077\n",
      "Iteration 573000 reward: 1.40951832460733\n",
      "Iteration 574000 reward: 1.4095592334494773\n",
      "Iteration 575000 reward: 1.4095617391304347\n",
      "Iteration 576000 reward: 1.4096284722222223\n",
      "Iteration 577000 reward: 1.4096533795493935\n",
      "Iteration 578000 reward: 1.4097076124567474\n",
      "Iteration 579000 reward: 1.409651122625216\n",
      "Iteration 580000 reward: 1.4096931034482758\n",
      "Iteration 581000 reward: 1.4095748709122202\n",
      "Iteration 582000 reward: 1.409536082474227\n",
      "Iteration 583000 reward: 1.4095197255574614\n",
      "Iteration 584000 reward: 1.4095770547945206\n",
      "Iteration 585000 reward: 1.409642735042735\n",
      "Iteration 586000 reward: 1.4096569965870307\n",
      "Iteration 587000 reward: 1.4096933560477\n",
      "Iteration 588000 reward: 1.4096683673469388\n",
      "Iteration 589000 reward: 1.4097453310696095\n",
      "Iteration 590000 reward: 1.409728813559322\n",
      "Iteration 591000 reward: 1.4098037225042301\n",
      "Iteration 592000 reward: 1.4097381756756757\n",
      "Iteration 593000 reward: 1.4097588532883643\n",
      "Iteration 594000 reward: 1.4098148148148149\n",
      "Iteration 595000 reward: 1.409764705882353\n",
      "Iteration 596000 reward: 1.4098070469798658\n",
      "Iteration 597000 reward: 1.4097621440536012\n",
      "Iteration 598000 reward: 1.4097123745819398\n",
      "Iteration 599000 reward: 1.4097312186978297\n",
      "Iteration 600000 reward: 1.40975\n",
      "Iteration 601000 reward: 1.4096821963394344\n",
      "Iteration 602000 reward: 1.4097142857142857\n",
      "Iteration 603000 reward: 1.4097081260364843\n",
      "Iteration 604000 reward: 1.4096937086092716\n",
      "Iteration 605000 reward: 1.4097289256198346\n",
      "Iteration 606000 reward: 1.4097062706270627\n",
      "Iteration 607000 reward: 1.4096935749588138\n",
      "Iteration 608000 reward: 1.4096134868421053\n",
      "Iteration 609000 reward: 1.4096666666666666\n",
      "Iteration 610000 reward: 1.409606557377049\n",
      "Iteration 611000 reward: 1.4095662847790507\n",
      "Iteration 612000 reward: 1.409549019607843\n",
      "Iteration 613000 reward: 1.4095546492659055\n",
      "Iteration 614000 reward: 1.409516286644951\n",
      "Iteration 615000 reward: 1.4095447154471545\n",
      "Iteration 616000 reward: 1.409521103896104\n",
      "Iteration 617000 reward: 1.4095380875202592\n",
      "Iteration 618000 reward: 1.40957928802589\n",
      "Iteration 619000 reward: 1.409573505654281\n",
      "Iteration 620000 reward: 1.4095145161290323\n",
      "Iteration 621000 reward: 1.4094702093397746\n",
      "Iteration 622000 reward: 1.4095289389067525\n",
      "Iteration 623000 reward: 1.4095425361155698\n",
      "Iteration 624000 reward: 1.4095192307692308\n",
      "Iteration 625000 reward: 1.4095168\n",
      "Iteration 626000 reward: 1.4095031948881789\n",
      "Iteration 627000 reward: 1.4095087719298245\n",
      "Iteration 628000 reward: 1.4094936305732484\n",
      "Iteration 629000 reward: 1.4094753577106518\n",
      "Iteration 630000 reward: 1.4094825396825397\n",
      "Iteration 631000 reward: 1.4094833597464342\n",
      "Iteration 632000 reward: 1.4094572784810127\n",
      "Iteration 633000 reward: 1.4094296998420222\n",
      "Iteration 634000 reward: 1.4094637223974764\n",
      "Iteration 635000 reward: 1.4094771653543308\n",
      "Iteration 636000 reward: 1.4095157232704403\n",
      "Iteration 637000 reward: 1.4094599686028257\n",
      "Iteration 638000 reward: 1.4094310344827585\n",
      "Iteration 639000 reward: 1.4094053208137716\n",
      "Iteration 640000 reward: 1.4093984375\n",
      "Iteration 641000 reward: 1.409446177847114\n",
      "Iteration 642000 reward: 1.4094096573208723\n",
      "Iteration 643000 reward: 1.4094152410575427\n",
      "Iteration 644000 reward: 1.4093944099378881\n",
      "Iteration 645000 reward: 1.409401550387597\n",
      "Iteration 646000 reward: 1.4094318885448915\n",
      "Iteration 647000 reward: 1.4095564142194745\n",
      "Iteration 648000 reward: 1.409513888888889\n",
      "Iteration 649000 reward: 1.4096348228043143\n",
      "Iteration 650000 reward: 1.4096784615384614\n",
      "Iteration 651000 reward: 1.4097665130568355\n",
      "Iteration 652000 reward: 1.4097377300613496\n",
      "Iteration 653000 reward: 1.4096523736600306\n",
      "Iteration 654000 reward: 1.4097262996941895\n",
      "Iteration 655000 reward: 1.4097007633587786\n",
      "Iteration 656000 reward: 1.409623475609756\n",
      "Iteration 657000 reward: 1.4096560121765602\n",
      "Iteration 658000 reward: 1.4096747720364742\n",
      "Iteration 659000 reward: 1.4096722306525038\n",
      "Iteration 660000 reward: 1.409778787878788\n",
      "Iteration 661000 reward: 1.4098396369137671\n",
      "Iteration 662000 reward: 1.4098519637462235\n",
      "Iteration 663000 reward: 1.4099049773755656\n",
      "Iteration 664000 reward: 1.409984939759036\n",
      "Iteration 665000 reward: 1.4100105263157894\n",
      "Iteration 666000 reward: 1.4099864864864864\n",
      "Iteration 667000 reward: 1.4099010494752624\n",
      "Iteration 668000 reward: 1.409880239520958\n",
      "Iteration 669000 reward: 1.4098744394618834\n",
      "Iteration 670000 reward: 1.4098805970149253\n",
      "Iteration 671000 reward: 1.4098897168405364\n",
      "Iteration 672000 reward: 1.4098556547619048\n",
      "Iteration 673000 reward: 1.4099049034175335\n",
      "Iteration 674000 reward: 1.409980712166172\n",
      "Iteration 675000 reward: 1.40992\n",
      "Iteration 676000 reward: 1.409957100591716\n",
      "Iteration 677000 reward: 1.4099394387001478\n",
      "Iteration 678000 reward: 1.4099896755162242\n",
      "Iteration 679000 reward: 1.4099513991163475\n",
      "Iteration 680000 reward: 1.4098264705882353\n",
      "Iteration 681000 reward: 1.4098649045521292\n",
      "Iteration 682000 reward: 1.4098284457478005\n",
      "Iteration 683000 reward: 1.409838945827233\n",
      "Iteration 684000 reward: 1.4099195906432749\n",
      "Iteration 685000 reward: 1.4099372262773722\n",
      "Iteration 686000 reward: 1.409924198250729\n",
      "Iteration 687000 reward: 1.4099170305676856\n",
      "Iteration 688000 reward: 1.4099476744186046\n",
      "Iteration 689000 reward: 1.4099433962264152\n",
      "Iteration 690000 reward: 1.4099144927536231\n",
      "Iteration 691000 reward: 1.4099189580318379\n",
      "Iteration 692000 reward: 1.4099190751445088\n",
      "Iteration 693000 reward: 1.409906204906205\n",
      "Iteration 694000 reward: 1.409958213256484\n",
      "Iteration 695000 reward: 1.4099956834532374\n",
      "Iteration 696000 reward: 1.4099727011494252\n",
      "Iteration 697000 reward: 1.409997130559541\n",
      "Iteration 698000 reward: 1.4100702005730659\n",
      "Iteration 699000 reward: 1.4101316165951359\n",
      "Iteration 700000 reward: 1.4101857142857144\n",
      "Iteration 701000 reward: 1.4101897289586305\n",
      "Iteration 702000 reward: 1.4101851851851852\n",
      "Iteration 703000 reward: 1.410221906116643\n",
      "Iteration 704000 reward: 1.410203125\n",
      "Iteration 705000 reward: 1.410236879432624\n",
      "Iteration 706000 reward: 1.4102832861189802\n",
      "Iteration 707000 reward: 1.4102517680339464\n",
      "Iteration 708000 reward: 1.4102175141242939\n",
      "Iteration 709000 reward: 1.4102849083215796\n",
      "Iteration 710000 reward: 1.4103295774647888\n",
      "Iteration 711000 reward: 1.4102869198312236\n",
      "Iteration 712000 reward: 1.4103103932584269\n",
      "Iteration 713000 reward: 1.4102706872370268\n",
      "Iteration 714000 reward: 1.4103207282913166\n",
      "Iteration 715000 reward: 1.410309090909091\n",
      "Iteration 716000 reward: 1.4102416201117318\n",
      "Iteration 717000 reward: 1.4102663877266388\n",
      "Iteration 718000 reward: 1.4102451253481894\n",
      "Iteration 719000 reward: 1.4102155771905425\n",
      "Iteration 720000 reward: 1.4101458333333334\n",
      "Iteration 721000 reward: 1.4101608876560332\n",
      "Iteration 722000 reward: 1.4101523545706371\n",
      "Iteration 723000 reward: 1.4100746887966804\n",
      "Iteration 724000 reward: 1.4100994475138122\n",
      "Iteration 725000 reward: 1.4100786206896552\n",
      "Iteration 726000 reward: 1.4100013774104683\n",
      "Iteration 727000 reward: 1.4100550206327374\n",
      "Iteration 728000 reward: 1.4100357142857143\n",
      "Iteration 729000 reward: 1.4099410150891631\n",
      "Iteration 730000 reward: 1.4099739726027398\n",
      "Iteration 731000 reward: 1.4099835841313269\n",
      "Iteration 732000 reward: 1.4100232240437158\n",
      "Iteration 733000 reward: 1.4100027285129604\n",
      "Iteration 734000 reward: 1.4100054495912806\n",
      "Iteration 735000 reward: 1.409908843537415\n",
      "Iteration 736000 reward: 1.409904891304348\n",
      "Iteration 737000 reward: 1.4098833107191315\n",
      "Iteration 738000 reward: 1.4098970189701896\n",
      "Iteration 739000 reward: 1.4098890392422192\n",
      "Iteration 740000 reward: 1.4098986486486487\n",
      "Iteration 741000 reward: 1.4098785425101215\n",
      "Iteration 742000 reward: 1.409865229110512\n",
      "Iteration 743000 reward: 1.4098479138627187\n",
      "Iteration 744000 reward: 1.4098682795698925\n",
      "Iteration 745000 reward: 1.4099087248322149\n",
      "Iteration 746000 reward: 1.4100174262734584\n",
      "Iteration 747000 reward: 1.4100870147255689\n",
      "Iteration 748000 reward: 1.4101363636363637\n",
      "Iteration 749000 reward: 1.4101188251001335\n",
      "Iteration 750000 reward: 1.410064\n",
      "Iteration 751000 reward: 1.4100905459387483\n",
      "Iteration 752000 reward: 1.410059840425532\n",
      "Iteration 753000 reward: 1.410163346613546\n",
      "Iteration 754000 reward: 1.4101750663129973\n",
      "Iteration 755000 reward: 1.4101761589403974\n",
      "Iteration 756000 reward: 1.4101613756613756\n",
      "Iteration 757000 reward: 1.410121532364597\n",
      "Iteration 758000 reward: 1.4101002638522429\n",
      "Iteration 759000 reward: 1.410175230566535\n",
      "Iteration 760000 reward: 1.4101855263157894\n",
      "Iteration 761000 reward: 1.4102706964520368\n",
      "Iteration 762000 reward: 1.410257217847769\n",
      "Iteration 763000 reward: 1.4102739187418087\n",
      "Iteration 764000 reward: 1.4102853403141362\n",
      "Iteration 765000 reward: 1.410294117647059\n",
      "Iteration 766000 reward: 1.410364229765013\n",
      "Iteration 767000 reward: 1.4103715775749674\n",
      "Iteration 768000 reward: 1.4103958333333333\n",
      "Iteration 769000 reward: 1.41032899869961\n",
      "Iteration 770000 reward: 1.4103376623376624\n",
      "Iteration 771000 reward: 1.410313878080415\n",
      "Iteration 772000 reward: 1.4103497409326424\n",
      "Iteration 773000 reward: 1.4103505821474773\n",
      "Iteration 774000 reward: 1.4103514211886305\n",
      "Iteration 775000 reward: 1.410334193548387\n",
      "Iteration 776000 reward: 1.4103105670103093\n",
      "Iteration 777000 reward: 1.4102985842985842\n",
      "Iteration 778000 reward: 1.4103187660668381\n",
      "Iteration 779000 reward: 1.4103311938382541\n",
      "Iteration 780000 reward: 1.4103051282051282\n",
      "Iteration 781000 reward: 1.410290653008963\n",
      "Iteration 782000 reward: 1.4102455242966752\n",
      "Iteration 783000 reward: 1.4103052362707535\n",
      "Iteration 784000 reward: 1.410344387755102\n",
      "Iteration 785000 reward: 1.4102955414012739\n",
      "Iteration 786000 reward: 1.4102837150127225\n",
      "Iteration 787000 reward: 1.4102782719186786\n",
      "Iteration 788000 reward: 1.410269035532995\n",
      "Iteration 789000 reward: 1.4102382762991128\n",
      "Iteration 790000 reward: 1.4101569620253165\n",
      "Iteration 791000 reward: 1.4101504424778761\n",
      "Iteration 792000 reward: 1.4101363636363637\n",
      "Iteration 793000 reward: 1.4101941992433795\n",
      "Iteration 794000 reward: 1.410168765743073\n",
      "Iteration 795000 reward: 1.4101333333333332\n",
      "Iteration 796000 reward: 1.4101545226130654\n",
      "Iteration 797000 reward: 1.410138017565872\n",
      "Iteration 798000 reward: 1.4101365914786967\n",
      "Iteration 799000 reward: 1.4101764705882354\n",
      "Iteration 800000 reward: 1.4102125\n",
      "Iteration 801000 reward: 1.4102459425717853\n",
      "Iteration 802000 reward: 1.410213216957606\n",
      "Iteration 803000 reward: 1.4102278953922789\n",
      "Iteration 804000 reward: 1.4102400497512437\n",
      "Iteration 805000 reward: 1.410263354037267\n",
      "Iteration 806000 reward: 1.410259305210918\n",
      "Iteration 807000 reward: 1.4103035935563817\n",
      "Iteration 808000 reward: 1.4102400990099009\n",
      "Iteration 809000 reward: 1.410310259579728\n",
      "Iteration 810000 reward: 1.4103049382716049\n",
      "Iteration 811000 reward: 1.410299630086313\n",
      "Iteration 812000 reward: 1.4102820197044335\n",
      "Iteration 813000 reward: 1.410279212792128\n",
      "Iteration 814000 reward: 1.4103083538083538\n",
      "Iteration 815000 reward: 1.4103386503067485\n",
      "Iteration 816000 reward: 1.4103762254901961\n",
      "Iteration 817000 reward: 1.410435740514076\n",
      "Iteration 818000 reward: 1.4104217603911982\n",
      "Iteration 819000 reward: 1.4104505494505495\n",
      "Iteration 820000 reward: 1.4104731707317073\n",
      "Iteration 821000 reward: 1.4104299634591961\n",
      "Iteration 822000 reward: 1.4104270072992702\n",
      "Iteration 823000 reward: 1.4103803159173756\n",
      "Iteration 824000 reward: 1.410384708737864\n",
      "Iteration 825000 reward: 1.4104109090909092\n",
      "Iteration 826000 reward: 1.4103861985472155\n",
      "Iteration 827000 reward: 1.4104244256348246\n",
      "Iteration 828000 reward: 1.4104541062801932\n",
      "Iteration 829000 reward: 1.4103872135102533\n",
      "Iteration 830000 reward: 1.4103614457831326\n",
      "Iteration 831000 reward: 1.4103417569193744\n",
      "Iteration 832000 reward: 1.4103185096153845\n",
      "Iteration 833000 reward: 1.4103313325330131\n",
      "Iteration 834000 reward: 1.41031654676259\n",
      "Iteration 835000 reward: 1.410336526946108\n",
      "Iteration 836000 reward: 1.4103516746411484\n",
      "Iteration 837000 reward: 1.4103751493428913\n",
      "Iteration 838000 reward: 1.4104140811455848\n",
      "Iteration 839000 reward: 1.410435041716329\n",
      "Iteration 840000 reward: 1.4104642857142857\n",
      "Iteration 841000 reward: 1.4103816884661118\n",
      "Iteration 842000 reward: 1.4103479809976247\n",
      "Iteration 843000 reward: 1.4103107947805458\n",
      "Iteration 844000 reward: 1.4103530805687203\n",
      "Iteration 845000 reward: 1.4103704142011835\n",
      "Iteration 846000 reward: 1.4103676122931441\n",
      "Iteration 847000 reward: 1.4104144037780402\n",
      "Iteration 848000 reward: 1.4103997641509434\n",
      "Iteration 849000 reward: 1.4104228504122498\n",
      "Iteration 850000 reward: 1.410464705882353\n",
      "Iteration 851000 reward: 1.410475910693302\n",
      "Iteration 852000 reward: 1.4104718309859154\n",
      "Iteration 853000 reward: 1.4105134818288394\n",
      "Iteration 854000 reward: 1.4105046838407493\n",
      "Iteration 855000 reward: 1.410536842105263\n",
      "Iteration 856000 reward: 1.4105408878504673\n",
      "Iteration 857000 reward: 1.4105449241540258\n",
      "Iteration 858000 reward: 1.410532634032634\n",
      "Iteration 859000 reward: 1.4105715948777648\n",
      "Iteration 860000 reward: 1.4105651162790698\n",
      "Iteration 861000 reward: 1.4105354239256678\n",
      "Iteration 862000 reward: 1.4105185614849187\n",
      "Iteration 863000 reward: 1.4104820393974506\n",
      "Iteration 864000 reward: 1.4104907407407408\n",
      "Iteration 865000 reward: 1.4105017341040462\n",
      "Iteration 866000 reward: 1.4104688221709007\n",
      "Iteration 867000 reward: 1.4104221453287198\n",
      "Iteration 868000 reward: 1.410421658986175\n",
      "Iteration 869000 reward: 1.410409666283084\n",
      "Iteration 870000 reward: 1.410364367816092\n",
      "Iteration 871000 reward: 1.4104236509758898\n",
      "Iteration 872000 reward: 1.4104701834862385\n",
      "Iteration 873000 reward: 1.4104627720504008\n",
      "Iteration 874000 reward: 1.410433638443936\n",
      "Iteration 875000 reward: 1.4104217142857143\n",
      "Iteration 876000 reward: 1.410406392694064\n",
      "Iteration 877000 reward: 1.4103728620296465\n",
      "Iteration 878000 reward: 1.4103849658314351\n",
      "Iteration 879000 reward: 1.4103811149032992\n",
      "Iteration 880000 reward: 1.4104113636363635\n",
      "Iteration 881000 reward: 1.410360953461975\n",
      "Iteration 882000 reward: 1.4103956916099774\n",
      "Iteration 883000 reward: 1.4104043035107587\n",
      "Iteration 884000 reward: 1.4104004524886877\n",
      "Iteration 885000 reward: 1.4104101694915254\n",
      "Iteration 886000 reward: 1.4103792325056432\n",
      "Iteration 887000 reward: 1.4104047350620068\n",
      "Iteration 888000 reward: 1.4104403153153153\n",
      "Iteration 889000 reward: 1.4104161979752532\n",
      "Iteration 890000 reward: 1.4103865168539327\n",
      "Iteration 891000 reward: 1.4104219977553312\n",
      "Iteration 892000 reward: 1.410372197309417\n",
      "Iteration 893000 reward: 1.4103751399776037\n",
      "Iteration 894000 reward: 1.4104463087248322\n",
      "Iteration 895000 reward: 1.4103899441340781\n",
      "Iteration 896000 reward: 1.4104129464285715\n",
      "Iteration 897000 reward: 1.410366778149387\n",
      "Iteration 898000 reward: 1.4103385300668152\n",
      "Iteration 899000 reward: 1.4103982202447163\n",
      "Iteration 900000 reward: 1.4104533333333333\n",
      "Iteration 901000 reward: 1.4104472807991122\n",
      "Iteration 902000 reward: 1.4104833702882484\n",
      "Iteration 903000 reward: 1.4105083056478405\n",
      "Iteration 904000 reward: 1.4105530973451328\n",
      "Iteration 905000 reward: 1.4104828729281769\n",
      "Iteration 906000 reward: 1.4104459161147902\n",
      "Iteration 907000 reward: 1.4104454244762954\n",
      "Iteration 908000 reward: 1.4104140969162995\n",
      "Iteration 909000 reward: 1.4104246424642464\n",
      "Iteration 910000 reward: 1.4104076923076923\n",
      "Iteration 911000 reward: 1.4104127332601537\n",
      "Iteration 912000 reward: 1.410419956140351\n",
      "Iteration 913000 reward: 1.4104644030668128\n",
      "Iteration 914000 reward: 1.4104781181619257\n",
      "Iteration 915000 reward: 1.4104786885245901\n",
      "Iteration 916000 reward: 1.4104486899563318\n",
      "Iteration 917000 reward: 1.4104830970556161\n",
      "Iteration 918000 reward: 1.4105032679738563\n",
      "Iteration 919000 reward: 1.410544069640914\n",
      "Iteration 920000 reward: 1.4104804347826088\n",
      "Iteration 921000 reward: 1.4104896851248643\n",
      "Iteration 922000 reward: 1.4105010845986985\n",
      "Iteration 923000 reward: 1.410537378114843\n",
      "Iteration 924000 reward: 1.4105876623376623\n",
      "Iteration 925000 reward: 1.4105816216216216\n",
      "Iteration 926000 reward: 1.4105539956803457\n",
      "Iteration 927000 reward: 1.4105631067961164\n",
      "Iteration 928000 reward: 1.410581896551724\n",
      "Iteration 929000 reward: 1.4105662002152852\n",
      "Iteration 930000 reward: 1.410620430107527\n",
      "Iteration 931000 reward: 1.4106197636949516\n",
      "Iteration 932000 reward: 1.4106255364806868\n",
      "Iteration 933000 reward: 1.4106709539121114\n",
      "Iteration 934000 reward: 1.4106820128479658\n",
      "Iteration 935000 reward: 1.4107433155080213\n",
      "Iteration 936000 reward: 1.4108055555555556\n",
      "Iteration 937000 reward: 1.4108335112059764\n",
      "Iteration 938000 reward: 1.410817697228145\n",
      "Iteration 939000 reward: 1.4107859424920128\n",
      "Iteration 940000 reward: 1.4107606382978723\n",
      "Iteration 941000 reward: 1.4107693942614241\n",
      "Iteration 942000 reward: 1.4108046709129511\n",
      "Iteration 943000 reward: 1.4108176033934252\n",
      "Iteration 944000 reward: 1.4107976694915254\n",
      "Iteration 945000 reward: 1.410810582010582\n",
      "Iteration 946000 reward: 1.4108805496828754\n",
      "Iteration 947000 reward: 1.4108078141499472\n",
      "Iteration 948000 reward: 1.410762658227848\n",
      "Iteration 949000 reward: 1.4107713382507903\n",
      "Iteration 950000 reward: 1.4108178947368422\n",
      "Iteration 951000 reward: 1.4107875920084123\n",
      "Iteration 952000 reward: 1.410799369747899\n",
      "Iteration 953000 reward: 1.4108016789087094\n",
      "Iteration 954000 reward: 1.410820754716981\n",
      "Iteration 955000 reward: 1.4108157068062828\n",
      "Iteration 956000 reward: 1.4108033472803347\n",
      "Iteration 957000 reward: 1.4107826541274817\n",
      "Iteration 958000 reward: 1.410793319415449\n",
      "Iteration 959000 reward: 1.4108143899895724\n",
      "Iteration 960000 reward: 1.4108114583333333\n",
      "Iteration 961000 reward: 1.410840790842872\n",
      "Iteration 962000 reward: 1.4108264033264033\n",
      "Iteration 963000 reward: 1.4108691588785047\n",
      "Iteration 964000 reward: 1.4108672199170125\n",
      "Iteration 965000 reward: 1.4108901554404145\n",
      "Iteration 966000 reward: 1.4108840579710145\n",
      "Iteration 967000 reward: 1.4108862461220268\n",
      "Iteration 968000 reward: 1.4108853305785123\n",
      "Iteration 969000 reward: 1.4109195046439629\n",
      "Iteration 970000 reward: 1.4109463917525773\n",
      "Iteration 971000 reward: 1.4109268795056642\n",
      "Iteration 972000 reward: 1.410937242798354\n",
      "Iteration 973000 reward: 1.4109599177800616\n",
      "Iteration 974000 reward: 1.4109229979466118\n",
      "Iteration 975000 reward: 1.4109805128205128\n",
      "Iteration 976000 reward: 1.410983606557377\n",
      "Iteration 977000 reward: 1.410951893551689\n",
      "Iteration 978000 reward: 1.4109703476482618\n",
      "Iteration 979000 reward: 1.4109754851889684\n",
      "Iteration 980000 reward: 1.4109744897959184\n",
      "Iteration 981000 reward: 1.4109255861365952\n",
      "Iteration 982000 reward: 1.4109307535641549\n",
      "Iteration 983000 reward: 1.410942014242116\n",
      "Iteration 984000 reward: 1.4109786585365853\n",
      "Iteration 985000 reward: 1.410994923857868\n",
      "Iteration 986000 reward: 1.410949290060852\n",
      "Iteration 987000 reward: 1.4110385005065855\n",
      "Iteration 988000 reward: 1.4110344129554655\n",
      "Iteration 989000 reward: 1.4110222446916076\n",
      "Iteration 990000 reward: 1.4110131313131313\n",
      "Iteration 991000 reward: 1.4109677093844601\n",
      "Iteration 992000 reward: 1.4109798387096775\n",
      "Iteration 993000 reward: 1.4110070493454179\n",
      "Iteration 994000 reward: 1.4109889336016097\n",
      "Iteration 995000 reward: 1.410953768844221\n",
      "Iteration 996000 reward: 1.410913654618474\n",
      "Iteration 997000 reward: 1.4108726178535607\n",
      "Iteration 998000 reward: 1.4108867735470942\n",
      "Iteration 999000 reward: 1.4109279279279279\n",
      "Iteration 1000000 reward: 1.410916\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Standard deep q network\n",
    "\n",
    "from dqn import DQN\n",
    "\n",
    "dqn = DQN(dueling=False)\n",
    "dqn.learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training dqn model with nu = 0.65, nu_p = [0.5, 0.3, 0.2]\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "csv/dqn_3W.csv already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 08:40:52.281447: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-20 08:40:52.281809: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-11-20 08:40:52.474692: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-11-20 08:40:52.531272: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 08:40:54.364731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.3665\n",
      "Iteration 3000 reward: 0.36833333333333335\n",
      "Iteration 4000 reward: 0.379\n",
      "Iteration 5000 reward: 0.3824\n",
      "Iteration 6000 reward: 0.3938333333333333\n",
      "Iteration 7000 reward: 0.4044285714285714\n",
      "Iteration 8000 reward: 0.418875\n",
      "Iteration 9000 reward: 0.434\n",
      "Iteration 10000 reward: 0.4436\n",
      "Iteration 11000 reward: 0.4521818181818182\n",
      "Iteration 12000 reward: 0.459\n",
      "Iteration 13000 reward: 0.46253846153846156\n",
      "Iteration 14000 reward: 0.4655714285714286\n",
      "Iteration 15000 reward: 0.47213333333333335\n",
      "Iteration 16000 reward: 0.47525\n",
      "Iteration 17000 reward: 0.4838235294117647\n",
      "Iteration 18000 reward: 0.49016666666666664\n",
      "Iteration 19000 reward: 0.49315789473684213\n",
      "Iteration 20000 reward: 0.49735\n",
      "Iteration 21000 reward: 0.5005238095238095\n",
      "Iteration 22000 reward: 0.5028636363636364\n",
      "Iteration 23000 reward: 0.5061304347826087\n",
      "Iteration 24000 reward: 0.5094583333333333\n",
      "Iteration 25000 reward: 0.51212\n",
      "Iteration 26000 reward: 0.5153076923076924\n",
      "Iteration 27000 reward: 0.5172592592592593\n",
      "Iteration 28000 reward: 0.5187142857142857\n",
      "Iteration 29000 reward: 0.5207241379310344\n",
      "Iteration 30000 reward: 0.5224333333333333\n",
      "Iteration 31000 reward: 0.5224193548387097\n",
      "Iteration 32000 reward: 0.52334375\n",
      "Iteration 33000 reward: 0.5266969696969697\n",
      "Iteration 34000 reward: 0.5283529411764706\n",
      "Iteration 35000 reward: 0.5286571428571428\n",
      "Iteration 36000 reward: 0.5288055555555555\n",
      "Iteration 37000 reward: 0.5325945945945946\n",
      "Iteration 38000 reward: 0.5337894736842105\n",
      "Iteration 39000 reward: 0.5355641025641026\n",
      "Iteration 40000 reward: 0.53775\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with nu = 0.5, nu_p = [0.6, 0.2, 0.2]\n",
      "csv/dqn_4W.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 09:14:50.702405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 09:14:56.441976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.4695\n",
      "Iteration 3000 reward: 0.48333333333333334\n",
      "Iteration 4000 reward: 0.491\n",
      "Iteration 5000 reward: 0.5132\n",
      "Iteration 6000 reward: 0.5278333333333334\n",
      "Iteration 7000 reward: 0.5418571428571428\n",
      "Iteration 8000 reward: 0.560875\n",
      "Iteration 9000 reward: 0.5734444444444444\n",
      "Iteration 10000 reward: 0.5841\n",
      "Iteration 11000 reward: 0.5903636363636363\n",
      "Iteration 12000 reward: 0.60125\n",
      "Iteration 13000 reward: 0.6093076923076923\n",
      "Iteration 14000 reward: 0.6184285714285714\n",
      "Iteration 15000 reward: 0.626\n",
      "Iteration 16000 reward: 0.6351875\n",
      "Iteration 17000 reward: 0.6438823529411765\n",
      "Iteration 18000 reward: 0.6502777777777777\n",
      "Iteration 19000 reward: 0.6511578947368422\n",
      "Iteration 20000 reward: 0.6554\n",
      "Iteration 21000 reward: 0.6603333333333333\n",
      "Iteration 22000 reward: 0.665409090909091\n",
      "Iteration 23000 reward: 0.6715217391304348\n",
      "Iteration 24000 reward: 0.6754166666666667\n",
      "Iteration 25000 reward: 0.67988\n",
      "Iteration 26000 reward: 0.681076923076923\n",
      "Iteration 27000 reward: 0.6848888888888889\n",
      "Iteration 28000 reward: 0.6861785714285714\n",
      "Iteration 29000 reward: 0.6889310344827586\n",
      "Iteration 30000 reward: 0.6923\n",
      "Iteration 31000 reward: 0.6963870967741935\n",
      "Iteration 32000 reward: 0.70071875\n",
      "Iteration 33000 reward: 0.704030303030303\n",
      "Iteration 34000 reward: 0.7065\n",
      "Iteration 35000 reward: 0.7097714285714286\n",
      "Iteration 36000 reward: 0.7114444444444444\n",
      "Iteration 37000 reward: 0.7122162162162162\n",
      "Iteration 38000 reward: 0.7138421052631579\n",
      "Iteration 39000 reward: 0.716\n",
      "Iteration 40000 reward: 0.717025\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with nu = 0.4, nu_p = [0.55, 0.25, 0.2]\n",
      "csv/dqn_5W.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 09:48:38.899851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 09:48:41.461855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.5505\n",
      "Iteration 3000 reward: 0.567\n",
      "Iteration 4000 reward: 0.58725\n",
      "Iteration 5000 reward: 0.6042\n",
      "Iteration 6000 reward: 0.6248333333333334\n",
      "Iteration 7000 reward: 0.6428571428571429\n",
      "Iteration 8000 reward: 0.668\n",
      "Iteration 9000 reward: 0.6802222222222222\n",
      "Iteration 10000 reward: 0.6955\n",
      "Iteration 11000 reward: 0.7069090909090909\n",
      "Iteration 12000 reward: 0.72275\n",
      "Iteration 13000 reward: 0.7313076923076923\n",
      "Iteration 14000 reward: 0.7442142857142857\n",
      "Iteration 15000 reward: 0.7528666666666667\n",
      "Iteration 16000 reward: 0.763375\n",
      "Iteration 17000 reward: 0.7729411764705882\n",
      "Iteration 18000 reward: 0.7795\n",
      "Iteration 19000 reward: 0.7887368421052632\n",
      "Iteration 20000 reward: 0.7968\n",
      "Iteration 21000 reward: 0.8012380952380952\n",
      "Iteration 22000 reward: 0.8075454545454546\n",
      "Iteration 23000 reward: 0.8151304347826087\n",
      "Iteration 24000 reward: 0.8197916666666667\n",
      "Iteration 25000 reward: 0.82528\n",
      "Iteration 26000 reward: 0.8307692307692308\n",
      "Iteration 27000 reward: 0.8350740740740741\n",
      "Iteration 28000 reward: 0.83975\n",
      "Iteration 29000 reward: 0.8459310344827586\n",
      "Iteration 30000 reward: 0.8502\n",
      "Iteration 31000 reward: 0.852741935483871\n",
      "Iteration 32000 reward: 0.855375\n",
      "Iteration 33000 reward: 0.8613636363636363\n",
      "Iteration 34000 reward: 0.863\n",
      "Iteration 35000 reward: 0.8664571428571428\n",
      "Iteration 36000 reward: 0.8706944444444444\n",
      "Iteration 37000 reward: 0.8736486486486487\n",
      "Iteration 38000 reward: 0.8778421052631579\n",
      "Iteration 39000 reward: 0.8829743589743589\n",
      "Iteration 40000 reward: 0.884975\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with nu = 0.3, nu_p = [0.5, 0.3, 0.2]\n",
      "csv/dqn_6W.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 10:21:05.102663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 10:21:17.371655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.6105\n",
      "Iteration 3000 reward: 0.6266666666666667\n",
      "Iteration 4000 reward: 0.66475\n",
      "Iteration 5000 reward: 0.6944\n",
      "Iteration 6000 reward: 0.7243333333333334\n",
      "Iteration 7000 reward: 0.7451428571428571\n",
      "Iteration 8000 reward: 0.760625\n",
      "Iteration 9000 reward: 0.7841111111111111\n",
      "Iteration 10000 reward: 0.802\n",
      "Iteration 11000 reward: 0.8194545454545454\n",
      "Iteration 12000 reward: 0.83875\n",
      "Iteration 13000 reward: 0.855\n",
      "Iteration 14000 reward: 0.8679285714285714\n",
      "Iteration 15000 reward: 0.8825333333333333\n",
      "Iteration 16000 reward: 0.897625\n",
      "Iteration 17000 reward: 0.9135882352941177\n",
      "Iteration 18000 reward: 0.9259444444444445\n",
      "Iteration 19000 reward: 0.9374736842105263\n",
      "Iteration 20000 reward: 0.9467\n",
      "Iteration 21000 reward: 0.9530952380952381\n",
      "Iteration 22000 reward: 0.9631818181818181\n",
      "Iteration 23000 reward: 0.9742608695652174\n",
      "Iteration 24000 reward: 0.982\n",
      "Iteration 25000 reward: 0.98912\n",
      "Iteration 26000 reward: 0.9949230769230769\n",
      "Iteration 27000 reward: 1.0007037037037037\n",
      "Iteration 28000 reward: 1.0065\n",
      "Iteration 29000 reward: 1.0123103448275863\n",
      "Iteration 30000 reward: 1.0190333333333332\n",
      "Iteration 31000 reward: 1.0253870967741936\n",
      "Iteration 32000 reward: 1.02953125\n",
      "Iteration 33000 reward: 1.0339090909090909\n",
      "Iteration 34000 reward: 1.0379117647058824\n",
      "Iteration 35000 reward: 1.0424285714285715\n",
      "Iteration 36000 reward: 1.0451666666666666\n",
      "Iteration 37000 reward: 1.0484324324324323\n",
      "Iteration 38000 reward: 1.0512368421052631\n",
      "Iteration 39000 reward: 1.0551025641025642\n",
      "Iteration 40000 reward: 1.058375\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with nu = 0.2, nu_p = [0.45, 0.35, 0.2]\n",
      "csv/dqn_7W.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 10:55:03.385258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 10:55:07.173811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.6765\n",
      "Iteration 3000 reward: 0.698\n",
      "Iteration 4000 reward: 0.73325\n",
      "Iteration 5000 reward: 0.7784\n",
      "Iteration 6000 reward: 0.8086666666666666\n",
      "Iteration 7000 reward: 0.8404285714285714\n",
      "Iteration 8000 reward: 0.8655\n",
      "Iteration 9000 reward: 0.8908888888888888\n",
      "Iteration 10000 reward: 0.9153\n",
      "Iteration 11000 reward: 0.9358181818181818\n",
      "Iteration 12000 reward: 0.95425\n",
      "Iteration 13000 reward: 0.9733846153846154\n",
      "Iteration 14000 reward: 0.9948571428571429\n",
      "Iteration 15000 reward: 1.011\n",
      "Iteration 16000 reward: 1.027375\n",
      "Iteration 17000 reward: 1.0422352941176471\n",
      "Iteration 18000 reward: 1.0562222222222222\n",
      "Iteration 19000 reward: 1.0691052631578948\n",
      "Iteration 20000 reward: 1.08085\n",
      "Iteration 21000 reward: 1.0934285714285714\n",
      "Iteration 22000 reward: 1.1055454545454546\n",
      "Iteration 23000 reward: 1.1178260869565217\n",
      "Iteration 24000 reward: 1.1281666666666668\n",
      "Iteration 25000 reward: 1.13636\n",
      "Iteration 26000 reward: 1.1445769230769232\n",
      "Iteration 27000 reward: 1.152962962962963\n",
      "Iteration 28000 reward: 1.161\n",
      "Iteration 29000 reward: 1.1703103448275862\n",
      "Iteration 30000 reward: 1.1756333333333333\n",
      "Iteration 31000 reward: 1.183258064516129\n",
      "Iteration 32000 reward: 1.189375\n",
      "Iteration 33000 reward: 1.195030303030303\n",
      "Iteration 34000 reward: 1.199529411764706\n",
      "Iteration 35000 reward: 1.2060285714285714\n",
      "Iteration 36000 reward: 1.2114444444444445\n",
      "Iteration 37000 reward: 1.2171351351351352\n",
      "Iteration 38000 reward: 1.2208947368421053\n",
      "Iteration 39000 reward: 1.2247948717948718\n",
      "Iteration 40000 reward: 1.228875\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with nu = 0.15, nu_p = [0.4, 0.3, 0.3]\n",
      "csv/dqn_8W.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 11:30:07.835548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 11:30:13.900022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.7305\n",
      "Iteration 3000 reward: 0.771\n",
      "Iteration 4000 reward: 0.81775\n",
      "Iteration 5000 reward: 0.8616\n",
      "Iteration 6000 reward: 0.8905\n",
      "Iteration 7000 reward: 0.928\n",
      "Iteration 8000 reward: 0.9725\n",
      "Iteration 9000 reward: 1.0037777777777779\n",
      "Iteration 10000 reward: 1.0356\n",
      "Iteration 11000 reward: 1.0665454545454545\n",
      "Iteration 12000 reward: 1.08275\n",
      "Iteration 13000 reward: 1.106153846153846\n",
      "Iteration 14000 reward: 1.1251428571428572\n",
      "Iteration 15000 reward: 1.1454666666666666\n",
      "Iteration 16000 reward: 1.165625\n",
      "Iteration 17000 reward: 1.1832352941176472\n",
      "Iteration 18000 reward: 1.1993333333333334\n",
      "Iteration 19000 reward: 1.2167368421052631\n",
      "Iteration 20000 reward: 1.23195\n",
      "Iteration 21000 reward: 1.2464285714285714\n",
      "Iteration 22000 reward: 1.2611363636363637\n",
      "Iteration 23000 reward: 1.2732608695652174\n",
      "Iteration 24000 reward: 1.285625\n",
      "Iteration 25000 reward: 1.29612\n",
      "Iteration 26000 reward: 1.3077307692307691\n",
      "Iteration 27000 reward: 1.3157037037037036\n",
      "Iteration 28000 reward: 1.3261785714285714\n",
      "Iteration 29000 reward: 1.3334137931034482\n",
      "Iteration 30000 reward: 1.3423\n",
      "Iteration 31000 reward: 1.3501935483870968\n",
      "Iteration 32000 reward: 1.35540625\n",
      "Iteration 33000 reward: 1.3635757575757577\n",
      "Iteration 34000 reward: 1.371264705882353\n",
      "Iteration 35000 reward: 1.3782\n",
      "Iteration 36000 reward: 1.383\n",
      "Iteration 37000 reward: 1.3881351351351352\n",
      "Iteration 38000 reward: 1.392736842105263\n",
      "Iteration 39000 reward: 1.3972820512820512\n",
      "Iteration 40000 reward: 1.401225\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with nu = 0.1, nu_p = [0.4, 0.2, 0.4]\n",
      "csv/dqn_9W.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 12:04:03.974668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 12:04:07.080916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.708\n",
      "Iteration 3000 reward: 0.773\n",
      "Iteration 4000 reward: 0.80725\n",
      "Iteration 5000 reward: 0.87\n",
      "Iteration 6000 reward: 0.9176666666666666\n",
      "Iteration 7000 reward: 0.966\n",
      "Iteration 8000 reward: 1.0125\n",
      "Iteration 9000 reward: 1.0497777777777777\n",
      "Iteration 10000 reward: 1.0911\n",
      "Iteration 11000 reward: 1.1257272727272727\n",
      "Iteration 12000 reward: 1.1568333333333334\n",
      "Iteration 13000 reward: 1.1874615384615386\n",
      "Iteration 14000 reward: 1.2126428571428571\n",
      "Iteration 15000 reward: 1.2360666666666666\n",
      "Iteration 16000 reward: 1.255625\n",
      "Iteration 17000 reward: 1.278\n",
      "Iteration 18000 reward: 1.2992222222222223\n",
      "Iteration 19000 reward: 1.3167368421052632\n",
      "Iteration 20000 reward: 1.33475\n",
      "Iteration 21000 reward: 1.3505714285714285\n",
      "Iteration 22000 reward: 1.3655\n",
      "Iteration 23000 reward: 1.3822173913043478\n",
      "Iteration 24000 reward: 1.3959166666666667\n",
      "Iteration 25000 reward: 1.40728\n",
      "Iteration 26000 reward: 1.4188076923076922\n",
      "Iteration 27000 reward: 1.430925925925926\n",
      "Iteration 28000 reward: 1.4416071428571429\n",
      "Iteration 29000 reward: 1.451758620689655\n",
      "Iteration 30000 reward: 1.4614333333333334\n",
      "Iteration 31000 reward: 1.4703870967741937\n",
      "Iteration 32000 reward: 1.480125\n",
      "Iteration 33000 reward: 1.4867575757575757\n",
      "Iteration 34000 reward: 1.4946470588235294\n",
      "Iteration 35000 reward: 1.5027714285714286\n",
      "Iteration 36000 reward: 1.5103888888888888\n",
      "Iteration 37000 reward: 1.517027027027027\n",
      "Iteration 38000 reward: 1.5236052631578947\n",
      "Iteration 39000 reward: 1.5297435897435898\n",
      "Iteration 40000 reward: 1.536625\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from jammer_power import *\n",
    "from dqn import DQN\n",
    "\n",
    "for i in range(2, 9):\n",
    "    power = list_nu_p[i]\n",
    "    print('Start training dqn model with nu = ' + str(power.nu) + ', nu_p = ' + str(power.nu_p))\n",
    "    \n",
    "    model = DQN(dueling=False, T=40_000)\n",
    "    model.set_custom_mode(mode=2)\n",
    "    model.env.set_jammer_power(nu=power.nu, nu_p=power.nu_p)\n",
    "    model.learning()\n",
    "    model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training dqn model with d_t = 3 packages\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "csv/dqn_dt_3.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 15:49:25.435087: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-20 15:49:25.435171: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-11-20 15:49:25.604714: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-11-20 15:49:25.638887: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 15:49:30.564163: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.633\n",
      "Iteration 3000 reward: 0.6646666666666666\n",
      "Iteration 4000 reward: 0.70775\n",
      "Iteration 5000 reward: 0.7402\n",
      "Iteration 6000 reward: 0.775\n",
      "Iteration 7000 reward: 0.81\n",
      "Iteration 8000 reward: 0.84075\n",
      "Iteration 9000 reward: 0.8707777777777778\n",
      "Iteration 10000 reward: 0.8984\n",
      "Iteration 11000 reward: 0.9209090909090909\n",
      "Iteration 12000 reward: 0.9479166666666666\n",
      "Iteration 13000 reward: 0.9672307692307692\n",
      "Iteration 14000 reward: 0.9882857142857143\n",
      "Iteration 15000 reward: 1.0034\n",
      "Iteration 16000 reward: 1.0224375\n",
      "Iteration 17000 reward: 1.0351176470588235\n",
      "Iteration 18000 reward: 1.0511666666666666\n",
      "Iteration 19000 reward: 1.065\n",
      "Iteration 20000 reward: 1.0772\n",
      "Iteration 21000 reward: 1.0896666666666666\n",
      "Iteration 22000 reward: 1.1030909090909091\n",
      "Iteration 23000 reward: 1.1145652173913043\n",
      "Iteration 24000 reward: 1.1253333333333333\n",
      "Iteration 25000 reward: 1.13624\n",
      "Iteration 26000 reward: 1.1458461538461537\n",
      "Iteration 27000 reward: 1.1555185185185186\n",
      "Iteration 28000 reward: 1.1665714285714286\n",
      "Iteration 29000 reward: 1.1739310344827587\n",
      "Iteration 30000 reward: 1.1815666666666667\n",
      "Iteration 31000 reward: 1.188225806451613\n",
      "Iteration 32000 reward: 1.19471875\n",
      "Iteration 33000 reward: 1.2010606060606062\n",
      "Iteration 34000 reward: 1.2063529411764706\n",
      "Iteration 35000 reward: 1.2125142857142857\n",
      "Iteration 36000 reward: 1.2175277777777778\n",
      "Iteration 37000 reward: 1.2239459459459459\n",
      "Iteration 38000 reward: 1.2295526315789473\n",
      "Iteration 39000 reward: 1.2347948717948718\n",
      "Iteration 40000 reward: 1.23945\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with d_t = 4 packages\n",
      "csv/dqn_dt_4.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 16:23:43.610598: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 16:23:51.644897: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.626\n",
      "Iteration 3000 reward: 0.6723333333333333\n",
      "Iteration 4000 reward: 0.722\n",
      "Iteration 5000 reward: 0.7466\n",
      "Iteration 6000 reward: 0.7858333333333334\n",
      "Iteration 7000 reward: 0.8167142857142857\n",
      "Iteration 8000 reward: 0.847375\n",
      "Iteration 9000 reward: 0.8674444444444445\n",
      "Iteration 10000 reward: 0.8931\n",
      "Iteration 11000 reward: 0.9134545454545454\n",
      "Iteration 12000 reward: 0.9409166666666666\n",
      "Iteration 13000 reward: 0.9614615384615385\n",
      "Iteration 14000 reward: 0.9793571428571428\n",
      "Iteration 15000 reward: 0.9996\n",
      "Iteration 16000 reward: 1.0186875\n",
      "Iteration 17000 reward: 1.0374117647058823\n",
      "Iteration 18000 reward: 1.055\n",
      "Iteration 19000 reward: 1.0695263157894737\n",
      "Iteration 20000 reward: 1.08075\n",
      "Iteration 21000 reward: 1.0931904761904763\n",
      "Iteration 22000 reward: 1.1078181818181818\n",
      "Iteration 23000 reward: 1.1184347826086956\n",
      "Iteration 24000 reward: 1.1295\n",
      "Iteration 25000 reward: 1.13688\n",
      "Iteration 26000 reward: 1.1476923076923078\n",
      "Iteration 27000 reward: 1.1572222222222222\n",
      "Iteration 28000 reward: 1.167\n",
      "Iteration 29000 reward: 1.1734827586206897\n",
      "Iteration 30000 reward: 1.181\n",
      "Iteration 31000 reward: 1.1869032258064516\n",
      "Iteration 32000 reward: 1.1929375\n",
      "Iteration 33000 reward: 1.2007272727272726\n",
      "Iteration 34000 reward: 1.2073823529411765\n",
      "Iteration 35000 reward: 1.2132285714285713\n",
      "Iteration 36000 reward: 1.2193888888888889\n",
      "Iteration 37000 reward: 1.2252432432432432\n",
      "Iteration 38000 reward: 1.2305526315789475\n",
      "Iteration 39000 reward: 1.2341794871794871\n",
      "Iteration 40000 reward: 1.239325\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with d_t = 5 packages\n",
      "csv/dqn_dt_5.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 16:58:23.015629: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 16:58:26.438230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.64\n",
      "Iteration 3000 reward: 0.6873333333333334\n",
      "Iteration 4000 reward: 0.7145\n",
      "Iteration 5000 reward: 0.7564\n",
      "Iteration 6000 reward: 0.7938333333333333\n",
      "Iteration 7000 reward: 0.8275714285714286\n",
      "Iteration 8000 reward: 0.857875\n",
      "Iteration 9000 reward: 0.8887777777777778\n",
      "Iteration 10000 reward: 0.9102\n",
      "Iteration 11000 reward: 0.9379090909090909\n",
      "Iteration 12000 reward: 0.95975\n",
      "Iteration 13000 reward: 0.9850769230769231\n",
      "Iteration 14000 reward: 1.0040714285714285\n",
      "Iteration 15000 reward: 1.0231333333333332\n",
      "Iteration 16000 reward: 1.0384375\n",
      "Iteration 17000 reward: 1.0540588235294117\n",
      "Iteration 18000 reward: 1.0707222222222221\n",
      "Iteration 19000 reward: 1.0837894736842106\n",
      "Iteration 20000 reward: 1.09605\n",
      "Iteration 21000 reward: 1.1106666666666667\n",
      "Iteration 22000 reward: 1.1226818181818181\n",
      "Iteration 23000 reward: 1.1334347826086957\n",
      "Iteration 24000 reward: 1.1439583333333334\n",
      "Iteration 25000 reward: 1.15468\n",
      "Iteration 26000 reward: 1.1628846153846153\n",
      "Iteration 27000 reward: 1.172\n",
      "Iteration 28000 reward: 1.1795714285714285\n",
      "Iteration 29000 reward: 1.186793103448276\n",
      "Iteration 30000 reward: 1.1937333333333333\n",
      "Iteration 31000 reward: 1.199741935483871\n",
      "Iteration 32000 reward: 1.2069375\n",
      "Iteration 33000 reward: 1.2133636363636364\n",
      "Iteration 34000 reward: 1.219529411764706\n",
      "Iteration 35000 reward: 1.2246857142857144\n",
      "Iteration 36000 reward: 1.2304166666666667\n",
      "Iteration 37000 reward: 1.2362162162162162\n",
      "Iteration 38000 reward: 1.2413157894736842\n",
      "Iteration 39000 reward: 1.245128205128205\n",
      "Iteration 40000 reward: 1.2504\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with d_t = 6 packages\n",
      "csv/dqn_dt_6.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 17:34:42.841998: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 17:34:46.800411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.657\n",
      "Iteration 3000 reward: 0.6996666666666667\n",
      "Iteration 4000 reward: 0.741\n",
      "Iteration 5000 reward: 0.7766\n",
      "Iteration 6000 reward: 0.8083333333333333\n",
      "Iteration 7000 reward: 0.8387142857142857\n",
      "Iteration 8000 reward: 0.868625\n",
      "Iteration 9000 reward: 0.8928888888888888\n",
      "Iteration 10000 reward: 0.9173\n",
      "Iteration 11000 reward: 0.9405454545454546\n",
      "Iteration 12000 reward: 0.9568333333333333\n",
      "Iteration 13000 reward: 0.9833846153846154\n",
      "Iteration 14000 reward: 0.999\n",
      "Iteration 15000 reward: 1.0168\n",
      "Iteration 16000 reward: 1.0351875\n",
      "Iteration 17000 reward: 1.0531176470588235\n",
      "Iteration 18000 reward: 1.0698333333333334\n",
      "Iteration 19000 reward: 1.0859473684210526\n",
      "Iteration 20000 reward: 1.09985\n",
      "Iteration 21000 reward: 1.1114285714285714\n",
      "Iteration 22000 reward: 1.1237272727272727\n",
      "Iteration 23000 reward: 1.1321739130434783\n",
      "Iteration 24000 reward: 1.1412916666666666\n",
      "Iteration 25000 reward: 1.15084\n",
      "Iteration 26000 reward: 1.1599615384615385\n",
      "Iteration 27000 reward: 1.1683703703703703\n",
      "Iteration 28000 reward: 1.1773214285714286\n",
      "Iteration 29000 reward: 1.1839655172413792\n",
      "Iteration 30000 reward: 1.1910333333333334\n",
      "Iteration 31000 reward: 1.1980967741935484\n",
      "Iteration 32000 reward: 1.20521875\n",
      "Iteration 33000 reward: 1.2107575757575757\n",
      "Iteration 34000 reward: 1.216264705882353\n",
      "Iteration 35000 reward: 1.2217142857142858\n",
      "Iteration 36000 reward: 1.2272222222222222\n",
      "Iteration 37000 reward: 1.2325405405405405\n",
      "Iteration 38000 reward: 1.2382894736842105\n",
      "Iteration 39000 reward: 1.2423333333333333\n",
      "Iteration 40000 reward: 1.247125\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with d_t = 7 packages\n",
      "csv/dqn_dt_7.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 18:09:54.179070: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 18:10:03.710067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.6295\n",
      "Iteration 3000 reward: 0.684\n",
      "Iteration 4000 reward: 0.72575\n",
      "Iteration 5000 reward: 0.7464\n",
      "Iteration 6000 reward: 0.7886666666666666\n",
      "Iteration 7000 reward: 0.829\n",
      "Iteration 8000 reward: 0.856875\n",
      "Iteration 9000 reward: 0.8827777777777778\n",
      "Iteration 10000 reward: 0.9054\n",
      "Iteration 11000 reward: 0.9305454545454546\n",
      "Iteration 12000 reward: 0.96025\n",
      "Iteration 13000 reward: 0.9817692307692307\n",
      "Iteration 14000 reward: 1.0021428571428572\n",
      "Iteration 15000 reward: 1.0228\n",
      "Iteration 16000 reward: 1.0395625\n",
      "Iteration 17000 reward: 1.0536470588235294\n",
      "Iteration 18000 reward: 1.067\n",
      "Iteration 19000 reward: 1.0820526315789474\n",
      "Iteration 20000 reward: 1.0967\n",
      "Iteration 21000 reward: 1.107904761904762\n",
      "Iteration 22000 reward: 1.1203636363636365\n",
      "Iteration 23000 reward: 1.1323478260869566\n",
      "Iteration 24000 reward: 1.1429166666666666\n",
      "Iteration 25000 reward: 1.153\n",
      "Iteration 26000 reward: 1.1627692307692308\n",
      "Iteration 27000 reward: 1.1708518518518518\n",
      "Iteration 28000 reward: 1.1775714285714285\n",
      "Iteration 29000 reward: 1.1857241379310344\n",
      "Iteration 30000 reward: 1.1922666666666666\n",
      "Iteration 31000 reward: 1.1991935483870968\n",
      "Iteration 32000 reward: 1.20646875\n",
      "Iteration 33000 reward: 1.212030303030303\n",
      "Iteration 34000 reward: 1.2176470588235293\n",
      "Iteration 35000 reward: 1.2238571428571428\n",
      "Iteration 36000 reward: 1.2289166666666667\n",
      "Iteration 37000 reward: 1.2344054054054054\n",
      "Iteration 38000 reward: 1.2398684210526316\n",
      "Iteration 39000 reward: 1.2434358974358974\n",
      "Iteration 40000 reward: 1.248\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with d_t = 8 packages\n",
      "csv/dqn_dt_8.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 18:44:15.231286: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 18:44:19.146049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.651\n",
      "Iteration 3000 reward: 0.677\n",
      "Iteration 4000 reward: 0.71675\n",
      "Iteration 5000 reward: 0.7518\n",
      "Iteration 6000 reward: 0.7915\n",
      "Iteration 7000 reward: 0.8245714285714286\n",
      "Iteration 8000 reward: 0.85625\n",
      "Iteration 9000 reward: 0.8827777777777778\n",
      "Iteration 10000 reward: 0.9056\n",
      "Iteration 11000 reward: 0.9323636363636364\n",
      "Iteration 12000 reward: 0.95325\n",
      "Iteration 13000 reward: 0.9773846153846154\n",
      "Iteration 14000 reward: 1.0022857142857142\n",
      "Iteration 15000 reward: 1.0208\n",
      "Iteration 16000 reward: 1.0368125\n",
      "Iteration 17000 reward: 1.054529411764706\n",
      "Iteration 18000 reward: 1.0722777777777779\n",
      "Iteration 19000 reward: 1.0874210526315788\n",
      "Iteration 20000 reward: 1.10175\n",
      "Iteration 21000 reward: 1.1131428571428572\n",
      "Iteration 22000 reward: 1.1244545454545454\n",
      "Iteration 23000 reward: 1.1342608695652174\n",
      "Iteration 24000 reward: 1.144125\n",
      "Iteration 25000 reward: 1.1536\n",
      "Iteration 26000 reward: 1.1627692307692308\n",
      "Iteration 27000 reward: 1.170962962962963\n",
      "Iteration 28000 reward: 1.17875\n",
      "Iteration 29000 reward: 1.1860344827586207\n",
      "Iteration 30000 reward: 1.1939\n",
      "Iteration 31000 reward: 1.2020967741935484\n",
      "Iteration 32000 reward: 1.20909375\n",
      "Iteration 33000 reward: 1.2145757575757576\n",
      "Iteration 34000 reward: 1.2215\n",
      "Iteration 35000 reward: 1.2267714285714286\n",
      "Iteration 36000 reward: 1.2322222222222223\n",
      "Iteration 37000 reward: 1.2367027027027027\n",
      "Iteration 38000 reward: 1.2403421052631578\n",
      "Iteration 39000 reward: 1.2447692307692308\n",
      "Iteration 40000 reward: 1.249\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Start training dqn model with d_t = 9 packages\n",
      "csv/dqn_dt_9.csv created with 2 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 19:18:26.482547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-20 19:18:28.105490: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunghoangtrung125/workspace/personal/graduation_thesis/source_code/util/csv_util.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 reward: 0.6725\n",
      "Iteration 3000 reward: 0.7186666666666667\n",
      "Iteration 4000 reward: 0.75275\n",
      "Iteration 5000 reward: 0.7992\n",
      "Iteration 6000 reward: 0.8336666666666667\n",
      "Iteration 7000 reward: 0.8548571428571429\n",
      "Iteration 8000 reward: 0.884375\n",
      "Iteration 9000 reward: 0.9094444444444445\n",
      "Iteration 10000 reward: 0.9332\n",
      "Iteration 11000 reward: 0.9570909090909091\n",
      "Iteration 12000 reward: 0.9760833333333333\n",
      "Iteration 13000 reward: 0.9957692307692307\n",
      "Iteration 14000 reward: 1.0172142857142856\n",
      "Iteration 15000 reward: 1.0322\n",
      "Iteration 16000 reward: 1.053875\n",
      "Iteration 17000 reward: 1.0688235294117647\n",
      "Iteration 18000 reward: 1.0806666666666667\n",
      "Iteration 19000 reward: 1.0934736842105264\n",
      "Iteration 20000 reward: 1.10535\n",
      "Iteration 21000 reward: 1.118952380952381\n",
      "Iteration 22000 reward: 1.1309545454545455\n",
      "Iteration 23000 reward: 1.1409565217391304\n",
      "Iteration 24000 reward: 1.1507916666666667\n",
      "Iteration 25000 reward: 1.16028\n",
      "Iteration 26000 reward: 1.1686923076923077\n",
      "Iteration 27000 reward: 1.1774074074074075\n",
      "Iteration 28000 reward: 1.1836428571428572\n",
      "Iteration 29000 reward: 1.190655172413793\n",
      "Iteration 30000 reward: 1.1968666666666667\n",
      "Iteration 31000 reward: 1.2025806451612904\n",
      "Iteration 32000 reward: 1.2086875\n",
      "Iteration 33000 reward: 1.2141818181818183\n",
      "Iteration 34000 reward: 1.221\n",
      "Iteration 35000 reward: 1.2265142857142857\n",
      "Iteration 36000 reward: 1.2302777777777778\n",
      "Iteration 37000 reward: 1.2348918918918919\n",
      "Iteration 38000 reward: 1.239236842105263\n",
      "Iteration 39000 reward: 1.2442820512820514\n",
      "Iteration 40000 reward: 1.2483\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Training dqn when vary d_t from 1 to 9\n",
    "from jammer_power import *\n",
    "from dqn import DQN\n",
    "\n",
    "for i in range(3, 10):\n",
    "    print('Start training dqn model with d_t = ' + str(i) + ' packages')\n",
    "    \n",
    "    model = DQN(dueling=False, T=40_000)\n",
    "    model.set_custom_mode(mode=1)\n",
    "    model.set_active_transmission_packages(d_t=i)\n",
    "    model.learning()\n",
    "    model.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
