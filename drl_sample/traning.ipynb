{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mddqn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQN\n\u001b[0;32m      5\u001b[0m deep_q_model \u001b[38;5;241m=\u001b[39m DQN(dueling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mdeep_q_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\workspace\\personal\\python\\graduation_thesis\\drl_sample\\ddqn.py:127\u001b[0m, in \u001b[0;36mDQN.learning\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremember(current_state, action, reward, next_state)\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# append rewards for plot graph\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(total_reward \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\workspace\\personal\\python\\graduation_thesis\\drl_sample\\ddqn.py:81\u001b[0m, in \u001b[0;36mDQN.replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m reward_sample \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_history[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m     80\u001b[0m next_state_sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_state_history[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices])\u001b[38;5;241m.\u001b[39mreshape((batch_size, num_features))\n\u001b[1;32m---> 81\u001b[0m future_rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m updated_q_values \u001b[38;5;241m=\u001b[39m reward_sample \u001b[38;5;241m+\u001b[39m gamma_deepQ \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_max(future_rewards, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     83\u001b[0m masks \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(action_sample, num_actions)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1720\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1716\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiWorkerDistributionStrategy or TPUStrategy and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1717\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoShardPolicy.FILE might lead to out-of-order result\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1718\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1720\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1383\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1382\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1138\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1137\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:320\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    318\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 320\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1903\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, map_func):\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m \n\u001b[0;32m   1873\u001b[0m \u001b[38;5;124;03m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1901\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   1902\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1903\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5062\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   5060\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5061\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m-> 5062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5065\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5066\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`map_func` must return a `Dataset` object. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   5067\u001b[0m           \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)))\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4218\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4211\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   4212\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4213\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4214\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4215\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4216\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m-> 4218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4219\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3150\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3142\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   3143\u001b[0m \n\u001b[0;32m   3144\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3148\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   3149\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3150\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   3151\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3152\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3116\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3114\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3116\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3117\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   3118\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   3119\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4195\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4189\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m   4190\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m   4191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m   4192\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   4193\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m   4194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m-> 4195\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4196\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m   4197\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4125\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m   4124\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m-> 4125\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m   4127\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:382\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 382\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:463\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    460\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:309\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    305\u001b[0m first_k_indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mslice(indices, [\u001b[38;5;241m0\u001b[39m], [num_in_full_batch])\n\u001b[0;32m    306\u001b[0m first_k_indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m    307\u001b[0m     first_k_indices, [num_full_batches, batch_size])\n\u001b[1;32m--> 309\u001b[0m flat_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_k_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_batch_size:\n\u001b[0;32m    311\u001b[0m   index_remainder \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensors(tf\u001b[38;5;241m.\u001b[39mslice(\n\u001b[0;32m    312\u001b[0m       indices, [num_in_full_batch], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_batch_size]))\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:685\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors):\n\u001b[0;32m    610\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[0;32m    611\u001b[0m \n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 685\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3856\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3852\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m   3853\u001b[0m   batch_dim\u001b[38;5;241m.\u001b[39massert_is_compatible_with(tensor_shape\u001b[38;5;241m.\u001b[39mDimension(\n\u001b[0;32m   3854\u001b[0m       tensor_shape\u001b[38;5;241m.\u001b[39mdimension_value(t\u001b[38;5;241m.\u001b[39mget_shape()[\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m-> 3856\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_slice_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3858\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3859\u001b[0m \u001b[38;5;28msuper\u001b[39m(TensorSliceDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:7126\u001b[0m, in \u001b[0;36mtensor_slice_dataset\u001b[1;34m(components, output_shapes, name)\u001b[0m\n\u001b[0;32m   7122\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   7123\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected list for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7124\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor_slice_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Op, not \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m output_shapes)\n\u001b[0;32m   7125\u001b[0m output_shapes \u001b[38;5;241m=\u001b[39m [_execute\u001b[38;5;241m.\u001b[39mmake_shape(_s, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _s \u001b[38;5;129;01min\u001b[39;00m output_shapes]\n\u001b[1;32m-> 7126\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7127\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensorSliceDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7128\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7129\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m   7130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    743\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    744\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    746\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    747\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 748\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    597\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    598\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3561\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3558\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3559\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3561\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3562\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3569\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3570\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2041\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2039\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m op_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2040\u001b[0m     op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_get_op_def(node_def\u001b[38;5;241m.\u001b[39mop)\n\u001b[1;32m-> 2041\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2042\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2043\u001b[0m   name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traceback \u001b[38;5;241m=\u001b[39m tf_stack\u001b[38;5;241m.\u001b[39mextract_stack_for_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op)\n",
      "File \u001b[1;32mc:\\Users\\dungh\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1880\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1876\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1877\u001b[0m                                          serialized)\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1880\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1882\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Standard deep q network\n",
    "\n",
    "from ddqn import DQN\n",
    "\n",
    "dqn = DQN(dueling=False)\n",
    "dqn.learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.661\n",
      "Iteration 2000 reward: 0.6855\n",
      "Iteration 3000 reward: 0.741\n",
      "Iteration 4000 reward: 0.775\n",
      "Iteration 5000 reward: 0.8108\n",
      "Iteration 6000 reward: 0.8408333333333333\n",
      "Iteration 7000 reward: 0.876\n",
      "Iteration 8000 reward: 0.90325\n",
      "Iteration 9000 reward: 0.928\n",
      "Iteration 10000 reward: 0.9517\n",
      "Iteration 11000 reward: 0.9726363636363636\n",
      "Iteration 12000 reward: 0.98875\n",
      "Iteration 13000 reward: 1.0057692307692307\n",
      "Iteration 14000 reward: 1.0246428571428572\n",
      "Iteration 15000 reward: 1.0400666666666667\n",
      "Iteration 16000 reward: 1.058875\n",
      "Iteration 17000 reward: 1.0735294117647058\n",
      "Iteration 18000 reward: 1.0891111111111111\n",
      "Iteration 19000 reward: 1.1010526315789473\n",
      "Iteration 20000 reward: 1.113\n",
      "Iteration 21000 reward: 1.1235714285714287\n",
      "Iteration 22000 reward: 1.1347727272727273\n",
      "Iteration 23000 reward: 1.144304347826087\n",
      "Iteration 24000 reward: 1.1529583333333333\n",
      "Iteration 25000 reward: 1.1614\n",
      "Iteration 26000 reward: 1.1698076923076923\n",
      "Iteration 27000 reward: 1.1776666666666666\n",
      "Iteration 28000 reward: 1.1845\n",
      "Iteration 29000 reward: 1.1904137931034482\n",
      "Iteration 30000 reward: 1.1965666666666666\n",
      "Iteration 31000 reward: 1.203741935483871\n",
      "Iteration 32000 reward: 1.2109375\n",
      "Iteration 33000 reward: 1.2175757575757575\n",
      "Iteration 34000 reward: 1.2238529411764707\n",
      "Iteration 35000 reward: 1.2298857142857142\n",
      "Iteration 36000 reward: 1.2356111111111112\n",
      "Iteration 37000 reward: 1.2386216216216217\n",
      "Iteration 38000 reward: 1.244184210526316\n",
      "Iteration 39000 reward: 1.247923076923077\n",
      "Iteration 40000 reward: 1.25285\n",
      "Iteration 41000 reward: 1.256170731707317\n",
      "Iteration 42000 reward: 1.260190476190476\n",
      "Iteration 43000 reward: 1.2642558139534883\n",
      "Iteration 44000 reward: 1.2679318181818182\n",
      "Iteration 45000 reward: 1.2714666666666667\n",
      "Iteration 46000 reward: 1.274391304347826\n",
      "Iteration 47000 reward: 1.277404255319149\n",
      "Iteration 48000 reward: 1.2809791666666666\n",
      "Iteration 49000 reward: 1.2838367346938775\n",
      "Iteration 50000 reward: 1.28704\n",
      "Iteration 51000 reward: 1.2903725490196079\n",
      "Iteration 52000 reward: 1.293346153846154\n",
      "Iteration 53000 reward: 1.2961509433962264\n",
      "Iteration 54000 reward: 1.2986111111111112\n",
      "Iteration 55000 reward: 1.3005272727272728\n",
      "Iteration 56000 reward: 1.3025892857142858\n",
      "Iteration 57000 reward: 1.3046140350877193\n",
      "Iteration 58000 reward: 1.3073793103448277\n",
      "Iteration 59000 reward: 1.309542372881356\n",
      "Iteration 60000 reward: 1.3114833333333333\n",
      "Iteration 61000 reward: 1.312983606557377\n",
      "Iteration 62000 reward: 1.3144354838709678\n",
      "Iteration 63000 reward: 1.317079365079365\n",
      "Iteration 64000 reward: 1.31909375\n",
      "Iteration 65000 reward: 1.3205692307692307\n",
      "Iteration 66000 reward: 1.3216969696969696\n",
      "Iteration 67000 reward: 1.3227164179104478\n",
      "Iteration 68000 reward: 1.3243235294117648\n",
      "Iteration 69000 reward: 1.3255652173913044\n",
      "Iteration 70000 reward: 1.326342857142857\n",
      "Iteration 71000 reward: 1.3275915492957746\n",
      "Iteration 72000 reward: 1.3290416666666667\n",
      "Iteration 73000 reward: 1.330095890410959\n",
      "Iteration 74000 reward: 1.3313378378378378\n",
      "Iteration 75000 reward: 1.33232\n",
      "Iteration 76000 reward: 1.3336184210526316\n",
      "Iteration 77000 reward: 1.3347662337662338\n",
      "Iteration 78000 reward: 1.335974358974359\n",
      "Iteration 79000 reward: 1.3371645569620254\n",
      "Iteration 80000 reward: 1.33815\n",
      "Iteration 81000 reward: 1.339888888888889\n",
      "Iteration 82000 reward: 1.3400975609756098\n",
      "Iteration 83000 reward: 1.3408915662650602\n",
      "Iteration 84000 reward: 1.341702380952381\n",
      "Iteration 85000 reward: 1.3432823529411764\n",
      "Iteration 86000 reward: 1.3442790697674418\n",
      "Iteration 87000 reward: 1.3450344827586207\n",
      "Iteration 88000 reward: 1.3453068181818182\n",
      "Iteration 89000 reward: 1.346438202247191\n",
      "Iteration 90000 reward: 1.3467777777777779\n",
      "Iteration 91000 reward: 1.3472417582417582\n",
      "Iteration 92000 reward: 1.3484239130434783\n",
      "Iteration 93000 reward: 1.3496451612903226\n",
      "Iteration 94000 reward: 1.3504893617021276\n",
      "Iteration 95000 reward: 1.3512947368421053\n",
      "Iteration 96000 reward: 1.3521145833333332\n",
      "Iteration 97000 reward: 1.3530927835051547\n",
      "Iteration 98000 reward: 1.3541938775510205\n",
      "Iteration 99000 reward: 1.3550909090909091\n",
      "Iteration 100000 reward: 1.35567\n",
      "Iteration 101000 reward: 1.3560198019801981\n",
      "Iteration 102000 reward: 1.3567058823529412\n",
      "Iteration 103000 reward: 1.3570970873786408\n",
      "Iteration 104000 reward: 1.3579807692307693\n",
      "Iteration 105000 reward: 1.358809523809524\n",
      "Iteration 106000 reward: 1.3601981132075471\n",
      "Iteration 107000 reward: 1.3608971962616823\n",
      "Iteration 108000 reward: 1.361175925925926\n",
      "Iteration 109000 reward: 1.361559633027523\n",
      "Iteration 110000 reward: 1.3620818181818182\n",
      "Iteration 111000 reward: 1.3627747747747747\n",
      "Iteration 112000 reward: 1.363767857142857\n",
      "Iteration 113000 reward: 1.3642035398230088\n",
      "Iteration 114000 reward: 1.3646929824561405\n",
      "Iteration 115000 reward: 1.365104347826087\n",
      "Iteration 116000 reward: 1.3654137931034482\n",
      "Iteration 117000 reward: 1.366\n",
      "Iteration 118000 reward: 1.3665338983050848\n",
      "Iteration 119000 reward: 1.3672016806722689\n",
      "Iteration 120000 reward: 1.3679916666666667\n",
      "Iteration 121000 reward: 1.368289256198347\n",
      "Iteration 122000 reward: 1.368672131147541\n",
      "Iteration 123000 reward: 1.3690243902439025\n",
      "Iteration 124000 reward: 1.3695967741935484\n",
      "Iteration 125000 reward: 1.370008\n",
      "Iteration 126000 reward: 1.3707063492063492\n",
      "Iteration 127000 reward: 1.371047244094488\n",
      "Iteration 128000 reward: 1.371390625\n",
      "Iteration 129000 reward: 1.3719767441860464\n",
      "Iteration 130000 reward: 1.3724153846153846\n",
      "Iteration 131000 reward: 1.3729847328244276\n",
      "Iteration 132000 reward: 1.3734848484848485\n",
      "Iteration 133000 reward: 1.3740075187969925\n",
      "Iteration 134000 reward: 1.3744477611940298\n",
      "Iteration 135000 reward: 1.3752222222222221\n",
      "Iteration 136000 reward: 1.375845588235294\n",
      "Iteration 137000 reward: 1.3762773722627737\n",
      "Iteration 138000 reward: 1.377144927536232\n",
      "Iteration 139000 reward: 1.377525179856115\n",
      "Iteration 140000 reward: 1.3779142857142856\n",
      "Iteration 141000 reward: 1.3781347517730496\n",
      "Iteration 142000 reward: 1.3784014084507041\n",
      "Iteration 143000 reward: 1.3784825174825175\n",
      "Iteration 144000 reward: 1.3787083333333334\n",
      "Iteration 145000 reward: 1.3791862068965517\n",
      "Iteration 146000 reward: 1.3795890410958904\n",
      "Iteration 147000 reward: 1.379843537414966\n",
      "Iteration 148000 reward: 1.3800202702702702\n",
      "Iteration 149000 reward: 1.3804697986577181\n",
      "Iteration 150000 reward: 1.3808666666666667\n",
      "Iteration 151000 reward: 1.3810264900662252\n",
      "Iteration 152000 reward: 1.381467105263158\n",
      "Iteration 153000 reward: 1.381908496732026\n",
      "Iteration 154000 reward: 1.381974025974026\n",
      "Iteration 155000 reward: 1.3823548387096773\n",
      "Iteration 156000 reward: 1.382903846153846\n",
      "Iteration 157000 reward: 1.3832738853503184\n",
      "Iteration 158000 reward: 1.3834936708860759\n",
      "Iteration 159000 reward: 1.3833962264150943\n",
      "Iteration 160000 reward: 1.38383125\n",
      "Iteration 161000 reward: 1.384360248447205\n",
      "Iteration 162000 reward: 1.384530864197531\n",
      "Iteration 163000 reward: 1.3848220858895706\n",
      "Iteration 164000 reward: 1.385091463414634\n",
      "Iteration 165000 reward: 1.3854181818181819\n",
      "Iteration 166000 reward: 1.3858192771084337\n",
      "Iteration 167000 reward: 1.3863173652694611\n",
      "Iteration 168000 reward: 1.3867857142857143\n",
      "Iteration 169000 reward: 1.387260355029586\n",
      "Iteration 170000 reward: 1.3875823529411764\n",
      "Iteration 171000 reward: 1.388111111111111\n",
      "Iteration 172000 reward: 1.388453488372093\n",
      "Iteration 173000 reward: 1.388520231213873\n",
      "Iteration 174000 reward: 1.3885344827586208\n",
      "Iteration 175000 reward: 1.3885885714285715\n",
      "Iteration 176000 reward: 1.3885738636363636\n",
      "Iteration 177000 reward: 1.3887514124293785\n",
      "Iteration 178000 reward: 1.3889044943820226\n",
      "Iteration 179000 reward: 1.3888324022346368\n",
      "Iteration 180000 reward: 1.389338888888889\n",
      "Iteration 181000 reward: 1.3893922651933701\n",
      "Iteration 182000 reward: 1.3894835164835164\n",
      "Iteration 183000 reward: 1.3896448087431694\n",
      "Iteration 184000 reward: 1.3899619565217392\n",
      "Iteration 185000 reward: 1.3902\n",
      "Iteration 186000 reward: 1.3902849462365592\n",
      "Iteration 187000 reward: 1.390235294117647\n",
      "Iteration 188000 reward: 1.3905\n",
      "Iteration 189000 reward: 1.3906560846560847\n",
      "Iteration 190000 reward: 1.3908315789473684\n",
      "Iteration 191000 reward: 1.390958115183246\n",
      "Iteration 192000 reward: 1.3908645833333333\n",
      "Iteration 193000 reward: 1.391020725388601\n",
      "Iteration 194000 reward: 1.3910309278350514\n",
      "Iteration 195000 reward: 1.3913487179487178\n",
      "Iteration 196000 reward: 1.3914948979591837\n",
      "Iteration 197000 reward: 1.3916852791878171\n",
      "Iteration 198000 reward: 1.3916818181818182\n",
      "Iteration 199000 reward: 1.3918844221105529\n",
      "Iteration 200000 reward: 1.392265\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Traning ddqn network\n",
    "from ddqn import DQN\n",
    "\n",
    "ddqn = DQN(dueling=True)\n",
    "ddqn.learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import numpy as np\n",
    "\n",
    "deep_q_model.model.save('model/dqn.keras')\n",
    "np.save('model/deep_q_matrix.npy', deep_q_model.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAHFCAYAAADrBB1NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABN/klEQVR4nO3deXQUVf7+8ac7nXRCSEICISFsBhVFowhEIQijgICguA+4Ai7zExVRARfEEXCcwXHAQR2BcUbhq+MgorgNuIQdBVQgbIIosgQhAUHIBlm6+/7+CClpkmA6JKkkvF/n9DlVt291fXJpTj/n1u1qhzHGCAAAABXitLsAAACAuoTwBAAAEADCEwAAQAAITwAAAAEgPAEAAASA8AQAABAAwhMAAEAACE8AAAABIDwBAAAEgPAEVLGZM2fK4XBYD5fLpWbNmunmm2/WDz/8YHd5VeaMM87Q0KFDq+z1tmzZoqFDh6pVq1YKCQlRkyZN1L9/f33yySdVdo6qdPy/8YmPyo5LVY9pRZS8X3fu3Fmj5wXqMpfdBQD11YwZM3TuuecqPz9fX375pf785z9r8eLF+u677xQdHW13ebXK3Llzdeutt6pNmzb64x//qHPOOUf79u3TjBkz1L9/fz366KN6/vnn7S6zlJtuukmjRo0q1R4bG1up13v//fcVGRl5qmUBqGaEJ6CaJCUlKTk5WZJ0+eWXy+v1aty4cfrggw9055132lzdbzty5IgaNGhQ7ef58ccfdccdd+iCCy7QkiVLFB4ebj33+9//Xvfdd5/+9re/qWPHjrr55purvZ4SRUVF1sxheeLi4tSlS5cqO2eHDh2q7LUAVB8u2wE1pCRI7du3z6999erVuuaaaxQTE6PQ0FB16NBB77zzjvV8dna2XC6X/va3v1ltBw4ckNPpVFRUlDwej9U+YsQIxcbGquT3vlNTU3XttdeqRYsWCg0N1VlnnaV7771XBw4c8Kth/PjxcjgcWrt2rW666SZFR0frzDPPlFQcIh577DHFx8erQYMG6tatm77++utSf9+RI0c0evRoJSYmKjQ0VDExMUpOTtasWbNOOi5///vfdeTIEb388st+wanE5MmT1ahRI/35z3+WJK1fv14Oh0OvvfZaqb6ffPKJHA6HPvroI6vthx9+0K233qqmTZvK7XarXbt2euWVV/yOW7JkiRwOh958802NGjVKzZs3l9vt1rZt205ae0UMHTpUDRs21LfffqtevXopPDxcsbGxGj58uI4cOeLX98TLdj6fT88++6zOOecchYWFqVGjRrrwwgv14osv+h33xRdfqFevXoqIiFCDBg3UtWtXzZs3r1Qtq1at0qWXXqrQ0FAlJCRozJgxKioqKrPu2bNnKyUlReHh4WrYsKH69u2rtLQ0vz7bt2/XzTffrISEBLndbsXFxalXr15at25d5QYLqCMIT0AN2bFjhySpbdu2VtvixYt16aWX6vDhw5o+fbo+/PBDXXTRRRo0aJBmzpwpSYqMjNTFF1+sBQsWWMctXLhQbrdbOTk5fkFmwYIF6tmzpxwOh6TiWZ2UlBRNmzZNn3/+uZ5++ml99dVX6tatW5kfmjfccIPOOusszZkzR9OnT5ck/eEPf9CkSZM0ePBgffjhh7rxxht1ww036NChQ37Hjhw5UtOmTdOIESP06aef6s0339Tvf/97HTx48KTjkpqaetIZnAYNGqhPnz7atGmTMjMz1b59e3Xo0EEzZswo1XfmzJlq2rSp+vfvL0navHmzLr74Ym3atEmTJ0/W//73P1111VUaMWKEJkyYUOr4MWPGKD09XdOnT9fHH3+spk2bnrR2Y4w8Hk+pR0l4LVFUVKT+/furV69e+uCDDzR8+HD985//1KBBg076+s8//7zGjx+vW265RfPmzdPs2bN199136/Dhw1afpUuXqmfPnsrKytJrr72mWbNmKSIiQgMGDNDs2bOtfps3b1avXr10+PBhzZw5U9OnT1daWpqeffbZUuf9y1/+oltuuUXnnXee3nnnHb355pvKyclR9+7dtXnzZqtf//79tWbNGj3//PNKTU3VtGnT1KFDB7/6gHrJAKhSM2bMMJLMqlWrTFFRkcnJyTGffvqpiY+PN7/73e9MUVGR1ffcc881HTp08Gszxpirr77aNGvWzHi9XmOMMU899ZQJCwsz+fn5xhhj7rnnHnPllVeaCy+80EyYMMEYY8yePXuMJPPqq6+WWZfP5zNFRUVm165dRpL58MMPrefGjRtnJJmnn37a75gtW7YYSeaRRx7xa3/rrbeMJDNkyBCrLSkpyVx33XUBjpYxoaGhpkuXLift8/jjjxtJ5quvvjLGGPPSSy8ZSWbr1q1Wn19++cW43W4zatQoq61v376mRYsWJisry+/1hg8fbkJDQ80vv/xijDFm8eLFRpL53e9+V+G6JZX7ePPNN61+Q4YMMZLMiy++6Hf8n//8ZyPJfPHFF1Zb69at/cb06quvNhdddNFJ6+jSpYtp2rSpycnJsdo8Ho9JSkoyLVq0MD6fzxhjzKBBg0xYWJjJzMz063fuuecaSWbHjh3GGGPS09ONy+UyDz74oN95cnJyTHx8vBk4cKAxxpgDBw4YSWbKlCkVGC2gfmHmCagmXbp0UXBwsCIiInTllVcqOjpaH374obWGZtu2bfruu+902223SZLfzEX//v2VkZGhrVu3SpJ69eqlo0ePasWKFZKKZ5h69+6tK664QqmpqVabJF1xxRVWDfv379ewYcPUsmVLuVwuBQcHq3Xr1pKKv912ohtvvNFvf/HixZJk1Vhi4MCBpdYCXXLJJfrkk0/0xBNPaMmSJTp69GglRq1s5thMTsmM2m233Sa3223NzknSrFmzVFBQYK0ny8/P18KFC3X99derQYMGpcY3Pz9fq1at8jvPiX//bxk4cKC++eabUo+Sma/jnTiGt956q6Rfx7gsl1xyidavX6/7779fn332mbKzs/2ez8vL01dffaWbbrpJDRs2tNqDgoJ0xx136KeffrLeQ4sXL1avXr0UFxfn1+/E2a/PPvtMHo9HgwcP9huz0NBQXXbZZVqyZIkkKSYmRmeeeab+9re/6YUXXlBaWpp8Pl8FRg2o+whPQDV544039M0332jRokW69957tWXLFt1yyy3W8yVrn0aPHq3g4GC/x/333y9J1tqkrl27qkGDBlqwYIG2bdumnTt3WuHpq6++Um5urhYsWKA2bdooMTFRUvF6mT59+mju3Ll67LHHtHDhQn399ddWYCgr3DRr1sxvv+SSW3x8vF+7y+VS48aN/dpeeuklPf744/rggw/Uo0cPxcTE6LrrrvvN2zO0atXKuqRZnpKv0bds2VJS8Qf3NddcozfeeENer1dS8SW7Sy65ROeff75Vu8fj0csvv1xqfEvCzYlrv078+39LbGyskpOTSz1iYmL8+pU1XiVjerLLmmPGjNGkSZO0atUq9evXT40bN1avXr20evVqSdKhQ4dkjCmz7oSEBL/XP3jwYKl/x+PrKFHyvrz44otLjdvs2bOtMXM4HFq4cKH69u2r559/Xh07dlRsbKxGjBihnJyc8gcNqAf4th1QTdq1a2ctEu/Ro4e8Xq/+/e9/691339VNN92kJk2aSCr+gLzhhhvKfI1zzjlHkhQSEqJu3bppwYIFatGiheLj43XBBReoTZs2kooXPC9cuFBXX321deymTZu0fv16zZw5U0OGDLHaT7YIumRmp0TJB35mZqaaN29utXs8nlIf+uHh4ZowYYImTJigffv2WbNQAwYM0HfffVfuOXv37q1XXnlFq1atKnPd05EjR5SamqqkpCS/D/o777xTc+bMUWpqqlq1aqVvvvlG06ZNs56Pjo62ZmAeeOCBMs9dEjTL+/urSsl4HR+gMjMzJalUqDqey+XSyJEjNXLkSB0+fFgLFizQk08+qb59+2r37t2Kjo6W0+lURkZGqWP37t0rSdb7rHHjxtY5j3diW0n/d99915qlLE/r1q2thfvff/+93nnnHY0fP16FhYXWmjmgXrL7uiFQ35Ssefrmm2/82n/55RcTHR1t2rVrZ61lOvvss03//v0r9LrPP/+8CQoKMr169TK333671d69e3fTp08fI8m88847VvuGDRuMJDNr1iy/1xk9erSRZMaNG2e1lax5+vnnn/36bt68ucJrnsry8MMPG0kmLy+v3D7btm0zYWFhJjk52eTm5pZ6/r777jOSzNtvv+3X7vF4TPPmzc3AgQPN6NGjTWhoqDl8+LBfnyuuuMK0b9/eFBQUnLTOkjVPc+bMOWm/40kyDzzwwG/2+601T8uXL7faTlzzVJYpU6YYSebbb781xhiTkpJi4uPjzZEjR6w+Xq/XXHDBBZVa87Rjxw7jcrnMX//619/828py0UUXmYsvvrhSxwJ1BTNPQA2Jjo7WmDFj9Nhjj+m///2vbr/9dv3zn/9Uv3791LdvXw0dOlTNmzfXL7/8oi1btmjt2rWaM2eOdXyvXr3k9Xq1cOFC/d///Z/VfsUVV2jcuHFyOBzq2bOn1X7uuefqzDPP1BNPPCFjjGJiYvTxxx9ba6Qqol27drr99ts1ZcoUBQcH64orrtCmTZs0adKkUjdz7Ny5s66++mpdeOGFio6O1pYtW/Tmm28qJSXlpPeLOvPMM/Xmm2/qtttu08UXX6yRI0daN8l8/fXX9cknn2j06NGl1uYEBQVp8ODBeuGFFxQZGakbbrhBUVFRfn1efPFFdevWTd27d9d9992nM844Qzk5Odq2bZs+/vhjLVq0qMJjUZZ9+/aVWjclFX9D8rzzzrP2Q0JCNHnyZOXm5uriiy/WihUr9Oyzz6pfv37q1q1bua8/YMAA635hsbGx2rVrl6ZMmaLWrVvr7LPPliRNnDhRvXv3Vo8ePTR69GiFhIRo6tSp2rRpk2bNmmXNpj311FP66KOP1LNnTz399NNq0KCBXnnlFeXl5fmd84wzztAzzzyjsWPHavv27dZ6vX379unrr7+2Zhg3bNig4cOH6/e//73OPvtshYSEaNGiRdqwYYOeeOKJUxpXoNazO70B9U15M0/GGHP06FHTqlUrc/bZZxuPx2OMMWb9+vVm4MCBpmnTpiY4ONjEx8ebnj17munTp/sd6/P5TJMmTYwks2fPHqv9yy+/NJJMx44dS51v8+bNpnfv3iYiIsJER0eb3//+9yY9Pb3CM0/GGFNQUGBGjRplmjZtan0zbuXKlaVmSZ544gmTnJxsoqOjjdvtNm3atDGPPPKIOXDgQIXG7dtvvzVDhgwxLVq0MMHBwSYmJsZceeWVZt68eeUe8/3331vfcEtNTS2zz44dO8xdd91lmjdvboKDg01sbKzp2rWrefbZZ60+lZ15Ku9x6aWXWv2GDBliwsPDzYYNG8zll19uwsLCTExMjLnvvvtKzbSdOKaTJ082Xbt2NU2aNDEhISGmVatW5u677zY7d+70O2758uWmZ8+eJjw83ISFhZkuXbqYjz/+uFTNX375penSpYtxu90mPj7ePProo+bVV1/1m3kq8cEHH5gePXqYyMhI43a7TevWrc1NN91kFixYYIwxZt++fWbo0KHm3HPPNeHh4aZhw4bmwgsvNH//+9+t9zZQXzmMOeGGJACAKjN06FC9++67ys3NtbsUAFWEb9sBAAAEgPAEAAAQAC7bAQAABICZJwAAgAAQngAAAAJAeAIAAAjAaXeTTJ/Pp7179yoiIqLafooBAABULWOMcnJylJCQIKfT3rmf0y487d271/pxUQAAULfs3r1bLVq0sLWG0y48RURESCoe/BN/XgIAANRO2dnZatmypfU5bqfTLjyVXKqLjIwkPAEAUMfUhiU3LBgHAAAIAOEJAAAgAIQnAACAABCeAAAAAkB4AgAACADhCQAAIACEJwAAgAAQngAAAAJAeAIAAAiAreFp2bJlGjBggBISEuRwOPTBBx9U+Ngvv/xSLpdLF110UbXVBwAAcCJbw1NeXp7at2+vf/zjHwEdl5WVpcGDB6tXr17VVBkAAEDZbP1tu379+qlfv34BH3fvvffq1ltvVVBQUECzVQAAAKeqzv0w8IwZM/Tjjz/qP//5j5599tnf7F9QUKCCggJrPzs7uzrLAwCgzjPGyGekIq9PXp+R1xj5fEZen5GRFORwyOGQPD4jp8OhEJdTXp9Rgccrn08KcTkVEx5i959RbepUePrhhx/0xBNPaPny5XK5Klb6xIkTNWHChGquDABQ3Xw+o7xCj4q8Rh6vTx6fUaHHJ0lyBTlkjOQzRkXHnvMee95IcjocKijyymuKP+x9PqN8j1dHCr3y+owkKb/IK69PKvR45XQ65Dh2Xo/PyBXklIyRw+GQ0+GQkVFYcJCCnI7icOEzx4JEcX+fzyi/yCevMQoOcsoYY9UXHORUkNOhIq9PBR6fnA6HCj0+FXq9kqQir7Geyy/0Wn9Lyd9W5C0+j9Ph0NGi4voLvT55vCXP+3SksPhv83h9KvT6FBL06yodp9Oh4CCnPF6fjDk2tsboaJFXx3at9spq0jBEq5/qfWovUovVmfDk9Xp16623asKECWrbtm2FjxszZoxGjhxp7WdnZ6tly5bVUSIA1AklH7AOOVTk8ykn3yOv18jj8/06s1Dy4V5UHD6MKf4Az8n3yOGQ3K4g5Xu8OnykUPlFPhV6fMov8upokVd5BR4dKfSq0OOTw1H8QVzoLT5PgcerIs+v55LDoaOFxf19x0LAsSwjY8yx1ygOFx7fr88hMEXHgllNcDkdcruCaux8dqgz4SknJ0erV69WWlqahg8fLkny+Xwyxsjlcunzzz9Xz549Sx3ndrvldrtrulwAKJfPZ3SkyKsjx0JGdn6RCjzFMwdHCj0KCwlSgcenomOzJnkFHuUWeJR9tMiahfD4jI4UeJSd77FCSqHHp4N5hcXByOGQx+uzZiY83uKZhSOFHuUX+eweglPmcBR/SJfMqBQdm/UJcjjkCnIqOMhhXU5yOGRdSnI5HfIdm30KDQ5SWEiQghzFc0yhwU4FOZ1yBzvl8xXPFDkcxTM1Xm9xavMZY83O5B8b2yBn8bmCj81+ley7g0tmmIprc6h4tqjo2MyUK8ght8sp77Ha3K7iv6WkTrcr6FhNDrmcDjmP/b1BToeMit9HocFBcgUVzyQFBzkU5HQqJMipcHeQGoQEyXXs7ymZoZOKZ8Y83uLzO6Rjs2lSWHCQSqbbHCo+pyvIYf09QU6HdbmuJGQXj6eOveekkCCnHA6HzKlOXdVydSY8RUZGauPGjX5tU6dO1aJFi/Tuu+8qMTHRpsoA1BW+46Ytso4WKbfAo5x8j3Lyi5R3LFSUzJ78uD9PYSFO5RV45XQ4lO/xKvtokaTiMCNJR4u8+jmnQHGRocor8CjE5ZTPFH84FRR55TPFl25yC4oDzvGXk2qb0GCngp1OBR0LHUVen4KDnMUfqMeEuIr3Sy4fBQc5FRocpMbhIcXPhQQpNDhI4SFBCgsOkvu4Y90upxq6XcVh5VgIcDiKP7xLjnM5i8OO89gHtDHF5yw5t8vpUFRYsIKDnMVBxOkQ7OEK+nXsgxxSkNN/psnhqN//NraGp9zcXG3bts3a37Fjh9atW6eYmBi1atVKY8aM0Z49e/TGG2/I6XQqKSnJ7/imTZsqNDS0VDuAusV3bD2H1xgdPXa5x2eKZ1J+zi1QkNOhnPwiNQgJktPhkMdnlFvgUW6+R4ePFCo736OCIq/2ZuXLe+y5rCNFyjk2W3Mwr8B6verw4895lTquJCA0aRiiyNBgq83hKJ6RCA4qnjUJD3GpodulyDCXXEHOY7MrxUGjUViIjhZ5FeF2KTSkOMgEBxXPNAQ5pUYNQo7NIBQHn7DgIEWEuhTicspICg76NcgAqBhbw9Pq1avVo0cPa79kbdKQIUM0c+ZMZWRkKD093a7yAFSAMcWXkFzOXxevFnh8OnykUJszclTo8elAbvE3Xn/Yl6uIUJcOHylUkNOpPYeP6OecgkqHj1MVElQ8WxITHqJwd3GwCA5yKtztUqOwYO3PKVCrmAYKd7uUX+RVZFiwIkNdahDiUpCzeGFvVFiwso4WqVGDYDmPXf4ovmTz60xKRKhLIUHOY5dWnHIFORQe4lJoMKEFqIscpr5fmDxBdna2oqKilJWVpcjISLvLAWodn89oz+Gj+iWvUAUen37OKdB3mdkKCwlSkcfoP1/t0s85BerQqpH2ZeVrb1a+3/FOh055UW/JjMzxGjUIVkSoSz5f8SWDkKDir0a3jGmg2Ai3HJLC3S7FRrgVFRYst8upqLBgNW4YoiYN3QpyFq9xMUbKOlqoljEN6v2iVqA+qU2f33VmzROAyvH5jA7kFSg33yOvzyjraJG27svRhI83q0PLRooKC9bnm/dJkqLCgpVb4KnQmpy09MNln++4Q5s3CpPb5VRik3A5HA7FRrh1+EihWsU0UESoS82iwhQVFqzE2HDFNCi+J0zDUJdcTke1zsjERvAlEgCVR3gC6qAir0/b9udq/e7DOphXqF/yCvWfVbt0QfMouYOd+nLbwQq9zlc7fvHbzzq2IFoq/haNx2d0UctGatQgWNlHi3RG43BtzshW44YhuuWSVoppEKJmjcIUEepSocenyLBguY7dQyaIxbwA6inCE1DLHC30an9OvtLSD8vhKF4nlJNfpAVb9mvP4aMnPXb1rkMnfT4sOEjRDYL9LrX1OrepFn63X/2S4nXtRQlqFROus5o2tL7lBADwR3gCalBegUe7Dx3Rx+v3Ki39sFo3bqDMrHx9vy9XUWHB2pxRuZ8Pigh1KSffo2svSlDbuAg5HNL2n/N0yRkxOi8hUm3jIghDAFBFCE9AFfP5jPbl5OvH/Xka8/4G7f6l/NmiFT/+enmtvFmlnuc2VbOoUDVu6NbXOw7qiX7t1CgsWK0bN+CbWgBgA8ITUEnGGC374YAWf7dfLqdDW/flaPkPBwJ6jR7nxOrQkSLd1S1RYcFBatQgWK1Lvj1GMAKAWonwBPyGIq9PWzNztGlPll7/coe+35cb8Gs80ONMdWnTWG3jIhQXGVoNVQIAagrhCTjGGKPdvxzV4q37Nf7jbwP6VfFr2icoukGwGrhdim3o1i2XtFJYCPcQAoD6iPCE09b2n3M1+fPvtWTrfuUVVuwXx6++sJm+y8xRx1aNdPMlrXRes0iFBhOSAOB0QnjCaWPb/hxd8cKyCvePi3RrwjXnKybcreTW0fwIKQBAEuEJ9VSR16cBL3+h7zJzKtS/U+tonRMfocevPFdRYcHVXB0AoC4jPKFeMMbomf9t1owvd1b4mPkjuuu8BH7fEAAQGMIT6qxCj0+j56zXR+v3Vqj/X2+8QAOTW3ILAADAKSE8oU4xxujCCZ8rJ99Tbp9LEmPUIjpMf7o2SeFu3uIAgKrFJwtqPWOM/jJ/i/61fEe5fS5rG6vnb7qQeygBAKod4Qm11r+Xb9ez87actM/aP/ZWTHhIDVUEAADhCbXQ4+9u0OzVu8t9/puxVyg2wl2DFQEA8CvCE2qFD9ft0UNvryv3+eWP9VDLmAY1VxAAAOUgPME2RV6fzh77SbnPd06M0ex7U2qwIgAAfhvhCTUuMytfXSYuLPf5abd1VL8LmtVgRQAAVBzhCTXmx59z1Wvy0jKfiwx1acP4vjVcEQAAgSM8ododKfTovKc/K/M51jIBAOoawhOqzZ7DR3Xpc4vKfG79uD78hhwAoE4iPKHKGWOUOGZ+mc/tmNifn0cBANRphCdUqTtnfK3FW38u1b7mqSvUuCH3ZgIA1H2EJ1SJuWt/0sh31pdq3zC+jyJDuTwHAKg/CE84JR6vT2eVca+mufd3VcdW0TZUBABA9SI8odJW/nhQt/xrlV/biF5na2TvtjZVBABA9SM8oVLOeGJeqbZtf+4nV5DThmoAAKg5fNIhIP9ZtatUcLrz0jO087mrCE4AgNMCM0+osLJmm7hfEwDgdEN4wm/KyS/SBeM/L9W+87mrbKgGAAB7EZ5wUi8v/EGTU7/3a1s1ppfio0JtqggAAHsRnlCuHpOWaMeBPL82ZpsAAKc7VviiTH3/vswvOPU+L47gBACAmHlCGUbPWa+t+3Ks/QUjf6ezmkbYWBEAALUH4Ql+TvxG3fqn+yiqAd+mAwCghK2X7ZYtW6YBAwYoISFBDodDH3zwwUn7z507V71791ZsbKwiIyOVkpKizz77rGaKPQ08/u4Gv/1lj/YgOAEAcAJbw1NeXp7at2+vf/zjHxXqv2zZMvXu3Vvz58/XmjVr1KNHDw0YMEBpaWnVXGn9d8YT8zR79W5r/4vHe6hV4wY2VgQAQO3kMMYYu4uQJIfDoffff1/XXXddQMedf/75GjRokJ5++ukK9c/OzlZUVJSysrIUGRlZiUrrnyteWKpt+3Ot/TVPXaHGDd02VgQAgL/a9Pldp9c8+Xw+5eTkKCYmptw+BQUFKigosPazs7NrorQ6Y9qSH/2C09djexGcAAA4iTp9q4LJkycrLy9PAwcOLLfPxIkTFRUVZT1atmxZgxXWbt/uzdJfP/3O2k/7Y281jeDmlwAAnEydDU+zZs3S+PHjNXv2bDVt2rTcfmPGjFFWVpb12L17d7l9Tyden9FVL31h7c+482JFh4fYWBEAAHVDnbxsN3v2bN19992aM2eOrrjiipP2dbvdcru5DHWiM5+cb213O6uJepxTfgAFAAC/qnMzT7NmzdLQoUP13//+V1ddxR2vK+PEezn9557ONlUCAEDdY+vMU25urrZt22bt79ixQ+vWrVNMTIxatWqlMWPGaM+ePXrjjTckFQenwYMH68UXX1SXLl2UmZkpSQoLC1NUVJQtf0Ndc2Jw4idXAAAIjK0zT6tXr1aHDh3UoUMHSdLIkSPVoUMH67YDGRkZSk9Pt/r/85//lMfj0QMPPKBmzZpZj4ceesiW+uuaTzdl+u1v+3M/myoBAKDuqjX3eaoptek+ETXt+Fmnb8ZeodgI1oIBAOqG2vT5XefWPKFyjg9Oo3q3JTgBAFBJhKfTwPrdh/32H+x1tj2FAABQDxCe6jljjK595Utrf81TJ7+1AwAAODnCUz2XOObX+zk5HOKnVwAAOEWEp3ps1Dvr/fZ3TOS2BAAAnCrCUz3l9Rm9t/Yna//7Z7ktAQAAVYHwVE8d//MrHw/vphAX/9QAAFQFPlHroS0Z2X77F7Tg7usAAFQVwlM91O/F5db2ar5dBwBAlSI81TMn/nZdE75dBwBAlSI81SMHcgv89vnRXwAAqh7hqR5JfnaBtf3Vk71srAQAgPqL8FRPXPTM5377cZGhNlUCAED9RniqB3w+o8NHiqx9LtcBAFB9CE/1wJljf72n06w/dLGxEgAA6j/CUx1njJExv+6nnNnYvmIAADgNEJ7quJHH/X7d/x7sZmMlAACcHghPddz7aXus7aTm3EkcAIDqRniqw1bv/MXa7nVuUxsrAQDg9EF4qsNumr7S2v7X4GQbKwEA4PRBeKqjFm/d77fvdDpsqgQAgNML4amOunPGN9Y293UCAKDmEJ7qoO8ys63t27u0srESAABOP4SnOujKKcut7T9dm2RjJQAAnH4IT3WMOf6OmJIcDtY6AQBQkwhPdczfF/xgba9/uo+NlQAAcHoiPNUxLy38NTxFNQi2sRIAAE5PhKc6ZGtmjrXdk5tiAgBgC8JTHdJ3yjJr+/WhF9tYCQAApy/CUx1x+Eih3SUAAAARnuqM21/7ytre9ud+NlYCAMDpjfBUR2za8+uNMV1B/LMBAGAXPoXrgBU/HrC2lz/Ww8ZKAAAA4akOuPVfv16yaxnTwMZKAAAA4amW8/rMb3cCAAA1hvBUy5355Hxre/Hoy+0rBAAASCI81Wq/5PnfniCxSbhNlQAAgBK2hqdly5ZpwIABSkhIkMPh0AcffPCbxyxdulSdOnVSaGio2rRpo+nTp1d/oTbp+KdUa3veiG42VgIAAErYGp7y8vLUvn17/eMf/6hQ/x07dqh///7q3r270tLS9OSTT2rEiBF67733qrlS+52fEGV3CQAAQJLLzpP369dP/fpV/IaP06dPV6tWrTRlyhRJUrt27bR69WpNmjRJN954YzVVaY8ff861tt+5N8XGSgAAwPHq1JqnlStXqk+fPn5tffv21erVq1VUVFTmMQUFBcrOzvZ71AW9Ji+1ti9JjLGxEgAAcLw6FZ4yMzMVFxfn1xYXFyePx6MDBw6UeczEiRMVFRVlPVq2bFkTpQIAgHqqToUnSXI4HH77xpgy20uMGTNGWVlZ1mP37t3VXuOpyivwWNvzR3S3sRIAAHAiW9c8BSo+Pl6ZmZl+bfv375fL5VLjxo3LPMbtdsvtdtdEeVXm/HGfWdvtmkXYWAkAADhRnZp5SklJUWpqql/b559/ruTkZAUHB9tUVfUqb0YNAADYw9bwlJubq3Xr1mndunWSim9FsG7dOqWnp0sqvuQ2ePBgq/+wYcO0a9cujRw5Ulu2bNHrr7+u1157TaNHj7aj/GrxycYMa3v67R1trAQAAJTF1st2q1evVo8ePaz9kSNHSpKGDBmimTNnKiMjwwpSkpSYmKj58+frkUce0SuvvKKEhAS99NJL9eo2Bfe9tdbavjKpmY2VAACAstgani6//HJrwXdZZs6cWartsssu09q1a0t3rgc8Xp+1fVvnVjZWAgAAylOn1jzVd/+3cpe1PfaqdjZWAgAAykN4qkX+9L/N1naDkDr1RUgAAE4bhCcAAIAAEJ5qCZ/v17Vfz994oY2VAACAkyE81RL//mK7tX19x+Y2VgIAAE6G8FRL/GX+d9Z2cBD/LAAA1FZ8StcyV7SL++1OAADANoSnWuDwkUJr+/Erz7GxEgAA8FsIT7VAWvpha/vsOH4IGACA2ozwVAt8sG6P3SUAAIAKIjzVAh+u22t3CQAAoIIITwAAAAEgPNls3e7D1vaqMb3sKwQAAFQI4clmbx73Y8DxUaE2VgIAACqC8GSz99b+ZHcJAAAgAISnWiIqLNjuEgAAQAUQnmqJWy5pZXcJAACgAghPNsrOL7K2h3RtbWMlAACgoghPNrpw/OfWdnwki8UBAKgLCE+1hMPhsLsEAABQAYQnAACAABCebHKk0GNt/2twso2VAACAQBCebDJn9a/3d+p9XpyNlQAAgEAQnmwy7qNv7S4BAABUAuHJZpefE2t3CQAAIACEJ5uN6n2O3SUAAIAAEJ5s8NOhI9b2GU0a2FgJAAAIFOHJBt3+utjajgjlN+0AAKhLCE8AAAABIDzZ4Jy4CEnSS7d0sLkSAAAQKMJTDcvJL9L3+3MkSSltGttcDQAACBThqYatTT8sY4p/CDg2wm13OQAAIECEpxr2yuJtkqTQYIYeAIC6iE/wGna00CtJants3RMAAKhbCE817Idj650GtE+wuRIAAFAZhKca5PMZ5Rf5JEmNG4bYXA0AAKgMwlMN+jm3wNru2CraxkoAAEBl2R6epk6dqsTERIWGhqpTp05avnz5Sfu/9dZbat++vRo0aKBmzZrpzjvv1MGDB2uo2lPz3tqfrO3Q4CAbKwEAAJVla3iaPXu2Hn74YY0dO1ZpaWnq3r27+vXrp/T09DL7f/HFFxo8eLDuvvtuffvtt5ozZ46++eYb3XPPPTVceeVMW/yj3SUAAIBTZGt4euGFF3T33XfrnnvuUbt27TRlyhS1bNlS06ZNK7P/qlWrdMYZZ2jEiBFKTExUt27ddO+992r16tU1XHnl5BR47C4BAACcItvCU2FhodasWaM+ffr4tffp00crVqwo85iuXbvqp59+0vz582WM0b59+/Tuu+/qqquuKvc8BQUFys7O9nvY7fJzYu0uAQAAVJJt4enAgQPyer2Ki4vza4+Li1NmZmaZx3Tt2lVvvfWWBg0apJCQEMXHx6tRo0Z6+eWXyz3PxIkTFRUVZT1atmxZpX9HRfl8xrox5rgB59tSAwAAOHW2Lxh3OBx++8aYUm0lNm/erBEjRujpp5/WmjVr9Omnn2rHjh0aNmxYua8/ZswYZWVlWY/du3dXaf0VtTfrqPKLfAoOcqhldJgtNQAAgFPnsuvETZo0UVBQUKlZpv3795eajSoxceJEXXrppXr00UclSRdeeKHCw8PVvXt3Pfvss2rWrFmpY9xut9xu+39DbvvPeZKk1o3D5QqyPbMCAIBKqnB4uuGGGyr8onPnzv3NPiEhIerUqZNSU1N1/fXXW+2pqam69tpryzzmyJEjcrn8Sw4KKv7KvzGmwvXZ4cefcyVJbZqE21wJAAA4FRWeAjl+3VBkZKQWLlzo9y23NWvWaOHChYqKiqrwyUeOHKl///vfev3117VlyxY98sgjSk9Pty7DjRkzRoMHD7b6DxgwQHPnztW0adO0fft2ffnllxoxYoQuueQSJSTU7p87eXlR8Q8Cn9m0oc2VAACAU1HhmacZM2ZY248//rgGDhyo6dOnWzM/Xq9X999/vyIjIyt88kGDBungwYN65plnlJGRoaSkJM2fP1+tW7eWJGVkZPjd82no0KHKycnRP/7xD40aNUqNGjVSz5499de//rXC57TLL3mFkqSNP2XZXAkAADgVDlOJ612xsbH64osvdM455/i1b926VV27dq3Vd/zOzs5WVFSUsrKyAgp6p2L97sO69pUvJUkz7rxYPc5pWiPnBQCgvrDj87s8lVq57PF4tGXLllLtW7Zskc/nO+Wi6puS4CSJ4AQAQB1XqW/b3Xnnnbrrrru0bds2denSRVLx3b+fe+453XnnnVVaIAAAQG1SqfA0adIkxcfH6+9//7syMjIkSc2aNdNjjz2mUaNGVWmBAAAAtUnA4cnj8eitt97S4MGD9dhjj1k/d2L39ce64L/3dLa7BAAAcIoCXvPkcrl03333qaCgQFJxaCI4le/zb3+9CegFLSp+GwcAAFA7VWrBeOfOnZWWllbVtdRL8zZmWNsRocE2VgIAAKpCpdY83X///Ro1apR++uknderUSeHh/nfNvvDCC6ukuPpg4Zb9dpcAAACqUKXC06BBgyRJI0aMsNocDof1o75er7dqqqsHcgs8dpcAAACqUKXC044dO6q6DgAAgDqhUuGp5OdTAAAATjeVCk8lNm/erPT0dBUWFvq1X3PNNadUFAAAQG1VqfC0fft2XX/99dq4caO11kkqXvckiTVPx2Rm5VvblyTG2FgJAACoKpW6VcFDDz2kxMRE7du3Tw0aNNC3336rZcuWKTk5WUuWLKniEuuu3z2/2NqeMfRiGysBAABVpVIzTytXrtSiRYsUGxsrp9Mpp9Opbt26aeLEiRoxYgT3gDqm0PvrjySHu0/pCikAAKglKjXz5PV61bBhQ0lSkyZNtHfvXknFC8m3bt1addUBAADUMpWaDklKStKGDRvUpk0bde7cWc8//7xCQkL06quvqk2bNlVdY50XElSpjAoAAGqhSoWnp556Snl5eZKkZ599VldffbW6d++uxo0ba/bs2VVaYH2QfEa03SUAAIAqUqnw1LdvX2u7TZs22rx5s3755RdFR0db37g73XmOW+/UunEDGysBAABVqVLXk1JTU3XkyBG/tpiYGILTcZLGf2Zt39OdS5kAANQXlZp5uvHGG1VQUKBOnTrpsssu0+WXX65LL73UWkQOKb/o15mnxMbhJ+kJAADqkkrNPB06dEhLlizRNddco7S0NP3+979XTEyMunTpoieeeKKqa6zznE5m5AAAqC8cpuT24Kdg06ZNmjRpkt566y35fL5afYfx7OxsRUVFKSsrS5GRkdV2njOemGdt73zuqmo7DwAAp4Oa+vyuiEpdttuyZYuWLl2qJUuWaOnSpfJ6verWrZsmT56syy67rKprrNMe6nW23SUAAIAqVKnwdP755ys2NlYPP/yw/vjHP+r888+v6rrqtHkbMqztVxZv0yO929pYDQAAqEqVWvM0YsQINW/eXOPHj9ddd92lxx9/XJ988olyc3Orur466YH/rrW2n+h3ro2VAACAqlap8DRlyhStXbtW+/bt01NPPSWv16unn35aTZo0UZcuXaq6xjpl54E8v/27uyXaVAkAAKgOp/S7IT6fTx6PR4WFhSooKFBRUZF27txZRaXVTZdPWuK3z72vAACoXyoVnh566CG1b99eTZs21b333qu9e/fq//2//6f169crMzOzqmuss+69jJtjAgBQ31RqwfiePXv0hz/8QZdffrmSkpKquqZ64/G+rHcCAKC+qVR4evfdd6u6jnqJm2MCAFD/VHrN05tvvqlLL71UCQkJ2rVrl6TiheQffvhhlRUHAABQ21QqPE2bNk0jR45U//79dfjwYeuO4o0aNdKUKVOqsj4AAIBapVLh6eWXX9a//vUvjR07VkFBQVZ7cnKyNm7cWGXFAQAA1DaVCk87duxQhw4dSrW73W7l5eWVcQQAAED9UKnwlJiYqHXr1pVq/+STT9SuXbtTranO2nWQ4AgAQH1XqW/bPfroo3rggQeUn58vY4y+/vprzZo1S3/5y1/02muvVXWNdUbq5n3WdvNGYTZWAgAAqkulwtOdd94pj8ejxx57TEeOHNGtt96q5s2b6+WXX1b37t2rusY6Y+n3P1vbE2+4wMZKAABAdan0rQr+8Ic/aNeuXdq/f78yMzP19ddfKy0tTWeddVZArzN16lQlJiYqNDRUnTp10vLly0/av6CgQGPHjlXr1q3ldrt15pln6vXXX6/sn1Glzmra0Npu1yzSxkoAAEB1CSg8HT58WLfddptiY2OVkJCgl156STExMXrllVd01llnadWqVQEFmdmzZ+vhhx/W2LFjlZaWpu7du6tfv35KT08v95iBAwdq4cKFeu2117R161bNmjVL555bO+7knVfgsbZjI9w2VgIAAKqLwxhjKtr5/vvv18cff6xBgwbp008/1ZYtW9S3b1/l5+dr3LhxuuyyywI6eefOndWxY0dNmzbNamvXrp2uu+46TZw4sVT/Tz/9VDfffLO2b9+umJiYgM5VIjs7W1FRUcrKylJkZNXODvWctETbDxQvGt/53FVV+toAAJzOqvPzO1ABzTzNmzdPM2bM0KRJk/TRRx/JGKO2bdtq0aJFAQenwsJCrVmzRn369PFr79Onj1asWFHmMR999JGSk5P1/PPPq3nz5mrbtq1Gjx6to0ePBnTu6pJ8RrTdJQAAgGoW0ILxvXv36rzzzpMktWnTRqGhobrnnnsqdeIDBw7I6/UqLi7Orz0uLk6ZmZllHrN9+3Z98cUXCg0N1fvvv68DBw7o/vvv1y+//FLu5cKCggIVFBRY+9nZ2ZWqtyIua9tU76z+SS2i+aYdAAD1VUAzTz6fT8HBwdZ+UFCQwsPDT6kAh8P/x3ONMaXajj+/w+HQW2+9pUsuuUT9+/fXCy+8oJkzZ5Y7+zRx4kRFRUVZj5YtW55SvSfjPXYFlPAEAED9FdDMkzFGQ4cOldtdvBg6Pz9fw4YNKxWg5s6d+5uv1aRJEwUFBZWaZdq/f3+p2agSzZo1U/PmzRUVFWW1tWvXTsYY/fTTTzr77LNLHTNmzBiNHDnS2s/Ozq62AJVfWPwbf15fhZeRAQCAOiag8DRkyBC//dtvv73SJw4JCVGnTp2Umpqq66+/3mpPTU3VtddeW+Yxl156qebMmaPc3Fw1bFh8W4Dvv/9eTqdTLVq0KPMYt9tthb3q9vjcDZKkb3YeqpHzAQCAmhdQeJoxY0aVnnzkyJG64447lJycrJSUFL366qtKT0/XsGHDJBXPGu3Zs0dvvPGGJOnWW2/Vn/70J915552aMGGCDhw4oEcffVR33XWXwsLsv1RW8e8tAgCAuqpSdxivKoMGDdLBgwf1zDPPKCMjQ0lJSZo/f75at24tScrIyPC751PDhg2VmpqqBx98UMnJyWrcuLEGDhyoZ5991q4/AQAAnGYCus9TfVCd94k444l51jb3eQIAoOrU2fs8AQAAnO4ITwAAAAEgPAEAAASA8AQAABAAwhMAAEAACE8AAAABIDwBAAAEgPAEAAAQAMITAABAAAhPAAAAASA8AQAABIDwVEWKvD67SwAAADWA8FRFMrPy7S4BAADUAMITAABAAAhPAAAAASA8VRGH49ft3ufF2VcIAACoVoSnKuI4Lj05HSfpCAAA6jTCUxVx+G2TngAAqK8IT1Xk+Mt2DrITAAD1FuGpGjhJTwAA1FuEpypy/KU6shMAAPUX4amKHB+YVm0/aF8hAACgWhGeqsjxk02RocG21QEAAKoX4amqHJeeLmrVyLYyAABA9SI8VRG/NU/cqgAAgHqL8FQNuEkmAAD1F+Gpihy/YJxbFQAAUH8RnqrI8XHJyagCAFBv8TFfRfx/246ZJwAA6ivCUxU5Pi4FsegJAIB6i/BUDZh5AgCg/iI8VQOyEwAA9RfhqYrwbTsAAE4PhKdqwJInAADqL8JTNXAw8wQAQL1FeKoGZCcAAOovwlM1YM0TAAD1l+3haerUqUpMTFRoaKg6deqk5cuXV+i4L7/8Ui6XSxdddFH1FlgJ58RF2F0CAACoJraGp9mzZ+vhhx/W2LFjlZaWpu7du6tfv35KT08/6XFZWVkaPHiwevXqVUOVBibc7bK7BAAAUE1sDU8vvPCC7r77bt1zzz1q166dpkyZopYtW2ratGknPe7ee+/VrbfeqpSUlBqqNDB82w4AgPrLtvBUWFioNWvWqE+fPn7tffr00YoVK8o9bsaMGfrxxx81bty46i6x0ljzBABA/WXb9aUDBw7I6/UqLi7Orz0uLk6ZmZllHvPDDz/oiSee0PLly+VyVaz0goICFRQUWPvZ2dmVL7qCIsOCq/0cAADAHrYvGD/xnkjGmDLvk+T1enXrrbdqwoQJatu2bYVff+LEiYqKirIeLVu2POWaf0v7FlHVfg4AAGAP28JTkyZNFBQUVGqWaf/+/aVmoyQpJydHq1ev1vDhw+VyueRyufTMM89o/fr1crlcWrRoUZnnGTNmjLKysqzH7t27q+XvOR43yQQAoP6y7bJdSEiIOnXqpNTUVF1//fVWe2pqqq699tpS/SMjI7Vx40a/tqlTp2rRokV69913lZiYWOZ53G633G531RYPAABOW7Z+p37kyJG64447lJycrJSUFL366qtKT0/XsGHDJBXPGu3Zs0dvvPGGnE6nkpKS/I5v2rSpQkNDS7UDAABUF1vD06BBg3Tw4EE988wzysjIUFJSkubPn6/WrVtLkjIyMn7znk8AAAA1yWGMMXYXUZOys7MVFRWlrKwsRUZGVtnrHsorVIc/pUqSfvxLfwVxsycAAKpMdX1+V4bt37arj4hNAADUX4QnAACAABCeAAAAAkB4AgAACADhCQAAIACEJwAAgAAQngAAAAJAeAIAAAgA4QkAACAAhCcAAIAAEJ4AAAACQHgCAAAIAOEJAAAgAIQnAACAABCeAAAAAkB4AgAACADhCQAAIACEpypi7C4AAADUCMJTNXA47K4AAABUF8ITAABAAAhPAAAAASA8AQAABIDwBAAAEADCEwAAQAAITwAAAAEgPAEAAASA8AQAABAAwhMAAEAACE8AAAABIDwBAAAEgPAEAAAQAMITAABAAAhPAAAAASA8AQAABIDwBAAAEADCUxUxxthdAgAAqAGEp2rgcDjsLgEAAFQTwhMAAEAAbA9PU6dOVWJiokJDQ9WpUyctX7683L5z585V7969FRsbq8jISKWkpOizzz6rwWoBAMDpztbwNHv2bD388MMaO3as0tLS1L17d/Xr10/p6ell9l+2bJl69+6t+fPna82aNerRo4cGDBigtLS0Gq4cAACcrhzGxpXOnTt3VseOHTVt2jSrrV27drruuus0ceLECr3G+eefr0GDBunpp5+uUP/s7GxFRUUpKytLkZGRlaq7LAdzC9Tp2QWSpJ3PXVVlrwsAAKrv87sybJt5Kiws1Jo1a9SnTx+/9j59+mjFihUVeg2fz6ecnBzFxMSU26egoEDZ2dl+DwAAgMqyLTwdOHBAXq9XcXFxfu1xcXHKzMys0GtMnjxZeXl5GjhwYLl9Jk6cqKioKOvRsmXLU6obAACc3mxfMH7i1/qNMRX6qv+sWbM0fvx4zZ49W02bNi2335gxY5SVlWU9du/efco1AwCA05fLrhM3adJEQUFBpWaZ9u/fX2o26kSzZ8/W3XffrTlz5uiKK644aV+32y23233K9QIAAEg2zjyFhISoU6dOSk1N9WtPTU1V165dyz1u1qxZGjp0qP773//qqqtYmA0AAGqWbTNPkjRy5EjdcccdSk5OVkpKil599VWlp6dr2LBhkoovue3Zs0dvvPGGpOLgNHjwYL344ovq0qWLNWsVFhamqKgo2/4OAABw+rA1PA0aNEgHDx7UM888o4yMDCUlJWn+/Plq3bq1JCkjI8Pvnk///Oc/5fF49MADD+iBBx6w2ocMGaKZM2fWdPkAAOA0ZOt9nuzAfZ4AAKh7uM8TAABAHUV4AgAACADhCQAAIACEJwAAgAAQnqrIabXqHgCA0xjhCQAAIACEJwAAgAAQngAAAAJAeAIAAAgA4QkAACAAhCcAAIAAEJ4AAAACQHgCAAAIAOEJAAAgAIQnAACAABCeAAAAAkB4AgAACADhCQAAIACEJwAAgAAQngAAAAJAeAIAAAgA4QkAACAAhKcqYozdFQAAgJpAeKpiDofdFQAAgOpEeAIAAAgA4QkAACAAhCcAAIAAEJ4AAAACQHgCAAAIAOEJAAAgAIQnAACAABCeAAAAAkB4AgAACADhCQAAIACEJwAAgAAQngAAAAJAeAIAAAiA7eFp6tSpSkxMVGhoqDp16qTly5eftP/SpUvVqVMnhYaGqk2bNpo+fXoNVQoAAGBzeJo9e7YefvhhjR07Vmlpaerevbv69eun9PT0Mvvv2LFD/fv3V/fu3ZWWlqYnn3xSI0aM0HvvvVfDlQMAgNOVwxhj7Dp5586d1bFjR02bNs1qa9euna677jpNnDixVP/HH39cH330kbZs2WK1DRs2TOvXr9fKlSsrdM7s7GxFRUUpKytLkZGRp/5HHLMvO1+d/7JQDoe0Y+JVVfa6AACg+j6/K8O2mafCwkKtWbNGffr08Wvv06ePVqxYUeYxK1euLNW/b9++Wr16tYqKiso8pqCgQNnZ2X6P6nDoSGG1vC4AAKhdbAtPBw4ckNfrVVxcnF97XFycMjMzyzwmMzOzzP4ej0cHDhwo85iJEycqKirKerRs2bJq/oATxISHyO1y6pr2CdXy+gAAoHawfcG4w+Hw2zfGlGr7rf5ltZcYM2aMsrKyrMfu3btPseKyNY0I1dZn++nFmztUy+sDAIDawWXXiZs0aaKgoKBSs0z79+8vNbtUIj4+vsz+LpdLjRs3LvMYt9stt9tdNUUDAIDTnm0zTyEhIerUqZNSU1P92lNTU9W1a9cyj0lJSSnV//PPP1dycrKCg4OrrVYAAIAStl62GzlypP7973/r9ddf15YtW/TII48oPT1dw4YNk1R8yW3w4MFW/2HDhmnXrl0aOXKktmzZotdff12vvfaaRo8ebdefAAAATjO2XbaTpEGDBungwYN65plnlJGRoaSkJM2fP1+tW7eWJGVkZPjd8ykxMVHz58/XI488oldeeUUJCQl66aWXdOONN9r1JwAAgNOMrfd5skNtuk8EAAComNr0+W37t+0AAADqEsITAABAAAhPAAAAASA8AQAABIDwBAAAEADCEwAAQAAITwAAAAEgPAEAAASA8AQAABAAW3+exQ4lN1TPzs62uRIAAFBRJZ/bteGHUU678JSTkyNJatmypc2VAACAQOXk5CgqKsrWGk6737bz+Xzau3evIiIi5HA4qvS1s7Oz1bJlS+3evdv2392pSxi3ymPsKodxqzzGrnIYt8orGbv09HQ5HA4lJCTI6bR31dFpN/PkdDrVokWLaj1HZGQk/zkqgXGrPMauchi3ymPsKodxq7yoqKhaM3YsGAcAAAgA4QkAACAAhKcq5Ha7NW7cOLndbrtLqVMYt8pj7CqHcas8xq5yGLfKq41jd9otGAcAADgVzDwBAAAEgPAEAAAQAMITAABAAAhPAAAAASA8VZGpU6cqMTFRoaGh6tSpk5YvX253SdVm/Pjxcjgcfo/4+HjreWOMxo8fr4SEBIWFhenyyy/Xt99+6/caBQUFevDBB9WkSROFh4frmmuu0U8//eTX59ChQ7rjjjsUFRWlqKgo3XHHHTp8+LBfn/T0dA0YMEDh4eFq0qSJRowYocLCwmr72wO1bNkyDRgwQAkJCXI4HPrggw/8nq9tY7Vx40ZddtllCgsLU/PmzfXMM8/Y8jtSvzVuQ4cOLfUe7NKli1+f03HcJk6cqIsvvlgRERFq2rSprrvuOm3dutWvD++5slVk7HjflTZt2jRdeOGF1s0/U1JS9Mknn1jP19v3m8Epe/vtt01wcLD517/+ZTZv3mweeughEx4ebnbt2mV3adVi3Lhx5vzzzzcZGRnWY//+/dbzzz33nImIiDDvvfee2bhxoxk0aJBp1qyZyc7OtvoMGzbMNG/e3KSmppq1a9eaHj16mPbt2xuPx2P1ufLKK01SUpJZsWKFWbFihUlKSjJXX3219bzH4zFJSUmmR48eZu3atSY1NdUkJCSY4cOH18xAVMD8+fPN2LFjzXvvvWckmffff9/v+do0VllZWSYuLs7cfPPNZuPGjea9994zERERZtKkSdU3QOX4rXEbMmSIufLKK/3egwcPHvTrczqOW9++fc2MGTPMpk2bzLp168xVV11lWrVqZXJzc60+vOfKVpGx431X2kcffWTmzZtntm7darZu3WqefPJJExwcbDZt2mSMqb/vN8JTFbjkkkvMsGHD/NrOPfdc88QTT9hUUfUaN26cad++fZnP+Xw+Ex8fb5577jmrLT8/30RFRZnp06cbY4w5fPiwCQ4ONm+//bbVZ8+ePcbpdJpPP/3UGGPM5s2bjSSzatUqq8/KlSuNJPPdd98ZY4o/YJ1Op9mzZ4/VZ9asWcbtdpusrKwq+3uryokhoLaN1dSpU01UVJTJz8+3+kycONEkJCQYn89XhSMRmPLC07XXXlvuMYxbsf379xtJZunSpcYY3nOBOHHsjOF9V1HR0dHm3//+d71+v3HZ7hQVFhZqzZo16tOnj197nz59tGLFCpuqqn4//PCDEhISlJiYqJtvvlnbt2+XJO3YsUOZmZl+4+F2u3XZZZdZ47FmzRoVFRX59UlISFBSUpLVZ+XKlYqKilLnzp2tPl26dFFUVJRfn6SkJCUkJFh9+vbtq4KCAq1Zs6b6/vgqUtvGauXKlbrsssv8bkTXt29f7d27Vzt37qz6AThFS5YsUdOmTdW2bVv94Q9/0P79+63nGLdiWVlZkqSYmBhJvOcCceLYleB9Vz6v16u3335beXl5SklJqdfvN8LTKTpw4IC8Xq/i4uL82uPi4pSZmWlTVdWrc+fOeuONN/TZZ5/pX//6lzIzM9W1a1cdPHjQ+ptPNh6ZmZkKCQlRdHT0Sfs0bdq01LmbNm3q1+fE80RHRyskJKROjH1tG6uy+pTs17bx7Nevn9566y0tWrRIkydP1jfffKOePXuqoKBAEuMmFa81GTlypLp166akpCS/enjPnVxZYyfxvivPxo0b1bBhQ7ndbg0bNkzvv/++zjvvvHr9fnMF1BvlcjgcfvvGmFJt9UW/fv2s7QsuuEApKSk688wz9X//93/W4snKjMeJfcrqX5k+tV1tGquyainvWDsNGjTI2k5KSlJycrJat26tefPm6YYbbij3uNNp3IYPH64NGzboiy++KPUc77mTK2/seN+V7ZxzztG6det0+PBhvffeexoyZIiWLl160jrr+vuNmadT1KRJEwUFBZVKrfv37y+VcOur8PBwXXDBBfrhhx+sb92dbDzi4+NVWFioQ4cOnbTPvn37Sp3r559/9utz4nkOHTqkoqKiOjH2tW2syupTckmito9ns2bN1Lp1a/3www+SGLcHH3xQH330kRYvXqwWLVpY7bznflt5Y1cW3nfFQkJCdNZZZyk5OVkTJ05U+/bt9eKLL9br9xvh6RSFhISoU6dOSk1N9WtPTU1V165dbaqqZhUUFGjLli1q1qyZEhMTFR8f7zcehYWFWrp0qTUenTp1UnBwsF+fjIwMbdq0yeqTkpKirKwsff3111afr776SllZWX59Nm3apIyMDKvP559/LrfbrU6dOlXr31wVattYpaSkaNmyZX5f7f3888+VkJCgM844o+oHoAodPHhQu3fvVrNmzSSdvuNmjNHw4cM1d+5cLVq0SImJiX7P854r32+NXVl435XNGKOCgoL6/X4LaHk5ylRyq4LXXnvNbN682Tz88MMmPDzc7Ny50+7SqsWoUaPMkiVLzPbt282qVavM1VdfbSIiIqy/97nnnjNRUVFm7ty5ZuPGjeaWW24p86upLVq0MAsWLDBr1641PXv2LPOrqRdeeKFZuXKlWblypbngggvK/Gpqr169zNq1a82CBQtMixYtatWtCnJyckxaWppJS0szkswLL7xg0tLSrNtY1KaxOnz4sImLizO33HKL2bhxo5k7d66JjIy05WvjJxu3nJwcM2rUKLNixQqzY8cOs3jxYpOSkmKaN29+2o/bfffdZ6KiosySJUv8vk5/5MgRqw/vubL91tjxvivbmDFjzLJly8yOHTvMhg0bzJNPPmmcTqf5/PPPjTH19/1GeKoir7zyimndurUJCQkxHTt29Pt6a31Tcp+O4OBgk5CQYG644Qbz7bffWs/7fD4zbtw4Ex8fb9xut/nd735nNm7c6PcaR48eNcOHDzcxMTEmLCzMXH311SY9Pd2vz8GDB81tt91mIiIiTEREhLntttvMoUOH/Prs2rXLXHXVVSYsLMzExMSY4cOH+30N1W6LFy82kko9hgwZYoypfWO1YcMG0717d+N2u018fLwZP368LV97Ptm4HTlyxPTp08fExsaa4OBg06pVKzNkyJBSY3I6jltZYybJzJgxw+rDe65svzV2vO/Kdtddd1mffbGxsaZXr15WcDKm/r7fHMbYcCtXAACAOoo1TwAAAAEgPAEAAASA8AQAABAAwhMAAEAACE8AAAABIDwBAAAEgPAEAAAQAMITgDpj586dcjgcWrduXbWdY+jQobruuuuq7fUB1H2EJwA1ZujQoXI4HKUeV155ZYWOb9mypTIyMpSUlFTNlQJA+Vx2FwDg9HLllVdqxowZfm1ut7tCxwYFBVm/1A4AdmHmCUCNcrvdio+P93tER0dLkhwOh6ZNm6Z+/fopLCxMiYmJmjNnjnXsiZftDh06pNtuu02xsbEKCwvT2Wef7RfMNm7cqJ49eyosLEyNGzfW//t//0+5ubnW816vVyNHjlSjRo3UuHFjPfbYYzrxF6uMMXr++efVpk0bhYWFqX379nr33XercYQA1HaEJwC1yh//+EfdeOONWr9+vW6//Xbdcsst2rJlS7l9N2/erE8++URbtmzRtGnT1KRJE0nSkSNHdOWVVyo6OlrffPON5syZowULFmj48OHW8ZMnT9brr7+u1157TV988YV++eUXvf/++37neOqppzRjxgxNmzZN3377rR555BHdfvvtWrp0afUNAoDaLeCfEgaAShoyZIgJCgoy4eHhfo9nnnnGGFP8y/bDhg3zO6Zz587mvvvuM8YYs2PHDiPJpKWlGWOMGTBggLnzzjvLPNerr75qoqOjTW5urtU2b94843Q6TWZmpjHGmGbNmpnnnnvOer6oqMi0aNHCXHvttcYYY3Jzc01oaKhZsWKF32vffffd5pZbbqn8QACo01jzBKBG9ejRQ9OmTfNri4mJsbZTUlL8nktJSSn323X33XefbrzxRq1du1Z9+vTRddddp65du0qStmzZovbt2ys8PNzqf+mll8rn82nr1q0KDQ1VRkaG3/lcLpeSk5OtS3ebN29Wfn6+evfu7XfewsJCdejQIfA/HkC9QHgCUKPCw8N11llnBXSMw+Eos71fv37atWuX5s2bpwULFqhXr1564IEHNGnSJBljyj2uvPYT+Xw+SdK8efPUvHlzv+cqusgdQP3DmicAtcqqVatK7Z977rnl9o+NjdXQoUP1n//8R1OmTNGrr74qSTrvvPO0bt065eXlWX2//PJLOZ1OtW3bVlFRUWrWrJnf+Twej9asWWPtn3feeXK73UpPT9dZZ53l92jZsmVV/ckA6hhmngDUqIKCAmVmZvq1uVwua6H3nDlzlJycrG7duumtt97S119/rddee63M13r66afVqVMnnX/++SooKND//vc/tWvXTpJ02223ady4cRoyZIjGjx+vn3/+WQ8++KDuuOMOxcXFSZIeeughPffcczr77LPVrl07vfDCCzp8+LD1+hERERo9erQeeeQR+Xw+devWTdnZ2VqxYoUaNmyoIUOGVMMIAajtCE8AatSnn36qZs2a+bWdc845+u677yRJEyZM0Ntvv637779f8fHxeuutt3TeeeeV+VohISEaM2aMdu7cqbCwMHXv3l1vv/22JKlBgwb67LPP9NBDD+niiy9WgwYNdOONN+qFF16wjh81apQyMjI0dOhQOZ1O3XXXXbr++uuVlZVl9fnTn/6kpk2bauLEidq+fbsaNWqkjh076sknn6zqoQFQRziMOeGmJgBgE4fDoffff5+fRwFQq7HmCQAAIACEJwAAgACw5glArcEqAgB1ATNPAAAAASA8AQAABIDwBAAAEADCEwAAQAAITwAAAAEgPAEAAASA8AQAABAAwhMAAEAACE8AAAAB+P9mnkocwHXYsAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load rewards from the file\n",
    "loaded_rewards = np.load('result_model/deep_q_matrix.npy')\n",
    "\n",
    "# Now you can plot or analyze the rewards\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loaded_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards Over Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2048        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           16448       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 7)            231         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 7)            0           dense_4[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 154,248\n",
      "Trainable params: 154,248\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_model = tf.keras.models.load_model('model/ddqn.keras')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 reward: 0.619\n",
      "Iteration 2000 reward: 0.634\n",
      "Iteration 3000 reward: 0.6556666666666666\n",
      "Iteration 4000 reward: 0.6715\n",
      "Iteration 5000 reward: 0.6922\n",
      "Iteration 6000 reward: 0.7115\n",
      "Iteration 7000 reward: 0.7251428571428571\n",
      "Iteration 8000 reward: 0.737875\n",
      "Iteration 9000 reward: 0.7473333333333333\n",
      "Iteration 10000 reward: 0.7613\n",
      "Iteration 11000 reward: 0.7792727272727272\n",
      "Iteration 12000 reward: 0.7861666666666667\n",
      "Iteration 13000 reward: 0.8017692307692308\n",
      "Iteration 14000 reward: 0.8137142857142857\n",
      "Iteration 15000 reward: 0.8294\n",
      "Iteration 16000 reward: 0.8394375\n",
      "Iteration 17000 reward: 0.8568235294117647\n",
      "Iteration 18000 reward: 0.8708333333333333\n",
      "Iteration 19000 reward: 0.884\n",
      "Iteration 20000 reward: 0.8953\n",
      "Iteration 21000 reward: 0.9085238095238095\n",
      "Iteration 22000 reward: 0.9193181818181818\n",
      "Iteration 23000 reward: 0.9291304347826087\n",
      "Iteration 24000 reward: 0.9403333333333334\n",
      "Iteration 25000 reward: 0.95192\n",
      "Iteration 26000 reward: 0.9614230769230769\n",
      "Iteration 27000 reward: 0.975\n",
      "Iteration 28000 reward: 0.9868571428571429\n",
      "Iteration 29000 reward: 0.9972068965517241\n",
      "Iteration 30000 reward: 1.0062666666666666\n",
      "Iteration 31000 reward: 1.0164193548387097\n",
      "Iteration 32000 reward: 1.02553125\n",
      "Iteration 33000 reward: 1.034848484848485\n",
      "Iteration 34000 reward: 1.043764705882353\n",
      "Iteration 35000 reward: 1.052857142857143\n",
      "Iteration 36000 reward: 1.0608333333333333\n",
      "Iteration 37000 reward: 1.0676216216216217\n",
      "Iteration 38000 reward: 1.0748421052631578\n",
      "Iteration 39000 reward: 1.0803846153846153\n",
      "Iteration 40000 reward: 1.08695\n",
      "Iteration 41000 reward: 1.0937317073170731\n",
      "Iteration 42000 reward: 1.0987857142857143\n",
      "Iteration 43000 reward: 1.1054186046511627\n",
      "Iteration 44000 reward: 1.1101590909090908\n",
      "Iteration 45000 reward: 1.1162444444444444\n",
      "Iteration 46000 reward: 1.1217173913043479\n",
      "Iteration 47000 reward: 1.126404255319149\n",
      "Iteration 48000 reward: 1.1314583333333332\n",
      "Iteration 49000 reward: 1.1365102040816326\n",
      "Iteration 50000 reward: 1.1409\n",
      "Iteration 51000 reward: 1.1454509803921569\n",
      "Iteration 52000 reward: 1.149576923076923\n",
      "Iteration 53000 reward: 1.1537924528301886\n",
      "Iteration 54000 reward: 1.1569074074074075\n",
      "Iteration 55000 reward: 1.1614363636363636\n",
      "Iteration 56000 reward: 1.1653214285714286\n",
      "Iteration 57000 reward: 1.168280701754386\n",
      "Iteration 58000 reward: 1.1714310344827585\n",
      "Iteration 59000 reward: 1.1743050847457628\n",
      "Iteration 60000 reward: 1.17685\n",
      "Iteration 61000 reward: 1.1804426229508196\n",
      "Iteration 62000 reward: 1.1826774193548386\n",
      "Iteration 63000 reward: 1.1852539682539682\n",
      "Iteration 64000 reward: 1.187875\n",
      "Iteration 65000 reward: 1.1908307692307691\n",
      "Iteration 66000 reward: 1.193969696969697\n",
      "Iteration 67000 reward: 1.196313432835821\n",
      "Iteration 68000 reward: 1.198014705882353\n",
      "Iteration 69000 reward: 1.199927536231884\n",
      "Iteration 70000 reward: 1.2026714285714286\n",
      "Iteration 71000 reward: 1.2053521126760562\n",
      "Iteration 72000 reward: 1.2070277777777778\n",
      "Iteration 73000 reward: 1.2096027397260274\n",
      "Iteration 74000 reward: 1.2112027027027028\n",
      "Iteration 75000 reward: 1.2126933333333334\n",
      "Iteration 76000 reward: 1.214842105263158\n",
      "Iteration 77000 reward: 1.2158701298701298\n",
      "Iteration 78000 reward: 1.2175897435897436\n",
      "Iteration 79000 reward: 1.219645569620253\n",
      "Iteration 80000 reward: 1.221375\n",
      "Iteration 81000 reward: 1.2232592592592593\n",
      "Iteration 82000 reward: 1.2245365853658536\n",
      "Iteration 83000 reward: 1.2255542168674698\n",
      "Iteration 84000 reward: 1.227107142857143\n",
      "Iteration 85000 reward: 1.2288823529411765\n",
      "Iteration 86000 reward: 1.2303604651162792\n",
      "Iteration 87000 reward: 1.2320114942528735\n",
      "Iteration 88000 reward: 1.23325\n",
      "Iteration 89000 reward: 1.2344044943820225\n",
      "Iteration 90000 reward: 1.2361\n",
      "Iteration 91000 reward: 1.236945054945055\n",
      "Iteration 92000 reward: 1.2378152173913044\n",
      "Iteration 93000 reward: 1.239021505376344\n",
      "Iteration 94000 reward: 1.240840425531915\n",
      "Iteration 95000 reward: 1.2418526315789473\n",
      "Iteration 96000 reward: 1.2430729166666667\n",
      "Iteration 97000 reward: 1.2445567010309277\n",
      "Iteration 98000 reward: 1.2461326530612244\n",
      "Iteration 99000 reward: 1.247070707070707\n",
      "Iteration 100000 reward: 1.24762\n",
      "Iteration 101000 reward: 1.2486435643564358\n",
      "Iteration 102000 reward: 1.249421568627451\n",
      "Iteration 103000 reward: 1.2503203883495146\n",
      "Iteration 104000 reward: 1.2515192307692307\n",
      "Iteration 105000 reward: 1.2521714285714285\n",
      "Iteration 106000 reward: 1.253377358490566\n",
      "Iteration 107000 reward: 1.254140186915888\n",
      "Iteration 108000 reward: 1.2553425925925925\n",
      "Iteration 109000 reward: 1.256256880733945\n",
      "Iteration 110000 reward: 1.2568545454545454\n",
      "Iteration 111000 reward: 1.2577297297297296\n",
      "Iteration 112000 reward: 1.2586785714285715\n",
      "Iteration 113000 reward: 1.2592389380530973\n",
      "Iteration 114000 reward: 1.2600614035087718\n",
      "Iteration 115000 reward: 1.260304347826087\n",
      "Iteration 116000 reward: 1.260896551724138\n",
      "Iteration 117000 reward: 1.2615555555555555\n",
      "Iteration 118000 reward: 1.2621864406779661\n",
      "Iteration 119000 reward: 1.2629495798319328\n",
      "Iteration 120000 reward: 1.2638\n",
      "Iteration 121000 reward: 1.2643719008264462\n",
      "Iteration 122000 reward: 1.265155737704918\n",
      "Iteration 123000 reward: 1.2658861788617886\n",
      "Iteration 124000 reward: 1.266241935483871\n",
      "Iteration 125000 reward: 1.266984\n",
      "Iteration 126000 reward: 1.2674920634920634\n",
      "Iteration 127000 reward: 1.2679685039370079\n",
      "Iteration 128000 reward: 1.2688125\n",
      "Iteration 129000 reward: 1.2695736434108527\n",
      "Iteration 130000 reward: 1.2704076923076923\n",
      "Iteration 131000 reward: 1.2709847328244275\n",
      "Iteration 132000 reward: 1.2720075757575757\n",
      "Iteration 133000 reward: 1.2724135338345866\n",
      "Iteration 134000 reward: 1.2724776119402985\n",
      "Iteration 135000 reward: 1.2728\n",
      "Iteration 136000 reward: 1.2734191176470588\n",
      "Iteration 137000 reward: 1.2738175182481752\n",
      "Iteration 138000 reward: 1.2743550724637682\n",
      "Iteration 139000 reward: 1.2754028776978417\n",
      "Iteration 140000 reward: 1.2757357142857142\n",
      "Iteration 141000 reward: 1.276418439716312\n",
      "Iteration 142000 reward: 1.2770704225352112\n",
      "Iteration 143000 reward: 1.2775594405594406\n",
      "Iteration 144000 reward: 1.2782152777777778\n",
      "Iteration 145000 reward: 1.2789172413793104\n",
      "Iteration 146000 reward: 1.2793767123287672\n",
      "Iteration 147000 reward: 1.2797959183673469\n",
      "Iteration 148000 reward: 1.2799797297297297\n",
      "Iteration 149000 reward: 1.280241610738255\n",
      "Iteration 150000 reward: 1.2806933333333332\n",
      "Iteration 151000 reward: 1.2809933774834437\n",
      "Iteration 152000 reward: 1.2811644736842105\n",
      "Iteration 153000 reward: 1.2813071895424837\n",
      "Iteration 154000 reward: 1.2819025974025975\n",
      "Iteration 155000 reward: 1.282058064516129\n",
      "Iteration 156000 reward: 1.282128205128205\n",
      "Iteration 157000 reward: 1.2827261146496816\n",
      "Iteration 158000 reward: 1.2829430379746836\n",
      "Iteration 159000 reward: 1.2837421383647798\n",
      "Iteration 160000 reward: 1.28438125\n",
      "Iteration 161000 reward: 1.2846335403726707\n",
      "Iteration 162000 reward: 1.2851049382716049\n",
      "Iteration 163000 reward: 1.2853251533742331\n",
      "Iteration 164000 reward: 1.2858658536585366\n",
      "Iteration 165000 reward: 1.2863515151515152\n",
      "Iteration 166000 reward: 1.2868132530120482\n",
      "Iteration 167000 reward: 1.2870299401197605\n",
      "Iteration 168000 reward: 1.2874464285714287\n",
      "Iteration 169000 reward: 1.2875207100591717\n",
      "Iteration 170000 reward: 1.2879\n",
      "Iteration 171000 reward: 1.2881286549707602\n",
      "Iteration 172000 reward: 1.288325581395349\n",
      "Iteration 173000 reward: 1.2887514450867052\n",
      "Iteration 174000 reward: 1.2891379310344828\n",
      "Iteration 175000 reward: 1.2895142857142856\n",
      "Iteration 176000 reward: 1.2898863636363636\n",
      "Iteration 177000 reward: 1.2905141242937852\n",
      "Iteration 178000 reward: 1.290938202247191\n",
      "Iteration 179000 reward: 1.291586592178771\n",
      "Iteration 180000 reward: 1.2916722222222223\n",
      "Iteration 181000 reward: 1.2920055248618785\n",
      "Iteration 182000 reward: 1.2923021978021978\n",
      "Iteration 183000 reward: 1.292743169398907\n",
      "Iteration 184000 reward: 1.2930652173913044\n",
      "Iteration 185000 reward: 1.2934324324324324\n",
      "Iteration 186000 reward: 1.293731182795699\n",
      "Iteration 187000 reward: 1.2938235294117648\n",
      "Iteration 188000 reward: 1.2941755319148935\n",
      "Iteration 189000 reward: 1.2943968253968254\n",
      "Iteration 190000 reward: 1.2949052631578948\n",
      "Iteration 191000 reward: 1.2952094240837697\n",
      "Iteration 192000 reward: 1.29559375\n",
      "Iteration 193000 reward: 1.2959326424870465\n",
      "Iteration 194000 reward: 1.2961237113402062\n",
      "Iteration 195000 reward: 1.2965641025641026\n",
      "Iteration 196000 reward: 1.296892857142857\n",
      "Iteration 197000 reward: 1.2973451776649747\n",
      "Iteration 198000 reward: 1.2975202020202021\n",
      "Iteration 199000 reward: 1.2977889447236182\n",
      "Iteration 200000 reward: 1.297975\n",
      "Iteration 201000 reward: 1.2984179104477611\n",
      "Iteration 202000 reward: 1.2987475247524753\n",
      "Iteration 203000 reward: 1.299\n",
      "Iteration 204000 reward: 1.2991813725490196\n",
      "Iteration 205000 reward: 1.2995170731707317\n",
      "Iteration 206000 reward: 1.299757281553398\n",
      "Iteration 207000 reward: 1.300024154589372\n",
      "Iteration 208000 reward: 1.3002884615384616\n",
      "Iteration 209000 reward: 1.300578947368421\n",
      "Iteration 210000 reward: 1.3009619047619048\n",
      "Iteration 211000 reward: 1.301255924170616\n",
      "Iteration 212000 reward: 1.301617924528302\n",
      "Iteration 213000 reward: 1.3017981220657278\n",
      "Iteration 214000 reward: 1.3020140186915887\n",
      "Iteration 215000 reward: 1.302525581395349\n",
      "Iteration 216000 reward: 1.3029490740740741\n",
      "Iteration 217000 reward: 1.303152073732719\n",
      "Iteration 218000 reward: 1.30348623853211\n",
      "Iteration 219000 reward: 1.3039817351598173\n",
      "Iteration 220000 reward: 1.304009090909091\n",
      "Iteration 221000 reward: 1.3042352941176472\n",
      "Iteration 222000 reward: 1.3042027027027028\n",
      "Iteration 223000 reward: 1.304304932735426\n",
      "Iteration 224000 reward: 1.3046830357142858\n",
      "Iteration 225000 reward: 1.3049066666666667\n",
      "Iteration 226000 reward: 1.305070796460177\n",
      "Iteration 227000 reward: 1.3054229074889867\n",
      "Iteration 228000 reward: 1.3054868421052632\n",
      "Iteration 229000 reward: 1.3058078602620087\n",
      "Iteration 230000 reward: 1.3061565217391304\n",
      "Iteration 231000 reward: 1.3066493506493506\n",
      "Iteration 232000 reward: 1.3069870689655172\n",
      "Iteration 233000 reward: 1.307343347639485\n",
      "Iteration 234000 reward: 1.307653846153846\n",
      "Iteration 235000 reward: 1.3079361702127659\n",
      "Iteration 236000 reward: 1.3080805084745764\n",
      "Iteration 237000 reward: 1.3082995780590718\n",
      "Iteration 238000 reward: 1.308638655462185\n",
      "Iteration 239000 reward: 1.3088995815899582\n",
      "Iteration 240000 reward: 1.3091833333333334\n",
      "Iteration 241000 reward: 1.309182572614108\n",
      "Iteration 242000 reward: 1.3096694214876032\n",
      "Iteration 243000 reward: 1.3097777777777777\n",
      "Iteration 244000 reward: 1.3100491803278689\n",
      "Iteration 245000 reward: 1.3103469387755102\n",
      "Iteration 246000 reward: 1.3105243902439025\n",
      "Iteration 247000 reward: 1.3108744939271255\n",
      "Iteration 248000 reward: 1.311225806451613\n",
      "Iteration 249000 reward: 1.311305220883534\n",
      "Iteration 250000 reward: 1.311744\n",
      "Iteration 251000 reward: 1.3121115537848607\n",
      "Iteration 252000 reward: 1.3124126984126985\n",
      "Iteration 253000 reward: 1.3126205533596838\n",
      "Iteration 254000 reward: 1.3128188976377952\n",
      "Iteration 255000 reward: 1.3131058823529411\n",
      "Iteration 256000 reward: 1.31352734375\n",
      "Iteration 257000 reward: 1.313863813229572\n",
      "Iteration 258000 reward: 1.3140116279069767\n",
      "Iteration 259000 reward: 1.3144362934362934\n",
      "Iteration 260000 reward: 1.3146115384615384\n",
      "Iteration 261000 reward: 1.3147318007662836\n",
      "Iteration 262000 reward: 1.3149541984732824\n",
      "Iteration 263000 reward: 1.315212927756654\n",
      "Iteration 264000 reward: 1.315405303030303\n",
      "Iteration 265000 reward: 1.3155735849056605\n",
      "Iteration 266000 reward: 1.3157255639097745\n",
      "Iteration 267000 reward: 1.3159176029962547\n",
      "Iteration 268000 reward: 1.3160223880597015\n",
      "Iteration 269000 reward: 1.3162342007434944\n",
      "Iteration 270000 reward: 1.3164518518518518\n",
      "Iteration 271000 reward: 1.3168487084870848\n",
      "Iteration 272000 reward: 1.3171360294117647\n",
      "Iteration 273000 reward: 1.3173003663003664\n",
      "Iteration 274000 reward: 1.317536496350365\n",
      "Iteration 275000 reward: 1.317669090909091\n",
      "Iteration 276000 reward: 1.317855072463768\n",
      "Iteration 277000 reward: 1.3181119133574006\n",
      "Iteration 278000 reward: 1.3182625899280576\n",
      "Iteration 279000 reward: 1.318663082437276\n",
      "Iteration 280000 reward: 1.3188964285714286\n",
      "Iteration 281000 reward: 1.3192455516014234\n",
      "Iteration 282000 reward: 1.319531914893617\n",
      "Iteration 283000 reward: 1.3197632508833923\n",
      "Iteration 284000 reward: 1.3198591549295775\n",
      "Iteration 285000 reward: 1.320038596491228\n",
      "Iteration 286000 reward: 1.3200034965034966\n",
      "Iteration 287000 reward: 1.3199547038327526\n",
      "Iteration 288000 reward: 1.3200555555555555\n",
      "Iteration 289000 reward: 1.3201453287197231\n",
      "Iteration 290000 reward: 1.3203068965517242\n",
      "Iteration 291000 reward: 1.3204982817869415\n",
      "Iteration 292000 reward: 1.320527397260274\n",
      "Iteration 293000 reward: 1.3207337883959045\n",
      "Iteration 294000 reward: 1.3209897959183674\n",
      "Iteration 295000 reward: 1.321284745762712\n",
      "Iteration 296000 reward: 1.3214864864864866\n",
      "Iteration 297000 reward: 1.3215622895622896\n",
      "Iteration 298000 reward: 1.3216610738255035\n",
      "Iteration 299000 reward: 1.321943143812709\n",
      "Iteration 300000 reward: 1.3221533333333333\n",
      "Iteration 301000 reward: 1.3224950166112956\n",
      "Iteration 302000 reward: 1.322658940397351\n",
      "Iteration 303000 reward: 1.3227656765676568\n",
      "Iteration 304000 reward: 1.3228519736842106\n",
      "Iteration 305000 reward: 1.323006557377049\n",
      "Iteration 306000 reward: 1.3231339869281045\n",
      "Iteration 307000 reward: 1.3232605863192182\n",
      "Iteration 308000 reward: 1.3235194805194805\n",
      "Iteration 309000 reward: 1.3237378640776698\n",
      "Iteration 310000 reward: 1.3238258064516129\n",
      "Iteration 311000 reward: 1.323823151125402\n",
      "Iteration 312000 reward: 1.3240192307692307\n",
      "Iteration 313000 reward: 1.32426517571885\n",
      "Iteration 314000 reward: 1.3243025477707007\n",
      "Iteration 315000 reward: 1.3244571428571428\n",
      "Iteration 316000 reward: 1.3246898734177215\n",
      "Iteration 317000 reward: 1.324744479495268\n",
      "Iteration 318000 reward: 1.3250723270440252\n",
      "Iteration 319000 reward: 1.3252789968652037\n",
      "Iteration 320000 reward: 1.3252625\n",
      "Iteration 321000 reward: 1.3252741433021806\n",
      "Iteration 322000 reward: 1.3253540372670807\n",
      "Iteration 323000 reward: 1.3253839009287927\n",
      "Iteration 324000 reward: 1.3255555555555556\n",
      "Iteration 325000 reward: 1.3255630769230768\n",
      "Iteration 326000 reward: 1.3257546012269938\n",
      "Iteration 327000 reward: 1.325902140672783\n",
      "Iteration 328000 reward: 1.3261920731707317\n",
      "Iteration 329000 reward: 1.3261914893617022\n",
      "Iteration 330000 reward: 1.3263454545454545\n",
      "Iteration 331000 reward: 1.326513595166163\n",
      "Iteration 332000 reward: 1.3268102409638554\n",
      "Iteration 333000 reward: 1.326966966966967\n",
      "Iteration 334000 reward: 1.3270209580838324\n",
      "Iteration 335000 reward: 1.3271850746268656\n",
      "Iteration 336000 reward: 1.3273482142857143\n",
      "Iteration 337000 reward: 1.3275430267062314\n",
      "Iteration 338000 reward: 1.3278284023668638\n",
      "Iteration 339000 reward: 1.3280324483775812\n",
      "Iteration 340000 reward: 1.3281411764705882\n",
      "Iteration 341000 reward: 1.3283431085043989\n",
      "Iteration 342000 reward: 1.3284736842105263\n",
      "Iteration 343000 reward: 1.3286151603498542\n",
      "Iteration 344000 reward: 1.3288459302325581\n",
      "Iteration 345000 reward: 1.3288115942028986\n",
      "Iteration 346000 reward: 1.3289450867052024\n",
      "Iteration 347000 reward: 1.32907204610951\n",
      "Iteration 348000 reward: 1.3292672413793103\n",
      "Iteration 349000 reward: 1.3293925501432664\n",
      "Iteration 350000 reward: 1.329402857142857\n",
      "Iteration 351000 reward: 1.3294586894586895\n",
      "Iteration 352000 reward: 1.3297017045454544\n",
      "Iteration 353000 reward: 1.3297620396600567\n",
      "Iteration 354000 reward: 1.3297429378531074\n",
      "Iteration 355000 reward: 1.3298676056338028\n",
      "Iteration 356000 reward: 1.3299747191011235\n",
      "Iteration 357000 reward: 1.330280112044818\n",
      "Iteration 358000 reward: 1.3305446927374303\n",
      "Iteration 359000 reward: 1.3307632311977715\n",
      "Iteration 360000 reward: 1.3309472222222223\n",
      "Iteration 361000 reward: 1.3311052631578948\n",
      "Iteration 362000 reward: 1.3311491712707182\n",
      "Iteration 363000 reward: 1.331258953168044\n",
      "Iteration 364000 reward: 1.331239010989011\n",
      "Iteration 365000 reward: 1.3311397260273972\n",
      "Iteration 366000 reward: 1.3312650273224045\n",
      "Iteration 367000 reward: 1.3313242506811989\n",
      "Iteration 368000 reward: 1.3313478260869565\n",
      "Iteration 369000 reward: 1.3313821138211381\n",
      "Iteration 370000 reward: 1.331454054054054\n",
      "Iteration 371000 reward: 1.3314474393530997\n",
      "Iteration 372000 reward: 1.3315295698924732\n",
      "Iteration 373000 reward: 1.3317238605898123\n",
      "Iteration 374000 reward: 1.331855614973262\n",
      "Iteration 375000 reward: 1.3318986666666666\n",
      "Iteration 376000 reward: 1.331912234042553\n",
      "Iteration 377000 reward: 1.3319257294429707\n",
      "Iteration 378000 reward: 1.332116402116402\n",
      "Iteration 379000 reward: 1.3322374670184696\n",
      "Iteration 380000 reward: 1.3322684210526317\n",
      "Iteration 381000 reward: 1.3322992125984252\n",
      "Iteration 382000 reward: 1.3324476439790576\n",
      "Iteration 383000 reward: 1.332574412532637\n",
      "Iteration 384000 reward: 1.3325885416666667\n",
      "Iteration 385000 reward: 1.332612987012987\n",
      "Iteration 386000 reward: 1.3327772020725388\n",
      "Iteration 387000 reward: 1.3327596899224807\n",
      "Iteration 388000 reward: 1.3328582474226804\n",
      "Iteration 389000 reward: 1.3328560411311055\n",
      "Iteration 390000 reward: 1.332971794871795\n",
      "Iteration 391000 reward: 1.3330434782608696\n",
      "Iteration 392000 reward: 1.3330969387755103\n",
      "Iteration 393000 reward: 1.333297709923664\n",
      "Iteration 394000 reward: 1.3334467005076143\n",
      "Iteration 395000 reward: 1.3335569620253165\n",
      "Iteration 396000 reward: 1.3337070707070706\n",
      "Iteration 397000 reward: 1.3338035264483628\n",
      "Iteration 398000 reward: 1.3339924623115578\n",
      "Iteration 399000 reward: 1.334122807017544\n",
      "Iteration 400000 reward: 1.334295\n",
      "Iteration 401000 reward: 1.3343466334164589\n",
      "Iteration 402000 reward: 1.3345024875621891\n",
      "Iteration 403000 reward: 1.33463523573201\n",
      "Iteration 404000 reward: 1.3346584158415842\n",
      "Iteration 405000 reward: 1.3347753086419754\n",
      "Iteration 406000 reward: 1.334832512315271\n",
      "Iteration 407000 reward: 1.334894348894349\n",
      "Iteration 408000 reward: 1.3350392156862745\n",
      "Iteration 409000 reward: 1.3351344743276283\n",
      "Iteration 410000 reward: 1.3352341463414634\n",
      "Iteration 411000 reward: 1.3352822384428225\n",
      "Iteration 412000 reward: 1.3354053398058252\n",
      "Iteration 413000 reward: 1.3355665859564165\n",
      "Iteration 414000 reward: 1.3356400966183575\n",
      "Iteration 415000 reward: 1.3357566265060241\n",
      "Iteration 416000 reward: 1.335764423076923\n",
      "Iteration 417000 reward: 1.3358848920863309\n",
      "Iteration 418000 reward: 1.3359497607655502\n",
      "Iteration 419000 reward: 1.3360310262529833\n",
      "Iteration 420000 reward: 1.3361690476190475\n",
      "Iteration 421000 reward: 1.336187648456057\n",
      "Iteration 422000 reward: 1.3362535545023697\n",
      "Iteration 423000 reward: 1.3363144208037825\n",
      "Iteration 424000 reward: 1.3363349056603773\n",
      "Iteration 425000 reward: 1.3365105882352941\n",
      "Iteration 426000 reward: 1.3366220657276995\n",
      "Iteration 427000 reward: 1.3368103044496487\n",
      "Iteration 428000 reward: 1.3368364485981308\n",
      "Iteration 429000 reward: 1.336881118881119\n",
      "Iteration 430000 reward: 1.3369813953488372\n",
      "Iteration 431000 reward: 1.3370788863109049\n",
      "Iteration 432000 reward: 1.3371712962962963\n",
      "Iteration 433000 reward: 1.337175519630485\n",
      "Iteration 434000 reward: 1.3372603686635944\n",
      "Iteration 435000 reward: 1.3372298850574713\n",
      "Iteration 436000 reward: 1.337408256880734\n",
      "Iteration 437000 reward: 1.3375011441647597\n",
      "Iteration 438000 reward: 1.3375068493150686\n",
      "Iteration 439000 reward: 1.3376492027334852\n",
      "Iteration 440000 reward: 1.3377386363636363\n",
      "Iteration 441000 reward: 1.3378095238095238\n",
      "Iteration 442000 reward: 1.3379366515837103\n",
      "Iteration 443000 reward: 1.338040632054176\n",
      "Iteration 444000 reward: 1.3381103603603604\n",
      "Iteration 445000 reward: 1.33818202247191\n",
      "Iteration 446000 reward: 1.3384080717488789\n",
      "Iteration 447000 reward: 1.3383624161073826\n",
      "Iteration 448000 reward: 1.3384397321428572\n",
      "Iteration 449000 reward: 1.3384365256124722\n",
      "Iteration 450000 reward: 1.3385755555555556\n",
      "Iteration 451000 reward: 1.3386962305986696\n",
      "Iteration 452000 reward: 1.3388097345132743\n",
      "Iteration 453000 reward: 1.3389183222958057\n",
      "Iteration 454000 reward: 1.3388898678414096\n",
      "Iteration 455000 reward: 1.3390593406593407\n",
      "Iteration 456000 reward: 1.3391162280701754\n",
      "Iteration 457000 reward: 1.3391903719912472\n",
      "Iteration 458000 reward: 1.3392860262008734\n",
      "Iteration 459000 reward: 1.3393311546840958\n",
      "Iteration 460000 reward: 1.3394217391304348\n",
      "Iteration 461000 reward: 1.339648590021692\n",
      "Iteration 462000 reward: 1.3397337662337663\n",
      "Iteration 463000 reward: 1.3398228941684664\n",
      "Iteration 464000 reward: 1.3398318965517242\n",
      "Iteration 465000 reward: 1.3399139784946237\n",
      "Iteration 466000 reward: 1.339969957081545\n",
      "Iteration 467000 reward: 1.3401070663811563\n",
      "Iteration 468000 reward: 1.3402649572649572\n",
      "Iteration 469000 reward: 1.3403283582089551\n",
      "Iteration 470000 reward: 1.3404255319148937\n",
      "Iteration 471000 reward: 1.3405859872611465\n",
      "Iteration 472000 reward: 1.3406906779661016\n",
      "Iteration 473000 reward: 1.3407906976744186\n",
      "Iteration 474000 reward: 1.340850210970464\n",
      "Iteration 475000 reward: 1.341\n",
      "Iteration 476000 reward: 1.3411071428571428\n",
      "Iteration 477000 reward: 1.3412473794549267\n",
      "Iteration 478000 reward: 1.3414163179916319\n",
      "Iteration 479000 reward: 1.3414759916492693\n",
      "Iteration 480000 reward: 1.3416916666666667\n",
      "Iteration 481000 reward: 1.3417110187110186\n",
      "Iteration 482000 reward: 1.341844398340249\n",
      "Iteration 483000 reward: 1.341968944099379\n",
      "Iteration 484000 reward: 1.3420847107438016\n",
      "Iteration 485000 reward: 1.3422144329896908\n",
      "Iteration 486000 reward: 1.3423271604938272\n",
      "Iteration 487000 reward: 1.342299794661191\n",
      "Iteration 488000 reward: 1.3423852459016394\n",
      "Iteration 489000 reward: 1.3424192229038854\n",
      "Iteration 490000 reward: 1.3425\n",
      "Iteration 491000 reward: 1.342623217922607\n",
      "Iteration 492000 reward: 1.3428313008130082\n",
      "Iteration 493000 reward: 1.3429290060851926\n",
      "Iteration 494000 reward: 1.3430587044534412\n",
      "Iteration 495000 reward: 1.3431494949494949\n",
      "Iteration 496000 reward: 1.3432540322580646\n",
      "Iteration 497000 reward: 1.3432273641851107\n",
      "Iteration 498000 reward: 1.3433734939759037\n",
      "Iteration 499000 reward: 1.343432865731463\n",
      "Iteration 500000 reward: 1.343524\n",
      "Iteration 501000 reward: 1.3435688622754491\n",
      "Iteration 502000 reward: 1.343691235059761\n",
      "Iteration 503000 reward: 1.3437992047713718\n",
      "Iteration 504000 reward: 1.3437996031746031\n",
      "Iteration 505000 reward: 1.3439287128712871\n",
      "Iteration 506000 reward: 1.3439743083003952\n",
      "Iteration 507000 reward: 1.3440039447731755\n",
      "Iteration 508000 reward: 1.344015748031496\n",
      "Iteration 509000 reward: 1.3440275049115913\n",
      "Iteration 510000 reward: 1.3441490196078432\n",
      "Iteration 511000 reward: 1.3441526418786693\n",
      "Iteration 512000 reward: 1.34441015625\n",
      "Iteration 513000 reward: 1.344551656920078\n",
      "Iteration 514000 reward: 1.344614785992218\n",
      "Iteration 515000 reward: 1.344747572815534\n",
      "Iteration 516000 reward: 1.3447926356589148\n",
      "Iteration 517000 reward: 1.3449226305609285\n",
      "Iteration 518000 reward: 1.3450212355212354\n",
      "Iteration 519000 reward: 1.3450635838150289\n",
      "Iteration 520000 reward: 1.3450923076923076\n",
      "Iteration 521000 reward: 1.3451324376199616\n",
      "Iteration 522000 reward: 1.3452624521072798\n",
      "Iteration 523000 reward: 1.3453269598470363\n",
      "Iteration 524000 reward: 1.345465648854962\n",
      "Iteration 525000 reward: 1.3455485714285715\n",
      "Iteration 526000 reward: 1.3456273764258555\n",
      "Iteration 527000 reward: 1.345707779886148\n",
      "Iteration 528000 reward: 1.345780303030303\n",
      "Iteration 529000 reward: 1.345810964083176\n",
      "Iteration 530000 reward: 1.3458113207547169\n",
      "Iteration 531000 reward: 1.3457928436911488\n",
      "Iteration 532000 reward: 1.345783834586466\n",
      "Iteration 533000 reward: 1.3457861163227016\n",
      "Iteration 534000 reward: 1.345865168539326\n",
      "Iteration 535000 reward: 1.3459644859813085\n",
      "Iteration 536000 reward: 1.3460037313432835\n",
      "Iteration 537000 reward: 1.346052141527002\n",
      "Iteration 538000 reward: 1.346224907063197\n",
      "Iteration 539000 reward: 1.3462745825602969\n",
      "Iteration 540000 reward: 1.346387037037037\n",
      "Iteration 541000 reward: 1.3464121996303142\n",
      "Iteration 542000 reward: 1.3465036900369003\n",
      "Iteration 543000 reward: 1.3464567219152854\n",
      "Iteration 544000 reward: 1.3466452205882353\n",
      "Iteration 545000 reward: 1.346788990825688\n",
      "Iteration 546000 reward: 1.3468736263736263\n",
      "Iteration 547000 reward: 1.3468446069469835\n",
      "Iteration 548000 reward: 1.3469598540145986\n",
      "Iteration 549000 reward: 1.3470619307832423\n",
      "Iteration 550000 reward: 1.347158181818182\n",
      "Iteration 551000 reward: 1.3472540834845734\n",
      "Iteration 552000 reward: 1.3473876811594203\n",
      "Iteration 553000 reward: 1.3474412296564195\n",
      "Iteration 554000 reward: 1.347480144404332\n",
      "Iteration 555000 reward: 1.3475441441441443\n",
      "Iteration 556000 reward: 1.3476888489208634\n",
      "Iteration 557000 reward: 1.347786355475763\n",
      "Iteration 558000 reward: 1.3477921146953404\n",
      "Iteration 559000 reward: 1.347767441860465\n",
      "Iteration 560000 reward: 1.3478035714285714\n",
      "Iteration 561000 reward: 1.3478877005347594\n",
      "Iteration 562000 reward: 1.3479964412811387\n",
      "Iteration 563000 reward: 1.3481278863232682\n",
      "Iteration 564000 reward: 1.3482535460992908\n",
      "Iteration 565000 reward: 1.348387610619469\n",
      "Iteration 566000 reward: 1.348399293286219\n",
      "Iteration 567000 reward: 1.3484761904761904\n",
      "Iteration 568000 reward: 1.3485669014084507\n",
      "Iteration 569000 reward: 1.348615114235501\n",
      "Iteration 570000 reward: 1.348678947368421\n",
      "Iteration 571000 reward: 1.348786339754816\n",
      "Iteration 572000 reward: 1.3487465034965036\n",
      "Iteration 573000 reward: 1.348846422338569\n",
      "Iteration 574000 reward: 1.348951219512195\n",
      "Iteration 575000 reward: 1.349055652173913\n",
      "Iteration 576000 reward: 1.3492447916666668\n",
      "Iteration 577000 reward: 1.3493396880415944\n",
      "Iteration 578000 reward: 1.3494740484429066\n",
      "Iteration 579000 reward: 1.3495423143350604\n",
      "Iteration 580000 reward: 1.3496637931034483\n",
      "Iteration 581000 reward: 1.3497762478485371\n",
      "Iteration 582000 reward: 1.3498865979381443\n",
      "Iteration 583000 reward: 1.3499605488850772\n",
      "Iteration 584000 reward: 1.3500325342465753\n",
      "Iteration 585000 reward: 1.3501384615384615\n",
      "Iteration 586000 reward: 1.350179180887372\n",
      "Iteration 587000 reward: 1.350243611584327\n",
      "Iteration 588000 reward: 1.3502993197278912\n",
      "Iteration 589000 reward: 1.3503565365025467\n",
      "Iteration 590000 reward: 1.3504135593220339\n",
      "Iteration 591000 reward: 1.3505617597292725\n",
      "Iteration 592000 reward: 1.350535472972973\n",
      "Iteration 593000 reward: 1.3505463743676223\n",
      "Iteration 594000 reward: 1.35066835016835\n",
      "Iteration 595000 reward: 1.3508168067226891\n",
      "Iteration 596000 reward: 1.3508456375838926\n",
      "Iteration 597000 reward: 1.3509497487437185\n",
      "Iteration 598000 reward: 1.3510685618729097\n",
      "Iteration 599000 reward: 1.3511135225375626\n",
      "Iteration 600000 reward: 1.3512366666666666\n",
      "Iteration 601000 reward: 1.351324459234609\n",
      "Iteration 602000 reward: 1.3513837209302326\n",
      "Iteration 603000 reward: 1.35150912106136\n",
      "Iteration 604000 reward: 1.3515347682119205\n",
      "Iteration 605000 reward: 1.35161652892562\n",
      "Iteration 606000 reward: 1.3517227722772278\n",
      "Iteration 607000 reward: 1.3517907742998352\n",
      "Iteration 608000 reward: 1.35190625\n",
      "Iteration 609000 reward: 1.3520197044334976\n",
      "Iteration 610000 reward: 1.3520770491803278\n",
      "Iteration 611000 reward: 1.3522209492635024\n",
      "Iteration 612000 reward: 1.35225\n",
      "Iteration 613000 reward: 1.352231647634584\n",
      "Iteration 614000 reward: 1.3522964169381106\n",
      "Iteration 615000 reward: 1.3523463414634147\n",
      "Iteration 616000 reward: 1.3523798701298702\n",
      "Iteration 617000 reward: 1.3525056726094002\n",
      "Iteration 618000 reward: 1.3525906148867315\n",
      "Iteration 619000 reward: 1.3526332794830371\n",
      "Iteration 620000 reward: 1.3526983870967741\n",
      "Iteration 621000 reward: 1.3528470209339774\n",
      "Iteration 622000 reward: 1.352943729903537\n",
      "Iteration 623000 reward: 1.352951845906902\n",
      "Iteration 624000 reward: 1.3531298076923077\n",
      "Iteration 625000 reward: 1.3532192\n",
      "Iteration 626000 reward: 1.3532555910543131\n",
      "Iteration 627000 reward: 1.3533062200956938\n",
      "Iteration 628000 reward: 1.3533933121019108\n",
      "Iteration 629000 reward: 1.3534054054054054\n",
      "Iteration 630000 reward: 1.3535174603174602\n",
      "Iteration 631000 reward: 1.3535974643423139\n",
      "Iteration 632000 reward: 1.353620253164557\n",
      "Iteration 633000 reward: 1.3536445497630332\n",
      "Iteration 634000 reward: 1.3537334384858044\n",
      "Iteration 635000 reward: 1.3538031496062992\n",
      "Iteration 636000 reward: 1.3539040880503144\n",
      "Iteration 637000 reward: 1.3539654631083202\n",
      "Iteration 638000 reward: 1.354037617554859\n",
      "Iteration 639000 reward: 1.354035993740219\n",
      "Iteration 640000 reward: 1.3540578125\n",
      "Iteration 641000 reward: 1.3541185647425897\n",
      "Iteration 642000 reward: 1.354132398753894\n",
      "Iteration 643000 reward: 1.3542006220839813\n",
      "Iteration 644000 reward: 1.3542406832298137\n",
      "Iteration 645000 reward: 1.3543472868217055\n",
      "Iteration 646000 reward: 1.3544643962848297\n",
      "Iteration 647000 reward: 1.3545270479134466\n",
      "Iteration 648000 reward: 1.3545771604938273\n",
      "Iteration 649000 reward: 1.3546409861325115\n",
      "Iteration 650000 reward: 1.3547246153846153\n",
      "Iteration 651000 reward: 1.3547127496159754\n",
      "Iteration 652000 reward: 1.354664110429448\n",
      "Iteration 653000 reward: 1.3547641653905054\n",
      "Iteration 654000 reward: 1.3548088685015292\n",
      "Iteration 655000 reward: 1.354830534351145\n",
      "Iteration 656000 reward: 1.3548917682926829\n",
      "Iteration 657000 reward: 1.3548995433789954\n",
      "Iteration 658000 reward: 1.3549331306990882\n",
      "Iteration 659000 reward: 1.35498937784522\n",
      "Iteration 660000 reward: 1.3551166666666667\n",
      "Iteration 661000 reward: 1.3551860816944024\n",
      "Iteration 662000 reward: 1.3552764350453173\n",
      "Iteration 663000 reward: 1.3553740573152337\n",
      "Iteration 664000 reward: 1.3554774096385542\n",
      "Iteration 665000 reward: 1.3555924812030076\n",
      "Iteration 666000 reward: 1.3556201201201201\n",
      "Iteration 667000 reward: 1.3557796101949025\n",
      "Iteration 668000 reward: 1.3558338323353294\n",
      "Iteration 669000 reward: 1.3558460388639761\n",
      "Iteration 670000 reward: 1.3559626865671641\n",
      "Iteration 671000 reward: 1.3559970193740685\n",
      "Iteration 672000 reward: 1.3560446428571429\n",
      "Iteration 673000 reward: 1.3560520059435364\n",
      "Iteration 674000 reward: 1.3560148367952523\n",
      "Iteration 675000 reward: 1.3560029629629629\n",
      "Iteration 676000 reward: 1.3560680473372781\n",
      "Iteration 677000 reward: 1.3560989660265879\n",
      "Iteration 678000 reward: 1.3561548672566373\n",
      "Iteration 679000 reward: 1.356120765832106\n",
      "Iteration 680000 reward: 1.356179411764706\n",
      "Iteration 681000 reward: 1.356236417033774\n",
      "Iteration 682000 reward: 1.3563108504398826\n",
      "Iteration 683000 reward: 1.3563704245973647\n",
      "Iteration 684000 reward: 1.3564195906432748\n",
      "Iteration 685000 reward: 1.3564423357664233\n",
      "Iteration 686000 reward: 1.3565014577259475\n",
      "Iteration 687000 reward: 1.35654730713246\n",
      "Iteration 688000 reward: 1.3566017441860465\n",
      "Iteration 689000 reward: 1.3566705370101597\n",
      "Iteration 690000 reward: 1.3567666666666667\n",
      "Iteration 691000 reward: 1.3567496382054993\n",
      "Iteration 692000 reward: 1.356778901734104\n",
      "Iteration 693000 reward: 1.3568297258297257\n",
      "Iteration 694000 reward: 1.356963976945245\n",
      "Iteration 695000 reward: 1.3570359712230216\n",
      "Iteration 696000 reward: 1.3571135057471264\n",
      "Iteration 697000 reward: 1.3572639885222382\n",
      "Iteration 698000 reward: 1.357378223495702\n",
      "Iteration 699000 reward: 1.3574263233190271\n",
      "Iteration 700000 reward: 1.3574657142857143\n",
      "Iteration 701000 reward: 1.3574893009985736\n",
      "Iteration 702000 reward: 1.3575384615384616\n",
      "Iteration 703000 reward: 1.3575988620199146\n",
      "Iteration 704000 reward: 1.3576633522727273\n",
      "Iteration 705000 reward: 1.3575971631205674\n",
      "Iteration 706000 reward: 1.3576770538243625\n",
      "Iteration 707000 reward: 1.3576859971711457\n",
      "Iteration 708000 reward: 1.3577853107344633\n",
      "Iteration 709000 reward: 1.3577729196050776\n",
      "Iteration 710000 reward: 1.3578971830985915\n",
      "Iteration 711000 reward: 1.357943741209564\n",
      "Iteration 712000 reward: 1.3580393258426966\n",
      "Iteration 713000 reward: 1.3580883590462833\n",
      "Iteration 714000 reward: 1.3581176470588234\n",
      "Iteration 715000 reward: 1.3581986013986014\n",
      "Iteration 716000 reward: 1.3582709497206704\n",
      "Iteration 717000 reward: 1.3582942817294281\n",
      "Iteration 718000 reward: 1.358366295264624\n",
      "Iteration 719000 reward: 1.3584311543810847\n",
      "Iteration 720000 reward: 1.3585069444444444\n",
      "Iteration 721000 reward: 1.358613037447989\n",
      "Iteration 722000 reward: 1.3587160664819944\n",
      "Iteration 723000 reward: 1.3587524204702628\n",
      "Iteration 724000 reward: 1.358810773480663\n",
      "Iteration 725000 reward: 1.3588717241379311\n",
      "Iteration 726000 reward: 1.3589366391184572\n",
      "Iteration 727000 reward: 1.3588707015130674\n",
      "Iteration 728000 reward: 1.3589807692307692\n",
      "Iteration 729000 reward: 1.3590781893004116\n",
      "Iteration 730000 reward: 1.3591835616438357\n",
      "Iteration 731000 reward: 1.3592257181942544\n",
      "Iteration 732000 reward: 1.3593661202185792\n",
      "Iteration 733000 reward: 1.3594133697135062\n",
      "Iteration 734000 reward: 1.359475476839237\n",
      "Iteration 735000 reward: 1.3595455782312924\n",
      "Iteration 736000 reward: 1.3595828804347827\n",
      "Iteration 737000 reward: 1.3596472184531887\n",
      "Iteration 738000 reward: 1.3597046070460705\n",
      "Iteration 739000 reward: 1.359741542625169\n",
      "Iteration 740000 reward: 1.3597662162162163\n",
      "Iteration 741000 reward: 1.3598151147098516\n",
      "Iteration 742000 reward: 1.3598409703504044\n",
      "Iteration 743000 reward: 1.3599986541049798\n",
      "Iteration 744000 reward: 1.3600094086021506\n",
      "Iteration 745000 reward: 1.3600174496644295\n",
      "Iteration 746000 reward: 1.360038873994638\n",
      "Iteration 747000 reward: 1.3600481927710844\n",
      "Iteration 748000 reward: 1.3600975935828876\n",
      "Iteration 749000 reward: 1.360128170894526\n",
      "Iteration 750000 reward: 1.3601866666666667\n",
      "Iteration 751000 reward: 1.3602330226364847\n",
      "Iteration 752000 reward: 1.3603058510638297\n",
      "Iteration 753000 reward: 1.3603864541832669\n",
      "Iteration 754000 reward: 1.3604084880636604\n",
      "Iteration 755000 reward: 1.3604119205298013\n",
      "Iteration 756000 reward: 1.360505291005291\n",
      "Iteration 757000 reward: 1.360573315719947\n",
      "Iteration 758000 reward: 1.3606635883905014\n",
      "Iteration 759000 reward: 1.360737812911726\n",
      "Iteration 760000 reward: 1.3607355263157894\n",
      "Iteration 761000 reward: 1.3608554533508541\n",
      "Iteration 762000 reward: 1.3609120734908136\n",
      "Iteration 763000 reward: 1.3608951507208389\n",
      "Iteration 764000 reward: 1.3609829842931938\n",
      "Iteration 765000 reward: 1.3610222222222221\n",
      "Iteration 766000 reward: 1.3610456919060052\n",
      "Iteration 767000 reward: 1.361039113428944\n",
      "Iteration 768000 reward: 1.3611119791666666\n",
      "Iteration 769000 reward: 1.3611248374512355\n",
      "Iteration 770000 reward: 1.3612233766233766\n",
      "Iteration 771000 reward: 1.3612594033722438\n",
      "Iteration 772000 reward: 1.3612603626943005\n",
      "Iteration 773000 reward: 1.3612923673997412\n",
      "Iteration 774000 reward: 1.3613488372093023\n",
      "Iteration 775000 reward: 1.361421935483871\n",
      "Iteration 776000 reward: 1.3614278350515463\n",
      "Iteration 777000 reward: 1.3614839124839124\n",
      "Iteration 778000 reward: 1.3615167095115681\n",
      "Iteration 779000 reward: 1.361594351732991\n",
      "Iteration 780000 reward: 1.3615897435897435\n",
      "Iteration 781000 reward: 1.3616606914212548\n",
      "Iteration 782000 reward: 1.3617007672634271\n",
      "Iteration 783000 reward: 1.3617777777777778\n",
      "Iteration 784000 reward: 1.3618035714285714\n",
      "Iteration 785000 reward: 1.3618140127388536\n",
      "Iteration 786000 reward: 1.361852417302799\n",
      "Iteration 787000 reward: 1.3619110546378652\n",
      "Iteration 788000 reward: 1.361969543147208\n",
      "Iteration 789000 reward: 1.362041825095057\n",
      "Iteration 790000 reward: 1.362132911392405\n",
      "Iteration 791000 reward: 1.3621137800252845\n",
      "Iteration 792000 reward: 1.3621641414141414\n",
      "Iteration 793000 reward: 1.362234552332913\n",
      "Iteration 794000 reward: 1.362308564231738\n",
      "Iteration 795000 reward: 1.362359748427673\n",
      "Iteration 796000 reward: 1.362394472361809\n",
      "Iteration 797000 reward: 1.3624855708908405\n",
      "Iteration 798000 reward: 1.3625814536340852\n",
      "Iteration 799000 reward: 1.3626170212765958\n",
      "Iteration 800000 reward: 1.36265875\n",
      "Iteration 801000 reward: 1.362669163545568\n",
      "Iteration 802000 reward: 1.36264463840399\n",
      "Iteration 803000 reward: 1.3627210460772106\n",
      "Iteration 804000 reward: 1.3627848258706468\n",
      "Iteration 805000 reward: 1.362863354037267\n",
      "Iteration 806000 reward: 1.3629156327543424\n",
      "Iteration 807000 reward: 1.363018587360595\n",
      "Iteration 808000 reward: 1.3630680693069306\n",
      "Iteration 809000 reward: 1.3631334981458592\n",
      "Iteration 810000 reward: 1.3632222222222221\n",
      "Iteration 811000 reward: 1.363268803945746\n",
      "Iteration 812000 reward: 1.3632832512315272\n",
      "Iteration 813000 reward: 1.3633579335793358\n",
      "Iteration 814000 reward: 1.363428746928747\n",
      "Iteration 815000 reward: 1.3635263803680981\n",
      "Iteration 816000 reward: 1.3635698529411764\n",
      "Iteration 817000 reward: 1.363610771113831\n",
      "Iteration 818000 reward: 1.3636344743276283\n",
      "Iteration 819000 reward: 1.3637032967032967\n",
      "Iteration 820000 reward: 1.363740243902439\n",
      "Iteration 821000 reward: 1.3637649208282583\n",
      "Iteration 822000 reward: 1.3638296836982968\n",
      "Iteration 823000 reward: 1.3638298906439854\n",
      "Iteration 824000 reward: 1.363878640776699\n",
      "Iteration 825000 reward: 1.3639030303030304\n",
      "Iteration 826000 reward: 1.363914043583535\n",
      "Iteration 827000 reward: 1.3639117291414753\n",
      "Iteration 828000 reward: 1.3639359903381643\n",
      "Iteration 829000 reward: 1.3639481302774428\n",
      "Iteration 830000 reward: 1.3639686746987951\n",
      "Iteration 831000 reward: 1.363968712394705\n",
      "Iteration 832000 reward: 1.3639855769230769\n",
      "Iteration 833000 reward: 1.364062424969988\n",
      "Iteration 834000 reward: 1.3640827338129495\n",
      "Iteration 835000 reward: 1.3640958083832335\n",
      "Iteration 836000 reward: 1.3641184210526316\n",
      "Iteration 837000 reward: 1.364163679808841\n",
      "Iteration 838000 reward: 1.3641634844868735\n",
      "Iteration 839000 reward: 1.3641787842669846\n",
      "Iteration 840000 reward: 1.3642\n",
      "Iteration 841000 reward: 1.364244946492271\n",
      "Iteration 842000 reward: 1.3642399049881235\n",
      "Iteration 843000 reward: 1.3643214709371294\n",
      "Iteration 844000 reward: 1.3643270142180095\n",
      "Iteration 845000 reward: 1.364350295857988\n",
      "Iteration 846000 reward: 1.3643947990543734\n",
      "Iteration 847000 reward: 1.3644049586776859\n",
      "Iteration 848000 reward: 1.3644516509433962\n",
      "Iteration 849000 reward: 1.364487632508834\n",
      "Iteration 850000 reward: 1.364530588235294\n",
      "Iteration 851000 reward: 1.3645816686251468\n",
      "Iteration 852000 reward: 1.3646666666666667\n",
      "Iteration 853000 reward: 1.3646893317702227\n",
      "Iteration 854000 reward: 1.3647306791569087\n",
      "Iteration 855000 reward: 1.364766081871345\n",
      "Iteration 856000 reward: 1.3647885514018692\n",
      "Iteration 857000 reward: 1.364806301050175\n",
      "Iteration 858000 reward: 1.3648706293706294\n",
      "Iteration 859000 reward: 1.3648626309662397\n",
      "Iteration 860000 reward: 1.3648546511627906\n",
      "Iteration 861000 reward: 1.3649059233449476\n",
      "Iteration 862000 reward: 1.3648793503480279\n",
      "Iteration 863000 reward: 1.364933951332561\n",
      "Iteration 864000 reward: 1.3649930555555556\n",
      "Iteration 865000 reward: 1.3650080924855492\n",
      "Iteration 866000 reward: 1.3650658198614318\n",
      "Iteration 867000 reward: 1.3651014994232988\n",
      "Iteration 868000 reward: 1.3651290322580645\n",
      "Iteration 869000 reward: 1.3651588032220943\n",
      "Iteration 870000 reward: 1.3651839080459771\n",
      "Iteration 871000 reward: 1.3652181400688863\n",
      "Iteration 872000 reward: 1.3652649082568806\n",
      "Iteration 873000 reward: 1.365290950744559\n",
      "Iteration 874000 reward: 1.3653386727688788\n",
      "Iteration 875000 reward: 1.3653462857142857\n",
      "Iteration 876000 reward: 1.3653778538812786\n",
      "Iteration 877000 reward: 1.3654446978335233\n",
      "Iteration 878000 reward: 1.3654658314350798\n",
      "Iteration 879000 reward: 1.3655221843003413\n",
      "Iteration 880000 reward: 1.3655704545454546\n",
      "Iteration 881000 reward: 1.3655527809307606\n",
      "Iteration 882000 reward: 1.3656303854875282\n",
      "Iteration 883000 reward: 1.3656636466591165\n",
      "Iteration 884000 reward: 1.3656798642533936\n",
      "Iteration 885000 reward: 1.3656892655367232\n",
      "Iteration 886000 reward: 1.36577539503386\n",
      "Iteration 887000 reward: 1.3658523111612175\n",
      "Iteration 888000 reward: 1.3658468468468468\n",
      "Iteration 889000 reward: 1.3659111361079865\n",
      "Iteration 890000 reward: 1.3659685393258427\n",
      "Iteration 891000 reward: 1.366050505050505\n",
      "Iteration 892000 reward: 1.3660706278026906\n",
      "Iteration 893000 reward: 1.366097424412094\n",
      "Iteration 894000 reward: 1.3660950782997763\n",
      "Iteration 895000 reward: 1.366140782122905\n",
      "Iteration 896000 reward: 1.3661116071428572\n",
      "Iteration 897000 reward: 1.366153846153846\n",
      "Iteration 898000 reward: 1.3661369710467706\n",
      "Iteration 899000 reward: 1.3661078976640713\n",
      "Iteration 900000 reward: 1.3660911111111111\n",
      "Iteration 901000 reward: 1.366134295227525\n",
      "Iteration 902000 reward: 1.366159645232816\n",
      "Iteration 903000 reward: 1.3661982281284606\n",
      "Iteration 904000 reward: 1.36625\n",
      "Iteration 905000 reward: 1.3662740331491712\n",
      "Iteration 906000 reward: 1.3663289183222957\n",
      "Iteration 907000 reward: 1.3663153252480706\n",
      "Iteration 908000 reward: 1.3663359030837003\n",
      "Iteration 909000 reward: 1.3663773377337733\n",
      "Iteration 910000 reward: 1.366386813186813\n",
      "Iteration 911000 reward: 1.366431394072448\n",
      "Iteration 912000 reward: 1.3664682017543859\n",
      "Iteration 913000 reward: 1.3664939759036145\n",
      "Iteration 914000 reward: 1.3665218818380744\n",
      "Iteration 915000 reward: 1.3665256830601094\n",
      "Iteration 916000 reward: 1.3665240174672488\n",
      "Iteration 917000 reward: 1.36660959651036\n",
      "Iteration 918000 reward: 1.3666209150326798\n",
      "Iteration 919000 reward: 1.366587595212187\n",
      "Iteration 920000 reward: 1.3665945652173912\n",
      "Iteration 921000 reward: 1.3666775244299674\n",
      "Iteration 922000 reward: 1.3667125813449024\n",
      "Iteration 923000 reward: 1.3667291440953413\n",
      "Iteration 924000 reward: 1.3667792207792209\n",
      "Iteration 925000 reward: 1.3668086486486486\n",
      "Iteration 926000 reward: 1.3668034557235422\n",
      "Iteration 927000 reward: 1.3668274002157497\n",
      "Iteration 928000 reward: 1.3669181034482758\n",
      "Iteration 929000 reward: 1.367005382131324\n",
      "Iteration 930000 reward: 1.3670559139784946\n",
      "Iteration 931000 reward: 1.3670988184747583\n",
      "Iteration 932000 reward: 1.3671244635193134\n",
      "Iteration 933000 reward: 1.3671425509110398\n",
      "Iteration 934000 reward: 1.3671755888650963\n",
      "Iteration 935000 reward: 1.3672673796791444\n",
      "Iteration 936000 reward: 1.367315170940171\n",
      "Iteration 937000 reward: 1.3673863393810033\n",
      "Iteration 938000 reward: 1.367412579957356\n",
      "Iteration 939000 reward: 1.3674802981895633\n",
      "Iteration 940000 reward: 1.3675127659574469\n",
      "Iteration 941000 reward: 1.3676036131774707\n",
      "Iteration 942000 reward: 1.3676422505307855\n",
      "Iteration 943000 reward: 1.3676383881230116\n",
      "Iteration 944000 reward: 1.3676949152542373\n",
      "Iteration 945000 reward: 1.3677301587301587\n",
      "Iteration 946000 reward: 1.3677875264270614\n",
      "Iteration 947000 reward: 1.3678321013727561\n",
      "Iteration 948000 reward: 1.3678544303797469\n",
      "Iteration 949000 reward: 1.3678429926238145\n",
      "Iteration 950000 reward: 1.3678284210526315\n",
      "Iteration 951000 reward: 1.3678422712933753\n",
      "Iteration 952000 reward: 1.3678109243697478\n",
      "Iteration 953000 reward: 1.3678782791185728\n",
      "Iteration 954000 reward: 1.3678972746331237\n",
      "Iteration 955000 reward: 1.3679476439790577\n",
      "Iteration 956000 reward: 1.36801359832636\n",
      "Iteration 957000 reward: 1.3680323928944618\n",
      "Iteration 958000 reward: 1.3680250521920667\n",
      "Iteration 959000 reward: 1.3680521376433785\n",
      "Iteration 960000 reward: 1.36809375\n",
      "Iteration 961000 reward: 1.3681030176899063\n",
      "Iteration 962000 reward: 1.3682172557172556\n",
      "Iteration 963000 reward: 1.3682772585669782\n",
      "Iteration 964000 reward: 1.3683547717842324\n",
      "Iteration 965000 reward: 1.3684186528497408\n",
      "Iteration 966000 reward: 1.3684420289855073\n",
      "Iteration 967000 reward: 1.368511892450879\n",
      "Iteration 968000 reward: 1.3685661157024793\n",
      "Iteration 969000 reward: 1.3686295149638803\n",
      "Iteration 970000 reward: 1.3686268041237113\n",
      "Iteration 971000 reward: 1.3686508753862\n",
      "Iteration 972000 reward: 1.368764403292181\n",
      "Iteration 973000 reward: 1.368753340184995\n",
      "Iteration 974000 reward: 1.3688090349075976\n",
      "Iteration 975000 reward: 1.3688276923076923\n",
      "Iteration 976000 reward: 1.3688073770491804\n",
      "Iteration 977000 reward: 1.3688741044012283\n",
      "Iteration 978000 reward: 1.3689110429447853\n",
      "Iteration 979000 reward: 1.3689805924412666\n",
      "Iteration 980000 reward: 1.368961224489796\n",
      "Iteration 981000 reward: 1.368992864424057\n",
      "Iteration 982000 reward: 1.3690224032586558\n",
      "Iteration 983000 reward: 1.3690681586978637\n",
      "Iteration 984000 reward: 1.3691107723577236\n",
      "Iteration 985000 reward: 1.3691319796954315\n",
      "Iteration 986000 reward: 1.3691724137931034\n",
      "Iteration 987000 reward: 1.36922695035461\n",
      "Iteration 988000 reward: 1.3692682186234817\n",
      "Iteration 989000 reward: 1.369314459049545\n",
      "Iteration 990000 reward: 1.3693676767676768\n",
      "Iteration 991000 reward: 1.3694137235116044\n",
      "Iteration 992000 reward: 1.3694627016129033\n",
      "Iteration 993000 reward: 1.3694702920443103\n",
      "Iteration 994000 reward: 1.369539235412475\n",
      "Iteration 995000 reward: 1.3695909547738694\n",
      "Iteration 996000 reward: 1.3696305220883533\n",
      "Iteration 997000 reward: 1.3696649949849549\n",
      "Iteration 998000 reward: 1.369749498997996\n",
      "Iteration 999000 reward: 1.3698288288288287\n",
      "Iteration 1000000 reward: 1.369812\n",
      "Model saved to model/q_matrix.npy\n"
     ]
    }
   ],
   "source": [
    "from q_learning_agent import QLearningAgent\n",
    "q_learning_agent = QLearningAgent()\n",
    "q_learning_agent.learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScalarFormatter\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(q_learning_agent\u001b[38;5;241m.\u001b[39mrewards)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "plt.plot(q_learning_agent.rewards)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Q-learning Reward vs Iteration')\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(5, 5))  # Set x-axis labels in millions\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.plot(deep_q_model.rewards)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
